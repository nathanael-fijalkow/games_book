%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Introduction}}

\usepackage{sphinxmessages}




\title{Games on graphs}
\date{Feb 04, 2021}
\release{}
\author{Nathalie Bertrand, Romain Brenguier, Patricia Bouyer\sphinxhyphen{}Decitre, Arnaud Carayol, John Fearnley, Nathanaël Fijalkow, Hugo Gimbert, Florian Horn, Rasmus Ibsen\sphinxhyphen{}Jensen, Nicolas Markey, Benjamin Monmege, Petr Novotny, Mickael Randour, Ocan Sankur, Sylvain Schmitz, Olivier Serre}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{book::doc}}


That’s the entry point to the book. Maybe a little logo?

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{cover}.jpg}\hspace*{\fill}}


\chapter{Introduction}
\label{\detokenize{1_Introduction/main:introduction}}\label{\detokenize{1_Introduction/main:chap-introduction}}\label{\detokenize{1_Introduction/main::doc}}
\DUrole{xref,myst}{Intro} answers natural questions such as: what is the book about, at whom it is aimed, and how to read it.
{\hyperref[\detokenize{1_Introduction/simple:sec-simple}]{\sphinxcrossref{\DUrole{std,std-ref}{Simple}}}} defines a first model of games, which is the common denominator of (almost all) models studied in this book.

We introduce the computational models that we use in \DUrole{xref,myst}{Computation} and briefly define linear programming.
In \DUrole{xref,myst}{Conditions} we list the main objectives appearing in all chapters.
A few notions will be useful throughout the book: they are developed in this chapter.
We start with the notion of automata, discussed in \DUrole{xref,myst}{Automata}, and then memory for strategies, in \DUrole{xref,myst}{Memory}.
We then show how automata and memory structures can be used to construct reductions between games in \DUrole{xref,myst}{Reductions}.
We introduce in \DUrole{xref,myst}{Subgames} the notions of subgames and traps.

The notion of fixed point algorithms is central to the study of games.
We first recall the main two methods for proving the existence and computing fixed points in \DUrole{xref,myst}{Fixed points}.
We then give an overview of two prominent families of fixed point algorithms for games:
value iteration algorithms in \DUrole{xref,myst}{Value iteration algorithms} and strategy improvement algorithms in \DUrole{xref,myst}{Strategy improvement algorithms}.


\section{Simple}
\label{\detokenize{1_Introduction/simple:simple}}\label{\detokenize{1_Introduction/simple:sec-simple}}\label{\detokenize{1_Introduction/simple::doc}}
The first model we define is the common denominator of most models studied in this book:
\begin{itemize}
\item {} 
\(2\)\sphinxhyphen{}player,

\item {} 
zero sum,

\item {} 
turn based,

\item {} 
perfect information
game.

\end{itemize}


\subsection{Players}
\label{\detokenize{1_Introduction/simple:players}}\label{\detokenize{1_Introduction/simple:subsec-players}}
The term \sphinxstyleemphasis{\(2\)\sphinxhyphen{}player} means that there are two players, Eve and Adam. Many, many different names
have been used: Player \(0\) and Player \(1\), Player I and Player II as in
descriptive complexity, Éloïse and Abélard, Circle and Square,
corresponding to the graphical representation, Even and Odd, mostly for
parity objectives, Player and Opponent, Pathfinder and Verifier in the
context of automata, Max and Min, which makes sense for quantitative
objectives, and this is only a very partial list of names they have been
given. In the names Eve and Adam, the first letters refer to \(\exists\)
and \(\forall\) suggesting a duality between them. We will make use of
their gender to distinguish between them, so we speak of her or his
strategy.

We speak of 1\sphinxhyphen{}player games when there is only one player. In the
context of stochastic games, we refer to random as a third player, and
more precisely as half a player. Hence a 2 1/2\sphinxhyphen{}player game is a
stochastic game with two players, and a 1 1/2\sphinxhyphen{}player game is a
stochastic game with one player.

The situation where there are more than two players is called
multiplayer games.


\subsection{Graphs}
\label{\detokenize{1_Introduction/simple:graphs}}\label{\detokenize{1_Introduction/simple:subsec-graphs}}
A (directed) graph is given by a
set \(V\) of vertices and a set \(E \subseteq V \times V\) of edges. For an
edge \(e = (v,v')\) we write \(\ing(e)\) for the incoming
vertex \(v\) and \(\out(e)\) for the outgoing vertex \(v'\): we
say that \(e\) is an outgoing edge of \(v\) and an incoming
edge to \(v'\).

A path \(\pi = v_0 v_1 \cdots\) is a non empty finite or infinite
sequence of consecutive vertices: for all \(i\) we have
\((v_i,v_{i+1}) \in E\). We let \(\first(\pi)\) denote the first vertex
occurring in \(\pi\) and \(\last(\pi)\) the last one if \(\pi\) is finite. We
say that \(\pi\) starts from \(\first(\pi)\) and if \(\pi\) is finite
\(\pi\) ends in \(\last(\pi)\). We sometimes talk of a path and let
the context determine whether it is finite or infinite.

We let \(\Paths(G) \subseteq V^+\) denote the set of finite paths in the
graph \(G\), sometimes omitting \(G\) when clear from the context. To
restrict to paths starting from \(v\) we write \(\Paths(G,v)\). The set of
infinite paths is \(\Paths_\omega(G) \subseteq V^\omega\), and
\(\Paths_\omega(G,v)\) for those starting from \(v\).

We use the standard terminology of graphs: for instance a vertex \(v'\) is
a successor of \(v\) if \((v,v') \in E\), and then \(v\) is a
predecessor of \(v'\), a vertex \(v'\) is reachable from \(v\)
if there exists a path starting from \(v\) and ending in \(v'\), the
outdegree of a vertex is its number of outgoing edges, the
indegree is its number of incoming edges, a simple path
is a path with no repetitions of vertices, a cycle is a path
whose first and last vertex coincide, it is a simple cycle if it
does not strictly contain another cycle, a self loop is an edge
from a vertex to itself, and a sink is a vertex with only a self
loop as outgoing edge.


\subsection{Arenas}
\label{\detokenize{1_Introduction/simple:arenas}}\label{\detokenize{1_Introduction/simple:subsec-arenas}}
The arena is the place where the game is played, they have also
been called game structures or game graphs.

In the turn based setting we define here, the set of vertices is divided
into vertices controlled by each player. Since we are for now interested
in \sphinxstyleemphasis{\(2\)\sphinxhyphen{}player} games, we have \(V = \VE \uplus \VA\), where \(\VE\) is the
set of vertices controlled by Eve and \(\VA\) the set of vertices
controlled by Adam. We represent vertices in \(\VE\) by circles, and
vertices in \(\VA\) by squares, and also say that \(v \in \VE\) belongs to
Eve, or that Eve owns or controls \(v\), and similarly for Adam. An arena
is given by a graph and the sets \(\VE\) and \(\VA\). In the context of
games, vertices are often referred to as positions.

The adjective “\sphinxstyleemphasis{finite}” means that the arena is finite, \sphinxstyleemphasis{i.e.}
there are finitely many vertices (hence finitely many edges). We oppose
“\sphinxstyleemphasis{deterministic}” to “\sphinxstyleemphasis{stochastic}”: in the first definition we are
giving here, there is no stochastic aspect in the game. An important
assumption, called “\sphinxstyleemphasis{perfect information}”, says that the players see
everything about how the game is played out, in particular they see the
other player’s moves.

Our definition of an arena does not include the initial vertex.

We assume that all vertices have an outgoing edge. This is for technical
convenience, as it implies that we do not need to explain what happens
when a play cannot be prolonged.


\subsection{Playing}
\label{\detokenize{1_Introduction/simple:playing}}\label{\detokenize{1_Introduction/simple:subsec-playing}}
The interaction between the two players consists in moving a token on
the vertices of the arena. The token is initially on some vertex. When
the token is in some vertex \(v\), the player who controls the vertex
chooses an outgoing edge \(e\) of \(v\) and pushes the token along this edge
to the next vertex \(\out(e) = v'\). The outcome of this interaction is
the sequence of vertices traversed by the token: it is a path. In the
context of games a path is also called a play and as for paths
usually written \(\play\). We note that plays can be finite (but non
empty) or infinite.


\subsection{Strategies}
\label{\detokenize{1_Introduction/simple:strategies}}\label{\detokenize{1_Introduction/simple:subsec-strategies}}
The most important notion in this book is that of \sphinxstyleemphasis{strategies}
(sometimes called policies). A strategy for a player is a full
description of his or her moves in all situations. Formally, a
strategy is a function mapping finite plays to edges:
\begin{equation*}
\begin{split}\sigma : \Paths \to E.\end{split}
\end{equation*}
We use \(\sigma\) for strategies of Eve and \(\tau\) for strategies of Adam
so when considering a strategy \(\sigma\) it is implicitly for Eve,
and similarly \(\tau\) is implicitly a strategy for Adam.

We say that a play \(\play = v_0 v_1 \dots\) is consistent with a strategy
\(\sigma\) of Eve if for all \(i\) such that \(v_i \in \VE\) we have
\(\sigma(\play_{\le i}) = (v_i,v_{i+1})\). The definition is easily
adapted for strategies of Adam.

Once an initial vertex \(v\) and two strategies \(\sigma\) and \(\tau\) have
been fixed, there exists a unique infinite play starting from \(v\) and
consistent with both strategies written \(\pi^{v}_{\sigma,\tau}\). Note
that the fact that it is infinite follows from our assumption that all
vertices have an outgoing edge.


\subsection{Conditions}
\label{\detokenize{1_Introduction/simple:conditions}}\label{\detokenize{1_Introduction/simple:subsec-conditions}}
The last ingredient to wrap up the definitions is (winning)
conditions, which is what Eve wants to achieve. There are two
types of conditions: the \sphinxstyleemphasis{qualitative}, or Boolean ones, and the
\sphinxstyleemphasis{quantitative} ones.

A qualitative condition is \(W \subseteq \Paths_\omega\): it
separates winning from losing plays, in other words a play which belongs
to \(W\) is winning and otherwise it is losing. We also say that the play
satisfies \(W\). In the zero sum context a play which is losing for Eve is
winning for Adam, so Adam’s condition is \(\Paths_\omega \setminus W\).

A quantitative condition is \(f : \Paths_\omega \to \Rinfty\): it
assigns a real value (or plus or minus infinity) to a play, which can be
thought of as a payoff or a score. In the zero sum context Eve wants to
maximise while Adam wants to minimise the outcome.

Often we define \(W\) as a subset of \(V^\omega\) and \(f\) as
\(f : V^\omega \to \Rinfty\), since \(\Paths_\omega\) is included in
\(V^\omega\).


\subsection{Objectives}
\label{\detokenize{1_Introduction/simple:objectives}}\label{\detokenize{1_Introduction/simple:subsec-objectives}}
To reason about classes of games with the same conditions, we introduce
the notions of objectives and colouring functions. An objective
and a colouring function together induce a condition. The main point is
that \sphinxstyleemphasis{objectives are independent of the arenas}, so we can speak of the
class of conditions induced by a given objective, and by extension a
class of games induced by a given objective, for instance parity games.

We fix a set \(C\) of colours. A qualitative objective is
\(\Omega \subseteq C^\omega\), and a quantitative objective is a
function \(\Phi : C^\omega \to \Rinfty\).

The link between an arena and an objective is given by a colouring
function \(\col : V \to C\) labelling vertices of the graph by
colours. We extend \(\col\) componentwise to induce
\(\col : \Paths_\omega \to C^\omega\) mapping plays to sequences of
colours:
\(\col(v_0 v_1 \dots) = \col(v_0)\ \col(v_1) \dots\)

A qualitative objective \(\Omega\) and a colouring function \(\col\) induce a
qualitative condition \(\Omega[\col]\) defined by:
\begin{equation*}
\begin{split}\Omega[\col] = \set{\play \in \Paths_\omega : \col(\play) \in \Omega}.\end{split}
\end{equation*}
When \(\col\) is clear from the context we sometimes say that a play
\(\play\) satisfies \(\Omega\) but the intended meaning is that \(\play\)
satisfies \(\Omega[\col]\), equivalently that \(\col(\play) \in \Omega\).

Similarly, a quantitative objective \(\Phi : C^\omega \to \Rinfty\) and a
colouring function \(\col\) induce a quantitative condition
\(\Phi[\col] : \Paths_\omega \to \Rinfty\) defined by:
\begin{equation*}
\begin{split}\Phi[\col](\play) = \Phi(\col(\play)).\end{split}
\end{equation*}
In our definition the colouring function labels vertices. Another more
general definition would label edges, and yet another relaxation would
be to allow partial functions, meaning that some vertices (or edges) are
not labelled by a colour. In most cases the variants are all (in some
sense) equivalent; whenever we use a different definition we will make
it explicit by referring for instance to edge colouring functions or
partial colouring functions.


\subsection{Games}
\label{\detokenize{1_Introduction/simple:games}}\label{\detokenize{1_Introduction/simple:subsec-games}}
We can now give the following definitions.
\begin{itemize}
\item {} 
A graph is a tuple \(G = (V,E)\) where \(V\) is a set of vertices and \(E\) is a set of edges.

\item {} 
An arena is a tuple \(\arena = (G,\VE,\VA)\) where \(G\) is a graph over the set of vertices \(V\) and \(V = \VE \uplus \VA\).

\item {} 
A colouring function is a function \(\col : V \to C\) where \(C\) is a set of colours.

\item {} 
A qualitative condition is \(W \subseteq \Paths_\omega\).

\item {} 
A qualitative objective is a subset \(\Omega \subseteq C^\omega\). A colouring function \(\col\) and a qualitative objective \(\Omega\) induce a qualitative condition \(\Omega[\col]\).

\item {} 
A qualitative game \(\game\) is a tuple \((\arena,W)\) where \(\arena\) is an arena and \(W\) a qualitative condition.

\item {} 
A quantitative condition is \(f : \Paths_\omega \to \Rinfty\).

\item {} 
A quantitative objective \(\Phi\) is a function \(\Phi : C^\omega \to \Rinfty\). A colouring function \(\col\) and a quantitative objective \(\Phi\) induce a quantitative condition \(\Phi[\col]\).

\item {} 
A quantitative game \(\game\) is a tuple \((\arena,f)\) where \(\arena\) is an arena and \(f\) a quantitative condition.

\end{itemize}

To be specific, the definition above is for \(2\)\sphinxhyphen{}player zero sum turn
based perfect information games. As a convention we use the condition to
qualify games, so for instance “parity games” are games equipped with a
parity condition. This extends to graphs: we speak of a “graph with
condition \(W\)” for a graph equipped with a condition \(W\), and for
instance a “mean payoff graph” if \(W\) is a mean payoff condition.

We often introduce notations implicitly: for instance when we introduce
a qualitative game \(\Game\) without specifying the arena and the
condition, it is understood that the arena is \(\arena\) and the condition
\(W\).

We always implicitly take the point of view of Eve. Since we consider
zero sum games we can easily reverse the point of view by considering
the qualitative game \((\arena,\Paths_\omega \setminus W)\) and the
qualitative game \((\arena,-f)\). Indeed for the latter Adam wants to
minimise \(f\), which is equivalent to maximising \(-f\). The term zero sum
comes from this: the total outcome for the two players is \(f + (-f)\),
meaning zero.

Unless otherwise stated we assume that graphs are finite, meaning that
there are finitely many vertices (hence finitely many edges). We
equivalently say that the arena or the game is finite. will study games
over infinite graphs.


\subsection{Winning in qualitative games}
\label{\detokenize{1_Introduction/simple:winning-in-qualitative-games}}\label{\detokenize{1_Introduction/simple:subsec-qualitative-games}}
Now that we have the definitions of a game we can ask the main question:
given a game \(\game\) and a vertex \(v\), who wins \(\game\) from \(v\)?

Let \(\game\) be a qualitative game and \(v\) a vertex. A strategy \(\sigma\)
for Eve is called winning from \(v\) if every play starting from
\(v\) consistent with \(\sigma\) is winning, \sphinxstyleemphasis{i.e.} satisfies \(W\). Another
common terminology is that \(\sigma\) ensures \(W\). In that case we say
that Eve has a winning strategy from \(v\) in \(\game\), or equivalently
that Eve wins \(\game\) from \(v\). This vocabulary also applies to Adam:
for instance a strategy \(\tau\) for Adam is called winning from
\(v\) if every play starting from \(v\) consistent with \(\tau\) is losing,
\sphinxstyleemphasis{i.e.} does not satisfy \(W\).

We let \(\WE(\game)\) denote the set of vertices \(v\) such that Eve wins
\(\game\) from \(v\), it is called winning region, or sometimes
winning set. A vertex in \(\WE(\game)\) is said winning for Eve. The
analogous notation for Adam is \(\WA(\game)\).

We say that a strategy is optimal if it is winning from all
vertices in \(\WE(\game)\).

\begin{sphinxadmonition}{note}{Lemma}

For all qualitative games \(\game\) we have
\(\WE(\game) \cap \WA(\game) = \emptyset\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

Assume for the sake of contradiction that both players have a
winning strategy from \(v\), then \(\pi^{v}_{\sigma,\tau}\) would both
satisfy \(W\) and not satisfy \(W\), a contradiction.
\end{sphinxadmonition}

It is however not clear that for every vertex \(v\), \sphinxstyleemphasis{some} player has a
winning strategy from \(v\), which symbolically reads
\(\WE(\game) \cup \WA(\game) = V\). One might imagine that if Eve picks a
strategy, then Adam can produce a counter strategy beating Eve’s
strategy, and vice versa, if Adam picks a strategy, then Eve can come up
with a strategy winning against Adam’s strategy. A typical example would
be rock\sphinxhyphen{}paper\sphinxhyphen{}scissors (note that this is a concurrent game, meaning the
two players play simultanously, hence it does not fit in the definitions
given so far), where neither player has a winning strategy.

Whenever \(\WE(\game) \cup \WA(\game) = V\), we say that the game is
determined. Being determined can be understood as follows: the
outcome can be determined before playing assuming both players play
optimally since one of them can ensure to win whatever is the strategy
of the opponent.

\begin{sphinxadmonition}{note}{Theorem}

Qualitative games with Borel conditions are determined.
\end{sphinxadmonition}

The definition of Borel sets goes beyond the scope of this book. Suffice
to say that all conditions studied in this book are (very simple)
examples of Borel sets, implying that our qualitative games are all
determined (as long as we consider perfect infomation and turn based
games, the situation will change with more general models of games).


\subsection{Computational problems for qualitative games}
\label{\detokenize{1_Introduction/simple:computational-problems-for-qualitative-games}}\label{\detokenize{1_Introduction/simple:subsec-computational-problems-for-qualitative-games}}
We identify three computational problems. The first is that of
solving a game, which is the simplest one and since it induces a
decision problem, allows us to make complexity theoretic statements.

For qualitative games, “solving the game” means solving the following
decision problem:

\begin{sphinxadmonition}{note}{Solving a qualitative game}

A “qualitative game” \(\game\) and a vertex \(v\)

Does Eve win \(\game\) from \(v\)?
\end{sphinxadmonition}

The second problem extends the previous one: most algorithms solve games
for all vertices at once instead of only for the given initial vertex.
This is called computing the winning regions.

For qualitative games, “computing the winning regions” means solving the
following computational task:

The third problem is constructing a winning strategy.

For qualitative games, “constructing a winning strategy” means solving
the following computational task:

We did not specify how the winning regions or the winning strategies are
represented, this will depend on the types of games we consider.


\subsection{Values in quantitative games}
\label{\detokenize{1_Introduction/simple:values-in-quantitative-games}}\label{\detokenize{1_Introduction/simple:subsec-values-in-quantitative-games}}
Let \(\game\) be a quantitative game and \(v\) a vertex. Given \(x \in \R\)
called a threshold, we say that a strategy \(\sigma\) for Eve
ensures \(x\) from \(v\) if every play \(\pi\) starting from \(v\)
consistent with \(\sigma\) has value at least \(x\) under \(f\), \sphinxstyleemphasis{i.e.}
\(f(\play) \ge x\). In that case we say that Eve has a strategy ensuring
\(x\) in \(\game\) from \(v\).

Note that by doing so we are actually considering a qualitative game in
disguise, where the qualitative condition is the set of plays having
value at least \(x\) under \(f\). Formally, a quantitative condition \(f\) and
a threshold \(x\) induce a qualitative condition
\begin{equation*}
\begin{split}f_{\ge x} = \set{\play \in \Paths_\omega \mid f(\play) \ge x}.\end{split}
\end{equation*}
Analogously, we say that a strategy \(\tau\) for Adam ensures \(x\)
from \(v\) if every play \(\play\) starting from \(v\) consistent with \(\tau\)
has value at most \(x\) under \(f\), \sphinxstyleemphasis{i.e.} \(f(\play) \le x\).

We let \(\ValueE^{\game}(v)\) denote the quantity
\begin{equation*}
\begin{split}\sup_{\sigma} \inf_{\tau} f(\play_{\sigma,\tau}^{v}),\end{split}
\end{equation*}
where \(\sigma\) ranges over all strategies of Eve and \(\tau\) over all strategies of Adam. We also write
\(\ValueE^{\sigma}(v) = \inf_{\tau} f(\play_{\sigma,\tau}^{v})\) so that
\(\ValueE^{\game}(v) = \sup_{\sigma} \ValueE^\sigma(v)\). This is called
the value of Eve in the game \(\game\) from \(v\), and represents the best
outcome that she can ensure against any strategy of Adam. Note that
\(\ValueE^{\game}(v)\) is either a real number, \(\infty\), or \(-\infty\).

A strategy \(\sigma\) such that \(\ValueE^\sigma(v) = \ValueE^{\game}(v)\)
is called optimal from \(v\), and it is simply optimal if the
equality holds for all vertices. Equivalently, \(\sigma\) is optimal from
\(v\) if for every play \(\play\) consistent with \(\sigma\) starting from \(v\)
we have \(f(\play) \ge \ValueE^{\game}(v)\).

There may not exist optimal strategies which is why we introduce the
following notion. For \(\varepsilon > 0\), a strategy \(\sigma\) such that
\(\ValueE^\sigma(v) \ge \ValueE^{\game}(v) - \varepsilon\) is called
\(\varepsilon\)\sphinxhyphen{}optimal. If \(\ValueE^{\game}(v)\) is finite there
exist \(\varepsilon\)\sphinxhyphen{}optimal strategies for any \(\varepsilon > 0\).

Symmetrically, we let \(\ValueA^{\game}(v)\) denote
\begin{equation*}
\begin{split}\inf_{\tau} \sup_{\sigma} f(\play_{\sigma,\tau}^{v}).\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Lemma}

For all quantitative games \(\game\) and vertex \(v\) we have
\(\ValueE^{\game}(v) \le \ValueA^{\game}(v)\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

For any function \(F : X \times Y \to \Rinfty\), we have
\begin{equation*}
\begin{split}\sup_{x \in X} \inf_{y \in Y} F(x,y) \le \inf_{y \in Y} \sup_{x \in X} F(x,y).\end{split}
\end{equation*}\end{sphinxadmonition}

If this inequality is an equality, we say that the game \(\game\) is
\sphinxstyleemphasis{determined} in \(v\), and let \(\Value^{\game}(v)\) denote the value in the
game \(\game\) from \(v\) and \(\Value^\sigma(v)\) for
\(\inf_{\tau} f(\play_{\sigma,\tau}^{v})\). Similarly as for the
qualitative case, being determined can be understood as follows: the
outcome can be determined before playing assuming both players play
optimally, and in that case the outcome is the value.

We say that a quantitative objective \(f : C^\omega \to \Rinfty\) is Borel
if for all \(x \in \R\), the qualitative objective
\(f_{\ge x} \subseteq C^\omega\) is a Borel set.

\begin{sphinxadmonition}{note}{Theorem}

Quantitative games with Borel
conditions are determined, meaning that for all quantitative games
\(\game\) we have \(\ValueE^{\game} = \ValueA^{\game}\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

If \(\ValueE^{\game}(v) = \infty\) then thanks to the inequality
above \(\ValueA^{\game}(v) = \infty\) and the equality holds. Assume
\(\ValueE^{\game}(v) = -\infty\) and let \(r\) be a real number. (The
argument is actually the same as for the finite case but for the sake of
clarity we treat them independently.) We consider \(f_{\ge r}\). By
definition, this a qualitative Borel condition, so implies that it is
determined. Since Eve cannot have a winning strategy for \(f_{\ge r}\), as
this would contradict the definition of \(\ValueE^{\game}(v)\), this
implies that Adam has a winning strategy for \(f_{\ge r}\), meaning a
strategy \(\tau\) such that every play \(\play\) starting from \(v\)
consistent with \(\tau\) satisfy \(f(\play) \< r\).
In other words, \(\ValueA^{\tau}(v) = \sup_{\sigma} f(\play_{\sigma,\tau}^{v}) \le r\),
which implies that \(\ValueA^{\game}(v) \le r\). Since this is true for
any real number \(r\), this implies \(\ValueA^{\game}(v) = -\infty\).

Let us now assume that \(x = \ValueE^{\game}(v)\) is finite and let
\(\varepsilon > 0\). We consider \(f_{\ge x + \varepsilon}\). By definition,
this a qualitative Borel condition, so implies that it is determined.
Since Eve cannot have a winning strategy for \(f_{\ge x + \varepsilon}\),
as this would contradict the definition of \(\ValueE^{\game}(v)\), this
implies that Adam has a winning strategy for \(f_{\ge x + \varepsilon}\),
meaning a strategy \(\tau\) such that every play \(\play\) starting from \(v\)
consistent with \(\tau\) satisfy \(f(\play) < x + \varepsilon\). In other
words,
\(\ValueA^{\tau}(v) = \sup_{\sigma} f(\play_{\sigma,\tau}^{v}) \le x + \varepsilon\),
which implies that \(\ValueA^{\game}(v) \le x + \varepsilon\). Since this
is true for any \(\varepsilon > 0\), this implies
\(\ValueA^{\game}(v) \le \ValueE^{\game}(v)\). As we have seen the
converse inequality holds, implying the equality.
\end{sphinxadmonition}

Note that this determinacy result does not imply the existence of
optimal strategies.


\subsection{Computational problems for quantitative games}
\label{\detokenize{1_Introduction/simple:computational-problems-for-quantitative-games}}\label{\detokenize{1_Introduction/simple:subsec-computational-problems-for-quantitative-games}}
As for qualitative games, we identify different computational problems.
The first is solving the game.

For quantitative games, “solving the game” means solving the following
decision problem:

\begin{sphinxadmonition}{note}{Decision problem}

A “qualitative game” \(\game\) and a vertex \(v\)

Does Eve win \(\game\) from \(v\)?
\end{sphinxadmonition}

A very close problem is the value problem.

\begin{sphinxadmonition}{note}{Decision problem}

A “qualitative game” \(\game\) and a vertex \(v\)

Does Eve win \(\game\) from \(v\)?
\end{sphinxadmonition}

For quantitative games, “solving the value problem” means solving the
following decision problem:

The two problems of solving a game and the value problem are not
quite equivalent: they become equivalent if we assume the existence of
optimal strategies.

The value problem is directly related to computing the
value.

For quantitative games, “computing the value” means solving the
following computational task:

What computing the value means may become unclear if the value is
not a rational number, making its representation complicated. Especially
in this case, it may be enough to approximate the value, which is indeed
what the value problem gives us: by repeatingly applying an
algorithm solving the value problem one can approximate the value to any
given precision, using a binary search.

\begin{sphinxadmonition}{note}{Lemma}

If there exists an algorithm \(A\) for solving the value problem of a
class of games, then there exists an algorithm for approximating the
value of games in this class within precision \(\varepsilon\) using
\(\log(\frac{1}{\varepsilon})\) calls to the algorithm \(A\).
\end{sphinxadmonition}

The following problem is global, in the same way as computing the
winning regions.

For quantitative games, “computing the value function” means solving the
following computational task:

\begin{sphinxadmonition}{note}{Decision problem}

A “qualitative game” \(\game\) and a vertex \(v\)

Does Eve win \(\game\) from \(v\)?
\end{sphinxadmonition}

Finally, we are sometimes interested in constructing optimal strategies
provided they exist.

For quantitative games, “constructing an optimal strategy” means solving
the following computational task:

A close variant is to construct \(\varepsilon\)\sphinxhyphen{}optimal strategies,
usually with \(\varepsilon\) given as input.

(1\sphinxhyphen{}subsec:prefix\sphinxhyphen{}independent\sphinxhyphen{}objectives)


\subsection{Prefix independent objectives}
\label{\detokenize{1_Introduction/simple:prefix-independent-objectives}}
A qualitative objective \(\Omega\) is:
\begin{itemize}
\item {} 
closed under adding prefixes if for every finite sequence
\(\rho\) and for every infinite sequence \(\rho'\), if
\(\rho' \in \Omega\) then \(\rho \rho' \in \Omega\);

\item {} 
closed under removing prefixes if for every finite sequence
\(\rho\) and for every infinite sequence \(\rho'\), if
\(\rho \rho' \in \Omega\) then \(\rho' \in \Omega\);

\item {} 
prefix independent if it is closed under both adding and
removing prefixes; in other words whether a sequence satisfies
\(\Omega\) does not depend upon finite prefixes.

\end{itemize}

Let \(\play\) be a finite play consistent with \(\sigma\), we write
\(\sigma_{\mid \play}\) for the strategy defined by
\begin{equation*}
\begin{split}\sigma_{\mid \play}(\play') = \sigma(\play \play').\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

Let \(\Game\) be a qualitative game with objective \(\Omega\) closed under removing prefixes,
\(\sigma\) a winning strategy from \(v\), and \(\play\) a finite play
consistent with \(\sigma\) starting from \(v\). Then \(\sigma_{\mid \play}\)
is winning from \(v' = \last(\play)\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

Let \(\play'\) be an infinite play consistent with
\(\sigma_{\mid \play}\) from \(v'\), then \(\play \play'\) is an infinite play
consistent with \(\sigma\) starting from \(v\), implying that it is winning,
and since \(\Omega\) is closed under removing prefixes the play \(\play'\)
is winning. Thus \(\sigma_{\mid \play}\) is winning from \(v'\).
\end{sphinxadmonition}

Let \(\Game\) be a qualitative game with objective \(\Omega\) closed under
removing prefixes and \(\sigma\) a winning strategy from \(v\). Then all
vertices reachable from \(v\) by a play consistent with \(\sigma\) are
winning.

In other words, when playing a winning strategy the play does not leave
the winning region.

Similarly, a quantitative objective \(\Phi\) is:
\begin{itemize}
\item {} 
monotonic under adding prefixes if for every finite sequence
\(\rho\) and for every infinite sequence \(\rho'\) we have
\(\Phi(\rho') \le \Phi(\rho \rho')\);

\item {} 
monotonic under removing prefixes if for every finite
sequence \(\rho\) and for every infinite sequence \(\rho'\) we have
\(\Phi(\rho') \ge \Phi(\rho \rho')\);

\item {} 
prefix independent if it is monotonic under both adding and
removing prefixes.

\end{itemize}

The fact above extends to quantitative objectives with the same proof.

\begin{sphinxadmonition}{note}{Fact}

Let \(\Game\) be a
quantitative game with objective \(\Phi\) monotonic under removing
prefixes, \(\sigma\) a strategy ensuring \(x\) from \(v\), and \(\play\) a
finite play consistent with \(\sigma\) starting from \(v\). Then
\(\sigma_{\mid \play}\) ensures \(x\) from \(v' = \last(\play)\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

Let \(\play'\) be an infinite play consistent with
\(\sigma_{\mid \play}\) from \(v'\), then \(\play \play'\) is an infinite play
consistent with \(\sigma\) starting from \(v\), implying that
\(\Phi(\play \play') \ge x\), and since \(\Phi\) is monotonic under removing
prefixes this implies that \(\Phi(\play') \ge x\). Thus
\(\sigma_{\mid \play}\) ensures \(x\) from \(v'\).
\end{sphinxadmonition}

Let \(\Game\) be a quantitative game with objective \(\Phi\) monotonic under
removing prefixes and \(\sigma\) an optimal strategy from \(v\). Then for
all vertices \(v'\) reachable from \(v\) by a play consistent with \(\sigma\)
we have \(\val^{\game}(v) \le \val^{\game}(v')\).

In other words, when playing an optimal strategy the value is
non\sphinxhyphen{}decreasing along the play.


\section{References}
\label{\detokenize{1_Introduction/references:references}}\label{\detokenize{1_Introduction/references:chap-references}}\label{\detokenize{1_Introduction/references::doc}}
The study of games, usually called game theory, has a very long history rooted in mathematics, logic, and economics, among other fields.
Foundational ideas and notions emerged from set theory with for instance backward induction by Zermelo \sphinxcite{1_Introduction/references:id40},
and topology with determinacy results by Martin \sphinxcite{1_Introduction/references:id33} (stated as \textbackslash{}cref\{1\sphinxhyphen{}thm:borel\_determinacy\} in this chapter),
and Banach\sphinxhyphen{}Mazur and Gale\sphinxhyphen{}Stewart games \sphinxcite{1_Introduction/references:id28}.

The topic of this book is a small part of game theory: we focus on infinite duration games played on graphs.
In this chapter we defined deterministic games, meaning games with no source of randomness, which will be the focus of \textbackslash{}cref\{part:classic\}.
\textbackslash{}Cref\{part:stochastic\} introduces stochastic games, which were initially studied in mathematics.
We refer to\textasciitilde{}\textbackslash{}cref\{6\sphinxhyphen{}sec:references\} for more bibliographic references on stochastic games,
and focus in this chapter on references for deterministic games.

The model presented in this chapter emerged from the study of automata theory and logic, where it is used as a tool for various purposes.
Let us first discuss the role of games in two contexts:
for solving the synthesis problem of reactive systems and for automata and logic over infinite trees.

The synthesis problem for non\sphinxhyphen{}terminating reactive systems, sometimes called Church’s problem,
was formulated in general terms by Church \sphinxcite{1_Introduction/references:id23}\sphinxcite{1_Introduction/references:id24}:
from a specification of a step\sphinxhyphen{}by step transformation of an input stream given in some logical formalism,
construct a system satisfying the specification.
The first published paper solving Church’s problem for monadic second\sphinxhyphen{}order logic was written by Büchi and Landweber \sphinxcite{1_Introduction/references:id21}, following a paper by Landweber \sphinxcite{1_Introduction/references:id32} (then Büchi’s PhD student) focussing on solving games.
However, the idea of casting the synthesis problem as a game between a system and its environment is due to McNaughton:
in the technical report \sphinxcite{1_Introduction/references:id34} McNaughton attempted to give a solution to the synthesis problem using games, initiating many of the most important ideas for analysing games.
Unfortunately the proof contained an error which Landweber detected and communicated to McNaughton,
who then decided to let Landweber publish his complete solution.
One of the most difficult step in the solution of Church’s problem for monadic second\sphinxhyphen{}order logic by Büchi and Landweber \sphinxcite{1_Introduction/references:id21} is the determinisation procedure from Büchi to Muller automata due to McNaughton \sphinxcite{1_Introduction/references:id35}.
We refer to Thomas’ survey \sphinxcite{1_Introduction/references:id36} for more details on some historical and technical aspects of the early papers on Church’s synthesis problem.

Games emerged in another aspect of automata theory: for understanding the difficult result of Rabin \sphinxcite{1_Introduction/references:id38} saying that automata over infinite trees can be effectively complemented.
This is the key step for proving Rabin’s seminal result that the monadic second\sphinxhyphen{}order theory of the infinite binary tree is decidable.
The celebrated paper of Gurevich and Harrington \sphinxcite{1_Introduction/references:id30} revisits Rabin’s result by reducing the complementation question to a determinacy result for games. Interestingly, they credit McNaughton for \textasciigrave{}\textasciigrave{}airing the idea’’ of using games in this context and then for exploiting it to Landweber \sphinxcite{1_Introduction/references:id32}, Büchi and Landweber \sphinxcite{1_Introduction/references:id21}, and Büchi \sphinxcite{1_Introduction/references:id22}.

Both lines of work have been highly influential in automata theory and logic;
we refer to the reference section in\textasciitilde{}\textbackslash{}cref\{2\sphinxhyphen{}chap:regular\} for more bibliographic references on this connection.
They bind automata theory and logic to the study of games on graphs and provide motivations and questions many of which are still open today.

Beyond these two examples there are many applications of games in theoretical computer science and logic in particular.
The following quote is due to Hodges \sphinxcite{1_Introduction/references:id31}:

\textasciigrave{}\textasciigrave{}An extraordinary number of basic ideas in model theory can be expressed in terms of games.’’

Let us mention model checking games, which are used for checking whether a model satisfies a formula.
They often form both a theoretical tool for understanding the model checking problem and proving its properties, as well as an algorithmic backend for effectively deciding properties of a logical formalism (we refer to \sphinxcite{1_Introduction/references:id29} for a survey on model checking games).
Another important construction of a game for understanding logical properties is the Ehrenfeucht\sphinxhyphen{}Fraïssé games \sphinxcite{1_Introduction/references:id25}\sphinxcite{1_Introduction/references:id26}\sphinxcite{1_Introduction/references:id27} whose goal is to determine whether two models are equivalent against a logical formalism.




\chapter{Regular Games}
\label{\detokenize{2_Regular/main:regular-games}}\label{\detokenize{2_Regular/main:chap-regular}}\label{\detokenize{2_Regular/main::doc}}

\chapter{Parity Games}
\label{\detokenize{3_Parity/main:parity-games}}\label{\detokenize{3_Parity/main:chap-parity}}\label{\detokenize{3_Parity/main::doc}}

\chapter{Games with Payoffs}
\label{\detokenize{4_Payoffs/main:games-with-payoffs}}\label{\detokenize{4_Payoffs/main:chap-payoffs}}\label{\detokenize{4_Payoffs/main::doc}}
\begin{sphinxthebibliography}{Fraisse5}
\bibitem[Zer13]{1_Introduction/references:id40}
Ernst Zermelo. Uber eine anwendung der mengenlehre auf die theorie des schachspiels. In \sphinxstyleemphasis{Proceedings of the International Congress of Mathematicians, ICM\textquotesingle{}13}, volume 2, 501\textendash{}504. Cambridge University Press, 1913.
\bibitem[Mar75]{1_Introduction/references:id33}
Donald A. Martin. Borel determinacy. \sphinxstyleemphasis{Annals of Mathematics}, 102(2):363\textendash{}371, 1975.
\bibitem[GS53]{1_Introduction/references:id28}
David Gale and F.M. Stewart. Infinite games with perfect information. \sphinxstyleemphasis{Annals of Mathematical Studies}, 28:245\textendash{}266, 1953.
\bibitem[Chu57]{1_Introduction/references:id23}
Alonzo Church. Applications of recursive arithmetic to the problem of cricuit synthesis. In \sphinxstyleemphasis{Summaries of the Summer Institute of Symbolic Logic}, volume I, pages 3\textendash{}50. Cornell University, 1957.
\bibitem[Chu62]{1_Introduction/references:id24}
Alonzo Church. Logic, arithmetic, and automata. In \sphinxstyleemphasis{Proceedings of the International Congress of Mathematicians}, 23\textendash{}35. 1962.
\bibitem[BuchiL69]{1_Introduction/references:id21}
J. Richard Büchi and Lawrence H. Landweber. Solving sequential conditions by finite\sphinxhyphen{}state strategies. \sphinxstyleemphasis{Transactions of the American Mathematical Society}, 138:295\textendash{}311, 1969.
\bibitem[Lan67]{1_Introduction/references:id32}
Lawrence H. Landweber. Finite state games\textendash{}a solvability algorithm for restricted second\sphinxhyphen{}order arithmetic. \sphinxstyleemphasis{Notices of the American Mathematical Society}, 14:129\textendash{}130, 1967.
\bibitem[McN65]{1_Introduction/references:id34}
Robert McNaughton. Finite\sphinxhyphen{}state infinite games. Technical Report, Massachusetts Institute of Technology, 1965.
\bibitem[McN66]{1_Introduction/references:id35}
Robert McNaughton. Testing and generating infinite sequences by a finite automaton. \sphinxstyleemphasis{Information and Computation}, 9(5):521\textendash{}530, 1966.
\bibitem[Tho09]{1_Introduction/references:id36}
Wolfgang Thomas. Facets of synthesis: revisiting Church\textquotesingle{}s problem. In \sphinxstyleemphasis{Proceedings of the International Conference on the Foundations of Software Science and Computational Structures, FoSSaCS\textquotesingle{}09}, 1\textendash{}14. 2009.
\bibitem[Rab69]{1_Introduction/references:id38}
Michael O. Rabin. Decidability of second\sphinxhyphen{}order theories and automata on infinite trees. \sphinxstyleemphasis{Transactions of the American Mathematical Society}, 141:1\textendash{}35, 1969.
\bibitem[GH82]{1_Introduction/references:id30}
Yuri Gurevich and Leo Harrington. Trees, automata, and games. In \sphinxstyleemphasis{Proceedings of the Annual ACM Symposium on Theory of Computing, STOC\textquotesingle{}82}, 60\textendash{}65. ACM Press, 1982.
\bibitem[Buchi77]{1_Introduction/references:id22}
J. Richard Büchi. Using determinancy of games to eliminate quantifiers. In \sphinxstyleemphasis{Fundamentals of Computation Theory77}, 367\textendash{}378. 1977.
\bibitem[Hod93]{1_Introduction/references:id31}
Wilfrid Hodges. \sphinxstyleemphasis{Model theory}. Volume 42 of Encyclopedia of mathematics and its applications. Cambridge University Press, 1993.
\bibitem[Gradel02]{1_Introduction/references:id29}
Erich Grädel. Model checking games. \sphinxstyleemphasis{Electronic Notes in Theoretical Computer Science}, 67:15\textendash{}34, 2002.
\bibitem[Ehr61]{1_Introduction/references:id25}
Andrzej Ehrenfeucht. An application of games to the completeness problem for formalized theories. \sphinxstyleemphasis{Comptes\sphinxhyphen{}rendus de l\textquotesingle{}Académie des Sciences}, 49:129\textendash{}141, 1961.
\bibitem[Fraisse50]{1_Introduction/references:id26}
Roland Fraïssé. Sur une nouvelle classification des systèmes de relations. In \sphinxstyleemphasis{Comptes Rendus de l\textquotesingle{}Académie des Sciences}, volume 230, 1022\textendash{}1024. 1950.
\bibitem[Fraisse53]{1_Introduction/references:id27}
Roland Fraïssé. Sur quelques classifications des systèmes de relations. In \sphinxstyleemphasis{Publications Scientifiques de l\textquotesingle{}Université d\textquotesingle{}Alger}, 35\textendash{}182. 1953.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}