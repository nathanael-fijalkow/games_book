
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mean-payoff optimality in strongly connected MDPs &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="End components" href="end_components.html" />
    <link rel="prev" title="Mean-payoff in MDPs: General properties and linear programming" href="mean_payoff_properties.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     BÃ¼chi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Markov Decision Processes
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Infinite
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../9_Timed/index.html">
   Timed Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/state_space_representation.html">
     State-Space Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/controllable_predecessor_operator.html">
     Controllable-Predecessor Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/backward_algorithm.html">
     Backward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/forward_algorithm.html">
     Forward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10_Pushdown/index.html">
   Pushdown Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/profiles.html">
     Profiles and regularity of the winning regions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/parity.html">
     Parity pushdown games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11_Counters/index.html">
   Games with Counters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/counters.html">
     Vector games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/dim1.html">
     Games in dimension one
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/avag.html">
     Asymmetric games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/resource.html">
     Resource-conscious games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/complexity.html">
     The complexity of asymmetric monotone games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multi
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12_Multiobjectives/index.html">
   Games with multiple objectives
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/mean_payoff_energy.html">
     Mean-payoff and energy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/total_payoff_shortest_path.html">
     Total-payoff and shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/beyond_worst_case.html">
     Beyond worst-case synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/percentile.html">
     Percentile queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13_Multiplayer/index.html">
   Multiplayer Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/nash_equilibria_normal_form.html">
     Nash Equilibria for games in normal form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/admissible_strategies.html">
     Admissible strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deterministic-optimality-in-strongly-connected-mdps">
   Deterministic optimality in strongly connected MDPs
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="mean-payoff-optimality-in-strongly-connected-mdps">
<span id="sec-mean-payoff-strongly-connected"></span><h1>Mean-payoff optimality in strongly connected MDPs<a class="headerlink" href="#mean-payoff-optimality-in-strongly-connected-mdps" title="Permalink to this headline">Â¶</a></h1>
<div class="math notranslate nohighlight">
\[\newcommand{\expv}{\mathbb{E}}
\newcommand{\probm}{\mathbb{P}}
\newcommand{\actions}{A}
\newcommand{\colouring}{c}
\newcommand{\probTranFunc}{\Delta}
\newcommand{\mdp}{\mathcal{M}}
\newcommand{\reachOP}{\mathcal{V}}
\newcommand{\discOP}{\mathcal{D}}
\newcommand{\lpmp}{\lp_{\mathit{mp}}}
\newcommand{\lpmpdual}{\lpmp^{\mathit{dual}}}
\newcommand{\MeanPayoffSup}{\MeanPayoff^{\;+}}
\newcommand{\MeanPayoffInf}{\MeanPayoff^{\;-}}
\newcommand{\mcprob}{P}
\newcommand{\invdist}{\vec{z}}
\newcommand{\playPay}{\textsf{p-Payoff}}
\newcommand{\stepPay}{\textsf{s-Payoff}}
\newcommand{\solvset}{S}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\vertices}{V}
\newcommand{\ing}{\textrm{In}}
\newcommand{\play}{\pi}
\newcommand{\MeanPayoff}{\mathtt{MeanPayoff}}
\newcommand{\DiscountedPayoff}{\mathtt{DiscountedPayoff}}\]</div>
<p>As shown in the previous section, the optimal solution of any of the programs <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}, \)</span>\lp_{\mathit{mp}}{\mathit{dual}} gives us an upper bound on the optimal value. In this sub-section we show that in strongly connected MDPs: a) a value of every vertex is the same; b) from a solution of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} one can extract a memoryless deterministic strategy \)</span>\sigma<span class="math notranslate nohighlight">\( whose expected mean-payoff is well defined (i.e., the preconditions of  {prf:ref}`5-lem:limit-defined` are satisfied)) and equal to the objective value of the solution. Moreover, if the solution in question is optimal, then \)</span> \sigma <span class="math notranslate nohighlight">\( is optimal for both \)</span>\textsf{p-Payoff}- and $\textsf{s-Payoff}-semantics.</p>
<div class="proof definition admonition" id="5-def:scc-mdp">
<p class="admonition-title"><span class="caption-number">Definition 162 </span> (NEEDS TITLE 5-def:scc-mdp)</p>
<div class="definition-content section" id="proof-content">
<p>An MDP is <strong>strongly connected</strong> if for each pair of vertices <span class="math notranslate nohighlight">\(u,v\)</span> there exists a strategy which, when starting in <span class="math notranslate nohighlight">\(u\)</span>, reaches <span class="math notranslate nohighlight">\(v\)</span> with a positive probability.</p>
</div>
</div><p>For the rest of this section we fix an optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}. We denote by \)</span>S the set of all vertices for which there exists action <span class="math notranslate nohighlight">\(a\)</span> s.t. <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}&gt;0.\)</span> From the shape of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} it follows that \)</span>S is non-empty and closed, and hence we can consider a sub-MDP <span class="math notranslate nohighlight">\(\mdp_{S\)</span> induced by <span class="math notranslate nohighlight">\(S. In \)</span>\mdp_{S<span class="math notranslate nohighlight">\( we then define a memoryless randomized strategy \)</span>\sigma<span class="math notranslate nohighlight">\( by putting 
\)</span><span class="math notranslate nohighlight">\(
\sigma(a\mid v)=\frac{\lpsol{x}_{(v,a)}}{\sum_{b\in A\lpsol{x}_{(v,b)}}.
\)</span>$</p>
<p>Fixing a strategy <span class="math notranslate nohighlight">\(\sigma\)</span> yields a <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(\mdp_S{\sigma}\)</span>. Markov chain can be viewed as an MDP with a single action (and hence, with no non-determinism). <span class="math notranslate nohighlight">\(\mdp_{S^\sigma\)</span> in particular can be viewed an MDP with the same vertices, edges, and colouring as <span class="math notranslate nohighlight">\(\mdp_S, but with a single action (as non-determinism was already resolved by \)</span>\sigma<span class="math notranslate nohighlight">\(). The probability of transitioning from a vertex \)</span>u<span class="math notranslate nohighlight">\( to a vertex \)</span>v<span class="math notranslate nohighlight">\( in a Markov chain is denoted by \)</span>\mcprob_{u,v}<span class="math notranslate nohighlight">\(. In \)</span>\mdp_{S^{\sigma}<span class="math notranslate nohighlight">\( we have \)</span>\mcprob_{u,v}=\sum_{a\in A \Deltav\mid u,a)\cdot\sigma(a\mid u)<span class="math notranslate nohighlight">\(, the right-hand side being computed in the original MDP \)</span>\mathcal{M}. Both <span class="math notranslate nohighlight">\(\mdp_S and \)</span>\mdp_{S^{\sigma}<span class="math notranslate nohighlight">\( have the same sets of plays and for each initial vertex, the probability measure induced by \)</span>\sigma<span class="math notranslate nohighlight">\( in \)</span>\mathcal{M} equals the probability measure arising (under the unique policy) in <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>. Hence, to prove anything about <span class="math notranslate nohighlight">\(\sigma\)</span> it suffices to analyse <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>.</p>
<blockquote>
<div><p><strong>A refresher on Markov chains.</strong></p>
</div></blockquote>
<p>We review some fundamental notions of Markov chain theory <span id="id1">[<a class="reference internal" href="references.html#id118"><span>Nor98</span></a>]</span>. A Markov chain that is strongly connected is called <strong>irreducible</strong>. The one-step transition probabilities in a Markov chain can be arranged into a square matrix <span class="math notranslate nohighlight">\(P, which has one row and one column for each vertex. The cell in the row corresponding to a vertex \)</span>u<span class="math notranslate nohighlight">\( and in the column corresponding to a vertex \)</span>v<span class="math notranslate nohighlight">\( bears the value \)</span>\mcprob_{u,v}<span class="math notranslate nohighlight">\( defined above. An easy induction shows that the matrix \)</span>Pk<span class="math notranslate nohighlight">\( contains \)</span>k<span class="math notranslate nohighlight">\(-step transition probabilities. That is, the probability of being in \)</span>v<span class="math notranslate nohighlight">\( after \)</span>k<span class="math notranslate nohighlight">\( steps from vertex \)</span>u<span class="math notranslate nohighlight">\( is equal to the \)</span>(u,v)<span class="math notranslate nohighlight">\(-cell of \)</span>Pk<span class="math notranslate nohighlight">\(, which we denote by \)</span>P{(k)}_{u,v}$.</p>
<p>A vertex <span class="math notranslate nohighlight">\(u\)</span> of a Markov chain is <strong>recurrent</strong> if, when starting from <span class="math notranslate nohighlight">\(u\)</span>, it is revisited infinitely often with probability <span class="math notranslate nohighlight">\(1\)</span>. On the other hand, if the probability that <span class="math notranslate nohighlight">\(u\)</span> is re-visited only finitely often is one, then the vertex is <strong>transient</strong>. It is known~\cite[Theorem 1.5.3]{Norris:1998} that each vertex of a finite Markov chain is either recurrent or transient, and that these two properties can be equivalently characterized as follows: vertex <span class="math notranslate nohighlight">\(u\)</span> is recurrent if and only if  <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty}P{(k)}_{u,u}=\infty\)</span>, otherwise it is transient.</p>
<p>An <strong>invariant distribution</strong> in a Markov chain with a vertex set <span class="math notranslate nohighlight">\(V is a \)</span>|V<span class="math notranslate nohighlight">\(-dimensional non-negative row vector \)</span>\vec{z} which adds up to <span class="math notranslate nohighlight">\(1\)</span> and satisfies $ \vec{z}cdot P= \vec{z}.</p>
<p>The following lemma holds for arbitrary finite Markov chains.</p>
<div class="proof lemma admonition" id="lemma-1">
<p class="admonition-title"><span class="caption-number">Lemma 163 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>\label{5-lem:MC-inv-rec}
Let <span class="math notranslate nohighlight">\(\vec{z} be an invariant distribution and \)</span>v<span class="math notranslate nohighlight">\( a vertex such that \)</span>\invdist_v &gt; 0<span class="math notranslate nohighlight">\(. Then \)</span>v$ is recurrent.</p>
<p>\label{5-lem:MC-inv-rec}
Let <span class="math notranslate nohighlight">\(\vec{z} be an invariant distribution and \)</span>v<span class="math notranslate nohighlight">\( a vertex such that \)</span>\invdist_v &gt; 0<span class="math notranslate nohighlight">\(. Then \)</span>v$ is recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(n\)</span> be the number of vertices in the chain and <span class="math notranslate nohighlight">\(p_{\min}\)</span> the minimum non-zero entry of <span class="math notranslate nohighlight">\(P.
Assume, for the sake of contradiction, that \)</span>v<span class="math notranslate nohighlight">\( is transient. We show that in such a case, for each vertex \)</span>u<span class="math notranslate nohighlight">\( it holds \)</span>\lim_{k\rightarrow\infty} P{(k)}<em>{u,v} = 0<span class="math notranslate nohighlight">\(. For \)</span>u=v<span class="math notranslate nohighlight">\( this is immediate, since the sum \)</span>\sum</em>{k=0}^{\infty}P{(k)}<em>{v,v}<span class="math notranslate nohighlight">\( converges for  transient \)</span>v<span class="math notranslate nohighlight">\(. Otherwise, let \)</span>f</em>{u,v,i}<span class="math notranslate nohighlight">\( be the probability that a play starting in \)</span>u<span class="math notranslate nohighlight">\( visits \)</span>v<span class="math notranslate nohighlight">\( for the **first time** in exactly \)</span>i<span class="math notranslate nohighlight">\( steps. Then \)</span>P{(k)}<em>{u,v}=\sum</em>{i=0}^k f_{u,v,i}\cdot P{(k-i)}<em>{v,v}<span class="math notranslate nohighlight">\(. Now when starting in a vertex from which \)</span>v<span class="math notranslate nohighlight">\( is reachable with a positive probability, at least one of the following events happens with probability \)</span>\geq p</em>{\min}^n<span class="math notranslate nohighlight">\( in the first \)</span>n<span class="math notranslate nohighlight">\( steps: either we reach a vertex from which \)</span>v<span class="math notranslate nohighlight">\( is not reachable with positive probability, or we reach \)</span>v<span class="math notranslate nohighlight">\(. If neither of the events happens, we are, after \)</span>n<span class="math notranslate nohighlight">\( steps, still in a vertex from which \)</span>v<span class="math notranslate nohighlight">\( can be reached with a positive probability. In such a case, the argument can be inductively repeated (analogously to the proof of  {prf:ref}`5-thm:as-char`) to show that \)</span>f_{u,v,i}\leq (1-p_{\min}^n)^{\lfloor\frac{i}{n}\rfloor}\leq (1-p_{\min}^n)^{\frac{i-n}{n}}$.</p>
<p>Since <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty}P{(k)}_{v,v}\)</span> converges, for each <span class="math notranslate nohighlight">\(\eps&gt;0\)</span> there exists <span class="math notranslate nohighlight">\(j_\eps\)</span> such that <span class="math notranslate nohighlight">\(\sum_{i=j_{\eps}}^{\infty}P{(i)}_{v,v} &lt; \frac{\eps}{2}\)</span>. Similarly, there exists <span class="math notranslate nohighlight">\(\ell_\eps\)</span> such that
$<span class="math notranslate nohighlight">\(
\sum_{i=\ell_{\eps}}^{\infty}{(1-p_{\min}^n)^{\frac{i-n}{n}}} = \frac{(1-p_{\min}^n)^{\frac{\ell_\eps}{n}}}{\left(1-(1-p_{\min}^n)^{\frac{1}{n}}\right)\cdot(1-p_{\min}^n)}&lt; \frac{\eps}{2},
\)</span><span class="math notranslate nohighlight">\(
 and hence \)</span>\sum_{i=\ell_{\eps}}^{\infty} f_{u,v,i}&lt; \frac{\eps}{2}.$</p>
<p>Now we put <span class="math notranslate nohighlight">\(m_{\eps}=\max\{j_\eps,\ell_\eps\}\)</span>. For any <span class="math notranslate nohighlight">\(k\geq 2m_{\eps}\)</span> we have <span class="math notranslate nohighlight">\(P{(k)}_{u,v}=\sum_{i=0}^k f_{u,v,i}\cdot P{(k-i)}_{v,v} \leq \sum_{i=m_{\eps}}^{k}f_{u,v,i} + \sum_{i=0}^{m_{\eps}}P{(k-i)}_{v,v}\leq\sum_{i=m_{\eps}}^{k}f_{u,v,i} + \sum_{i=m_{\eps}}^{k}P{(i)}_{v,v}&lt;\eps\)</span> (note that all the series involved are non-negative). This proves that <span class="math notranslate nohighlight">\(P{(k)}_{u,v}\)</span> vanishes in the limit.</p>
<p>Finally, we derive the contradiction. Since <span class="math notranslate nohighlight">\(\vec{z} satisfies \)</span>\vec{z}cdot P= \vec{z}, we also have <span class="math notranslate nohighlight">\(\vec{z}cdot Pk = \vec{z} for all \)</span>k<span class="math notranslate nohighlight">\(. Hence, the \)</span>v<span class="math notranslate nohighlight">\(-component of \)</span>\vec{z}cdot Pk<span class="math notranslate nohighlight">\( is equal to \)</span>\invdist_v&gt;0<span class="math notranslate nohighlight">\(. But as shown above, the \)</span>v<span class="math notranslate nohighlight">\(-column of \)</span>Pk<span class="math notranslate nohighlight">\( converges to the all-zero vector as \)</span>k\rightarrow \infty<span class="math notranslate nohighlight">\(, so also \)</span>(\vec{z}cdot Pk)_v$ vanishes in the limit, a contradiction.</p>
</div>
<blockquote>
<div><p><strong>Towards the optimality of <span class="math notranslate nohighlight">\( \sigma \)</span>.</strong></p>
</div></blockquote>
<p>We now turn back to the chain <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>, where the memoryless strategy <span class="math notranslate nohighlight">\( \sigma \)</span> is obtained from the optimal solution of <span class="math notranslate nohighlight">\( \lp_{\mathit{mp}}\)</span>. In general, <span class="math notranslate nohighlight">\( \mdp_{S^{\sigma} \)</span> does not have to be irreducible. Hence, we use the following lemma and its corollary to extract an irreducible sub-chain, to which we can apply known results of Markov chain theory.</p>
<div class="proof lemma admonition" id="5-lem:mc-rec">
<p class="admonition-title"><span class="caption-number">Lemma 164 </span> (NEEDS TITLE 5-lem:mc-rec)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bar{\vec{z}\)</span> be a vector such that for each <span class="math notranslate nohighlight">\(v\in S it holds \)</span>\bar{\vec{z}<em>v=\sum</em>{a\in A \lpsol{x}<em>{v,a}<span class="math notranslate nohighlight">\(. Then \)</span>\bar{\vec{z}<span class="math notranslate nohighlight">\( is an invariant distribution of \)</span>\mdp</em>{S^{\sigma}<span class="math notranslate nohighlight">\(. Consequently, all vertices of \)</span>\mdp_{S^{\sigma}$ are recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The first part follows directly from the fact that <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}\)</span> is a feasible solution of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}. The second part follows from {prf:ref}`5-lem:MC-inv-rec` and from the fact that \)</span>\bar\vec{z} is positive (by the definition of $S).</p>
</div>
<div class="proof corollary admonition" id="5-cor:mp-scc-extraction">
<p class="admonition-title"><span class="caption-number">Corollary 165 </span> (NEEDS TITLE 5-cor:mp-scc-extraction)</p>
<div class="corollary-content section" id="proof-content">
<p>The set <span class="math notranslate nohighlight">\(S can be partitioned into subsets \)</span>\solvset_1,\solvset_2,\dots,\solvset_m<span class="math notranslate nohighlight">\( such that each \)</span>\solvset_i<span class="math notranslate nohighlight">\( induces a strongly connected sub-chain of \)</span>\mdp_{S^{\sigma}$.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(v\inS be arbitrary and let \)</span>U_v\subseteq S be the set of all vertices reachable with positive probability from <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is reachable (in <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>) with positive probability from each <span class="math notranslate nohighlight">\(u\in U_v\)</span>: otherwise, there would be a positive probability of never revisiting <span class="math notranslate nohighlight">\(v\)</span>, a contradiction with each vertex being recurrent in <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span> ( <a class="reference internal" href="#5-lem:mc-rec">Lemma 164</a>). Hence, <span class="math notranslate nohighlight">\(U_v\)</span> induces a strongly connected sub-MDP (or sub-chain) of <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>. It is easy to show that if <span class="math notranslate nohighlight">\(U_v \neq U_w\)</span> for some <span class="math notranslate nohighlight">\(v\neq w \)</span>, then the two sets must be disjoint.</p>
</div>
<p>Hence, we can extract from <span class="math notranslate nohighlight">\(S a set \)</span>Q<span class="math notranslate nohighlight">\( inducing a strongly-connected sub-chain of \)</span>\mdp_{S^{\sigma}<span class="math notranslate nohighlight">\(, which we denote \)</span>\mathcal{M}{\sigma}_{Q}<span class="math notranslate nohighlight">\(. The set \)</span>Q<span class="math notranslate nohighlight">\( also induces a strongly connected sub-MDP of \)</span>\mathcal{M} denoted by <span class="math notranslate nohighlight">\(\mdp_Q\)</span>. The chain <span class="math notranslate nohighlight">\(\mathcal{M}{\sigma}_{Q}\)</span> arises by fixing, in <span class="math notranslate nohighlight">\(\mdp_Q\)</span>, a strategy formed by a restriction of <span class="math notranslate nohighlight">\(\sigma\)</span> to <span class="math notranslate nohighlight">\(Q\)</span>. We use the following powerful theorem to analyse <span class="math notranslate nohighlight">\(\mathcal{M}{\sigma}_{Q}\)</span>.</p>
<p>````{prf:theorem} Ergodic theorem; see Theorem~1.10.2 in <span id="id2">[<a class="reference internal" href="references.html#id118"><span>Nor98</span></a>]</span>
:label: 5-thm:ergodic
In a strongly connected Markov chain (with a finite set of vertices <span class="math notranslate nohighlight">\(V) there exists a unique invariant distribution \)</span>\vec{z}. Moreover, for every vector <span class="math notranslate nohighlight">\(\vec{h}\in \mathbb{R}{V\)</span> the following equation holds with probability 1:</p>
<div class="math notranslate nohighlight">
\[
\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{\textrm{In}\pi_i)} = \sum_{v\inV \invdist_v\cdot \vec{h}_v.
\]</div>
<p>(In particular, the limit is well-defined with probability 1).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>

We can use the Ergodic theorem to shows that the expected mean-payoff achieved by $\sigma$ in $\mdp_{Q}$ matches the optimal value of $ \lp_{\mathit{mp}}$, in a very strong sense: the probability of a play having a mean-payoff equal to this optimal value is 1 under $ \sigma $.

````{prf:theorem} NEEDS TITLE 5-cor:mp-scc-optimality
:label: 5-cor:mp-scc-optimality

Let $\sigma_Q$ be the restriction of $\sigma$ to $Q$. Then for every $v\in Q$ it holds that $\mathbb{P}{\sigma_Q}_{\mdp_Q,v}(\mathtt{MeanPayoff}{\;-}= r^*)=1$, where $r^*$ is the is the optimal value of $\lp_{\mathit{mp}}. 

</pre></div>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\( \vec{w}\in\mathbb{R}{V\timesA \)</span> be a vector sych that <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=\lpsol{x}_{(v,a)}/\sum_{(q,a)\in Q\timesA \lpsol{x}_{(q,a)}\)</span> for every <span class="math notranslate nohighlight">\((v,a)\in Q\times A, and \)</span>\vec{w}<em>{(v,a)}=0<span class="math notranslate nohighlight">\( for all other \)</span>(v,a)<span class="math notranslate nohighlight">\(. We claim that \)</span> \vec{w} <span class="math notranslate nohighlight">\( is also an optimal solution of \)</span>\lp</em>{\mathit{mp}}.</p>
<p>To prove feasibility, note that setting <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=0\)</span> for each <span class="math notranslate nohighlight">\(v\in Vsetminus Q\)</span> does not break the constraints~\eqref{5-eq:mdp-flow}. This is because <span class="math notranslate nohighlight">\(Q\)</span> induces a strongly connected sub-chain of <span class="math notranslate nohighlight">\(\mdp_{S^{\sigma}\)</span>, and hence there are no <span class="math notranslate nohighlight">\(v\in V, \)</span>u\in Vsetminus Q<span class="math notranslate nohighlight">\( such that \)</span>\lpsol{x}_{(u,a)}\cdot \Deltav\mid u,a)&gt;0$. Next,~\eqref{5-eq:mdp-flow} is invariant w.r.t. multiplication of variables by a constant, so normalizing the remaining values preserves~\eqref{5-eq:mdp-flow} and ensures that~\eqref{5-eq:mdp-freq-1} holds.</p>
<p>To prove optimality, assume that the objective value of <span class="math notranslate nohighlight">\(\vec{w}\)</span> is smaller than <span class="math notranslate nohighlight">\(r^*\)</span>. Then we can mirror the construction from the previous paragraph and produce a feasible solution <span class="math notranslate nohighlight">\({\hat{\vec{w}}_{(v,a)}}\)</span> whose <span class="math notranslate nohighlight">\((Q\timesA\)</span>-indexed components are zero and the rest are normalized components of <span class="math notranslate nohighlight">\(\lpsol{x}\)</span>. Then <span class="math notranslate nohighlight">\(r^*\)</span> is a convex combination of the objective values of <span class="math notranslate nohighlight">\(\vec{w}\)</span> and <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span>, so <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span> must have a strictly larger value than <span class="math notranslate nohighlight">\(r^*\)</span>, a contradiction with the latterâs optimality.</p>
<p>We now plug <span class="math notranslate nohighlight">\( \vec{w} \)</span> into the ergodic theorem as follows: As in <a class="reference internal" href="#5-lem:mc-rec">Lemma 164</a>, it easy to prove that setting <span class="math notranslate nohighlight">\(\invdist_v=\sum_{a\inA\vec{w}_{(v,a)}\)</span> yields an invariant distribution. Now put <span class="math notranslate nohighlight">\(\vec{h}_v=\sum_{a\inA\sigma(a\mid v)\cdot cv,a)\)</span> (<span class="math notranslate nohighlight">\( =  \sum_{w \in V \mcprob_{v,w}\cdot cv,w)\)</span>). From the Ergodic theorem we get that <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{\textrm{In}\pi_i)}\)</span> almost-surely exists and equals
\begin{align}
\sum_{v\in Q} \invdist_v\cdot \vec{h}<em>v &amp;= \sum</em>{v\in V \left(\big(\sum_{d\inA\vec{w}<em>{(v,d)}\big)\cdot \big(\sum</em>{a\inA\sigma(a\mid v)\cdot cv,a) \big)\right) \nonumber\
&amp;= \sum_{v\in Q} \left(\Bigg( \frac{\sum_{d\inA\lpsol{x}<em>{(v,d)}}{\sum\limits</em>{\substack{q\in Q\ b\in A} \lpsol{x}<em>{(q,b)}} \Bigg)\cdot \Bigg( \frac{\sum</em>{a\inA\lpsol{x}<em>{(v,a)}\cdotcv,a)}{\sum\limits</em>{d\in  A \lpsol{x}<em>{(v,d)}} \Bigg) \right) \nonumber\
&amp;= \frac{1}{\sum\limits</em>{\substack{q\in Q\ b\in A} \lpsol{x}<em>{(q,b)}}\cdot\sum\limits</em>{\substack{v\in Q\ a\inA} \lpsol{x}<em>{(v,a)}\cdot cv,a) = \sum\limits</em>{\substack{v\in Q\ a\inA} \vec{w}_{(v,a)}\cdotcv,a) =r^*.\label{5-eq:ergodic-use}
\end{align}</p>
<p>It remains to take a step from the left-hand side of~\eqref{5-eq:ergodic-use} towards the mean payoff. To this end, we construct a new Markov chain <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> from <span class="math notranslate nohighlight">\(\mdp_Q\)</span> by splitting every edge <span class="math notranslate nohighlight">\((u,v)\)</span> with a new dummy vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> (i.e., <span class="math notranslate nohighlight">\(d_{u,v}\)</span> has one edge incoming from <span class="math notranslate nohighlight">\(u\)</span> with probability <span class="math notranslate nohighlight">\(\mcprob_{u,v}\)</span> and one edge outgoing to <span class="math notranslate nohighlight">\(v\)</span> with probability <span class="math notranslate nohighlight">\(1\)</span>). In <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> we define a vector <span class="math notranslate nohighlight">\(\vec{h}'\)</span> s.t. for each vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> the vector <span class="math notranslate nohighlight">\( \vec{h}' \)</span> has the <span class="math notranslate nohighlight">\( d_{u,v} \)</span>-component equal to <span class="math notranslate nohighlight">\(cu,v)\)</span>, while the components corresponding to the original vertices are zero. It is easy to check that <span class="math notranslate nohighlight">\(\mdp_Q'\)</span>  is strongly connected and that it has an invariant distribution <span class="math notranslate nohighlight">\(\vec{z}\)</span> defined by <span class="math notranslate nohighlight">\(\vec{z}_v=\invdist_v/2\)</span> for <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(\vec{z}_{d_{u,v}}=\frac{\invdist_u\cdot\mcprob_{u,v}}{2}\)</span> for <span class="math notranslate nohighlight">\((u,v)\)</span> an edge of <span class="math notranslate nohighlight">\(\mdp_Q\)</span>.
Also, by easy induction, for each play <span class="math notranslate nohighlight">\(\pi of length \)</span>n<span class="math notranslate nohighlight">\( in \)</span>\mdp_Q<span class="math notranslate nohighlight">\( it holds \)</span>\frac{1}{n}\sum_{i=0}^{n-1}c\play_i) = \frac{1}{n}\sum_{i=0}^{2n-1}\vec{h}â<em>{\textrm{In}\play_iâ)}<span class="math notranslate nohighlight">\(, where \)</span>\pi<span class="math notranslate nohighlight">\( is the unique play in \)</span>\mdp_Qâ<span class="math notranslate nohighlight">\( obtained from \)</span>\pi by splitting edges with appropriate dummy vertices. Hence,
\begin{equation}
\label{5-eq:mc-opt-limit}
\lim</em>{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}c\play_i) = 2\cdot \lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}â<em>{\textrm{In}\play_iâ)},\end{equation} provided that both limits exist. By the ergodic theorem  applied to <span class="math notranslate nohighlight">\(\mdp_Q'\)</span>, we have that the RHS  limit in~\eqref{5-eq:mc-opt-limit} is defined with probability 1 and equal to
\begin{align*}
\underbrace{\sum</em>{v\in Q} \vec{z}<em>v \cdot \vec{h}â</em>{v}}<em>{=0} + \sum</em>{u,v\in Q} \vec{z}<em>{d</em>{u,v}}\cdot \vec{h}â<em>{d</em>{u,v}} = \frac{1}{2}\sum_{u\in Q}\invdist_u\cdot\left( \sum_{v\in Q}\mcprob_{u,v}\cdot cu,v)\right)\ =\frac{1}{2}\sum_{u\in Q} \invdist_u\cdot \vec{h}_u=\frac{r^<em>}{2},
\end{align</em>}</p>
<p>the last equality being shown above. Plugging this into~\eqref{5-eq:mc-opt-limit} yields that if a limit on the LHS (i.e., the mean payoff of a play) is well-defined with probability 1, then it is equal to <span class="math notranslate nohighlight">\(r^*\)</span> also with probability 1. But if there was a set <span class="math notranslate nohighlight">\(L\)</span> of positive probability in <span class="math notranslate nohighlight">\(\mdp_Q\)</span> with <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}c\play_i)\)</span> undefined for each <span class="math notranslate nohighlight">\(\piin L\)</span>, by splitting the plays in <span class="math notranslate nohighlight">\(L\)</span> we would obtain a positive-probability set of plays in <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> in which <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}'_{\textrm{In}\play_i')}\)</span> is also undefined, a contradiction with the ergodic theorem.</p>
</div>
<p>So far, we have constructed an optimal strategy <span class="math notranslate nohighlight">\(\sigma_Q\)</span> but only on the part <span class="math notranslate nohighlight">\(Q\)</span> of the original MDP <span class="math notranslate nohighlight">\(\mathcal{M}. To conclude the construction, we define a memoryless strategy \)</span>\sigma^<em><span class="math notranslate nohighlight">\( in \)</span>\mathcal{M} as follows: we fix a memoryless deterministic strategy <span class="math notranslate nohighlight">\(\sigma_{=1}\)</span> that is winning, from each vertex of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> for the objective of almost-sure reaching of <span class="math notranslate nohighlight">\(Q\)</span> (such a strategy exists since <span class="math notranslate nohighlight">\(\mathcal{M} is strongly connected, see also  {prf:ref}`5-thm:as-char`. Then we put \)</span>\sigma^</em>(v)=\sigma_{=1}(v)<span class="math notranslate nohighlight">\( if \)</span>v\not\in Q<span class="math notranslate nohighlight">\( and \)</span>\sigma^<em>(v)=\sigma_Q(v)<span class="math notranslate nohighlight">\( otherwise. Hence, starting in any vertex, \)</span>\sigma^</em><span class="math notranslate nohighlight">\( eventually reaches \)</span>Q<span class="math notranslate nohighlight">\( with probability 1 and then it starts behaving as \)</span>\sigma_Q$. The optimality of such a strategy follows from the prefix independence of mean payoff, as argued in the next theorem.</p>
<div class="proof theorem admonition" id="5-thm:mp-valcomp">
<p class="admonition-title"><span class="caption-number">Theorem 166 </span> (NEEDS TITLE 5-thm:mp-valcomp)</p>
<div class="theorem-content section" id="proof-content">
<p>For any sequence of numbers <span class="math notranslate nohighlight">\(c_0,c_1,\dots\)</span> and any <span class="math notranslate nohighlight">\(k\in\mathbb{N} it holds \)</span>\liminf_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}c_i = \liminf_{m\rightarrow \infty}\frac{1}{m}\sum_{i=0}^{m-1}c_{k+i}<span class="math notranslate nohighlight">\(. As a consequence, 
for every vertex \)</span>v<span class="math notranslate nohighlight">\( in \)</span>\mathcal{M} it holds <span class="math notranslate nohighlight">\(\mathbb{P}{\sigma_Q}_{\mdp_Q,v}(\mathtt{MeanPayoff}{\;-}r^*)=1,\)</span> where <span class="math notranslate nohighlight">\(r^*\)</span> is the optimal value of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}. Hence, \)</span>\mathbb{E}{\sigma^<em>}_v[\mathtt{MeanPayoff}{;-}= r^</em>$.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We have
\begin{align*}
\liminf_{n\rightarrow \infty}\frac{c_0 + \cdots c_{n-1}}{n} &amp;= \liminf_{n\rightarrow \infty}\left(\underbrace{\frac{k}{n}}<em>{\mathrlap{\text{vanishes for } n\rightarrow \infty}}\cdot\frac{c_0 + \cdots + c</em>{k-1}}{k} + \underbrace{\frac{n-k}{n}}<em>{\mathrlap{\rightarrow 1 \text{ for } n\rightarrow \infty}}\cdot\frac{c_k+\cdot+c</em>{n-1}}{n-k} \right)\
&amp;=\liminf_{m\rightarrow\infty} \frac{c_k+\dots+c_{k+m-1}}{m}.
\end{align*} A similar argument holds for <span class="math notranslate nohighlight">\(\limsup.\)</span></p>
<p>With probability 1, a play has an infinite suffix consisting of plays from <span class="math notranslate nohighlight">\(\mdp_Q^{\sigma}\)</span>, and thus also <span class="math notranslate nohighlight">\(\mathtt{MeanPayoff}{\;-} and \)</span>\mathtt{MeanPayoff}{;+} determined by this suffix. By \Cref{5-cor:mp-scc-optimality}, these quantities are equal to <span class="math notranslate nohighlight">\(r^*\)</span> with probability 1.</p>
</div>
<p>The following theorem summarizes the computational aspects.</p>
<div class="proof theorem admonition" id="5-thm:mp-rand-opt-main">
<p class="admonition-title"><span class="caption-number">Theorem 167 </span> (NEEDS TITLE 5-thm:mp-rand-opt-main)</p>
<div class="theorem-content section" id="proof-content">
<p>In a strongly connected mean-payoff MDP, one can compute, in polynomial time, a memoryless randomized strategy which is optimal from every vertex, as well as the (single) optimal value of every vertex.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We obtain, in polynomial time, an optimal solution of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}, with the optimal objective value being the optimal value of every vertex ( {prf:ref}`5-thm:mp-valcomp`). We then use this optimal solution \)</span>\lpsol{x}<span class="math notranslate nohighlight">\( to construct the strategy \)</span>\sigma<span class="math notranslate nohighlight">\( and the  Markov chain \)</span>\mdp_{S^{\sigma}<span class="math notranslate nohighlight">\(. From this chain we extract a strongly connected subset of vertices \)</span>Q<span class="math notranslate nohighlight">\( (in polynomial time, by a simple graph reachability analysis). With the subset in hand, we can construct strategies \)</span>\sigma_Q<span class="math notranslate nohighlight">\( and \)</span>\sigma_{=1}<span class="math notranslate nohighlight">\(, all polynomial-time computations (see  {prf:ref}`5-thm:as-char`). These two strategies are then combined to produce the optimal strategy \)</span>\sigma^*$.</p>
</div>
<div class="section" id="deterministic-optimality-in-strongly-connected-mdps">
<h2>Deterministic optimality in strongly connected MDPs<a class="headerlink" href="#deterministic-optimality-in-strongly-connected-mdps" title="Permalink to this headline">Â¶</a></h2>
<p>It remains to prove that we can actually compute a memoryless~<strong>deterministic</strong> strategy that is optimal in every vertex. Looking back at the construction that resulted in  <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 167</a>, we see that the optimal strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> might be randomized because the computed optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} can contain two components \)</span>(v,a)<span class="math notranslate nohighlight">\(, \)</span>(v,b)<span class="math notranslate nohighlight">\( with \)</span>a\neq b<span class="math notranslate nohighlight">\( and both \)</span>\lpsol{x}<em>{(v,a)}<span class="math notranslate nohighlight">\( and \)</span>\lpsol{x}</em>{(v,b)}$ being positive. To prove memoryless deterministic optimality, we will show that there is always an optimal solution which yields a deterministic strategy, and that such a solution can be obtained in polynomial time.</p>
<p>The previous section implicitly defined two mappings: First, a mapping <span class="math notranslate nohighlight">\(\Psi\)</span>, which maps every solution <span class="math notranslate nohighlight">\( \vec{x} \)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} to a memoryless strategy in some sub-MDP of \)</span>\mathcal{M}, by putting <span class="math notranslate nohighlight">\(\Psi(\vec{x}) = \sigma\)</span> where <span class="math notranslate nohighlight">\(\sigma(a\mid v) = \vec{x}_{(v,a)}/\sum_{b\in A\vec{x}_{(v,b)}\)</span>. Second, mapping <span class="math notranslate nohighlight">\(\Xi\)</span>, which maps each memoryless strategy <span class="math notranslate nohighlight">\(\sigma\)</span> that induces a strongly connected Markov chain to a solution <span class="math notranslate nohighlight">\(\Xi(\sigma)\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} such that \)</span>\Xi(\sigma)_{(v,a)}=\invdist_v\cdot \sigma(a\mid v)<span class="math notranslate nohighlight">\(, where \)</span>\vec{z} is the unique invariant distribution of the chain induced by <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<div class="proof lemma admonition" id="5-lem:sol-strat-correspondence">
<p class="admonition-title"><span class="caption-number">Lemma 168 </span> (NEEDS TITLE 5-lem:sol-strat-correspondence)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be the set containing exactly those solutions <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} for which the strategy  \)</span>\Psi(\vec{x})<span class="math notranslate nohighlight">\( induces a strongly connected Markov chain. Then the mappings \)</span>\Psi<span class="math notranslate nohighlight">\( and \)</span>\Xi<span class="math notranslate nohighlight">\( are bijections between \)</span>X<span class="math notranslate nohighlight">\( and the set of all memoryless strategies in some sub-MDP of \)</span>\mathcal{M} that induce a strongly connected Markov chain.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>A straightforward computation shows that <span class="math notranslate nohighlight">\(\Xi\circ\Psi\)</span> and <span class="math notranslate nohighlight">\(\Psi\circ\Xi\)</span> are identity functions on the respective sets.</p>
</div>
<div class="proof definition admonition" id="definition-7">
<p class="admonition-title"><span class="caption-number">Definition 169 </span> (NEEDS TITLE AND LABEL)</p>
<div class="definition-content section" id="proof-content">
<p>\label{5-def:pure-lp}
A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}is **pure** if for every vertex \)</span>v<span class="math notranslate nohighlight">\( there is at most one action \)</span>a<span class="math notranslate nohighlight">\( such that \)</span>\vec{x}_{(v,a)}&gt;0$.</p>
<p>\label{5-def:pure-lp}
A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}}is **pure** if for every vertex \)</span>v<span class="math notranslate nohighlight">\( there is at most one action \)</span>a<span class="math notranslate nohighlight">\( such that \)</span>\vec{x}_{(v,a)}&gt;0$.</p>
</div>
</div><p>The following lemma follows from the way in which strategies <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\sigma^*\)</span> were constructed in the previous sub-section.</p>
<div class="proof lemma admonition" id="lemma-8">
<p class="admonition-title"><span class="caption-number">Lemma 170 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>\label{5-lem:pure-lpsol}
Let <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} and denote \)</span> S = {v \in Vmid \exists a \text{ s.t. }\lpsol{x}<em>{(v,a)}&gt;0} <span class="math notranslate nohighlight">\(. Then the strategy \)</span>\sigma=\Psi(\lpsol{x})<span class="math notranslate nohighlight">\( is an MD strategy in \)</span>\mdp</em>{S<span class="math notranslate nohighlight">\(. Hence, in such a case, the strategy \)</span>\sigma^*<span class="math notranslate nohighlight">\( constructed from \)</span> \sigma <span class="math notranslate nohighlight">\( as in  {prf:ref}`5-thm:mp-rand-opt-main` is an optimal MD strategy in \)</span>\mathcal{M}.</p>
<p>\label{5-lem:pure-lpsol}
Let <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} and denote \)</span> S = {v \in Vmid \exists a \text{ s.t. }\lpsol{x}<em>{(v,a)}&gt;0} <span class="math notranslate nohighlight">\(. Then the strategy \)</span>\sigma=\Psi(\lpsol{x})<span class="math notranslate nohighlight">\( is an MD strategy in \)</span>\mdp</em>{S<span class="math notranslate nohighlight">\(. Hence, in such a case, the strategy \)</span>\sigma^*<span class="math notranslate nohighlight">\( constructed from \)</span> \sigma <span class="math notranslate nohighlight">\( as in  {prf:ref}`5-thm:mp-rand-opt-main` is an optimal MD strategy in \)</span>\mathcal{M}.</p>
</div>
</div><p>It remains to show how to find a pure optimal solution of $\lp_{\mathit{mp}}. To this end we exploit some fundamental properties of linear programs.</p>
<p>A linear program is in the <strong>standard</strong> (or equational) form if its set of constraints can be expressed as <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span>, <span class="math notranslate nohighlight">\(\vec{x}\geq 0\)</span>, where <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a vector of variables, <span class="math notranslate nohighlight">\(\vec{b}\)</span> is a non-negative vector, and <span class="math notranslate nohighlight">\(A\)</span> is a matrix of an appropriate dimension. In this notation, all the vectors are column vectors, i.e. <span class="math notranslate nohighlight">\(A\)</span> has one column per each variable. Note that <span class="math notranslate nohighlight">\(\lp_{\mathit{mp}} is a program in the standard form. A feasible solution \)</span>\vec{x}<span class="math notranslate nohighlight">\( of such a program is **basic** if the columns of \)</span>A<span class="math notranslate nohighlight">\( corresponding to variables whose value is positive in \)</span>\vec{x}<span class="math notranslate nohighlight">\( form a linearly independent set of vectors. Since the maximal number of linearly independent columns equals the maximal number of linearly independent rows (a number called a **rank** of \)</span>A<span class="math notranslate nohighlight">\(), we know that each basic feasible solution has at most as many positive entries as there are rows of \)</span>A$.</p>
<p>The next two lemmas prove some fundamental properties of basic feasible solutions.</p>
<div class="proof lemma admonition" id="5-lem:basic-cond-unique">
<p class="admonition-title"><span class="caption-number">Lemma 171 </span> (NEEDS TITLE 5-lem:basic-cond-unique)</p>
<div class="lemma-content section" id="proof-content">
<p>Assume that a linear program in a standard form has two basic feasible solutions <span class="math notranslate nohighlight">\(\vec{x},\vec{x}'\)</span> such that both solutions have the same set of non-zero components, and the cardinality of this set equals the number of equality constraints in the program. Then <span class="math notranslate nohighlight">\(\vec{x}=\vec{x}'\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Write <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span> the equational constraints of the LP.
If <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic feasible solution, then it solves the equation <span class="math notranslate nohighlight">\(A_{N} \cdot \vec{x}_N = \vec{b}\)</span>, where <span class="math notranslate nohighlight">\(A_N\)</span> (<span class="math notranslate nohighlight">\(  N\)</span> stands for non-zero) is obtained from <span class="math notranslate nohighlight">\(A\)</span> by removing all columns corresponding to zero components of <span class="math notranslate nohighlight">\(\vec{x}\)</span>, and   <span class="math notranslate nohighlight">\(\vec{x}_N\)</span> is obtained from <span class="math notranslate nohighlight">\(\vec{x}\)</span> by removing all zero components.</p>
<p>Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> has as many non-zero components as there are rows of <span class="math notranslate nohighlight">\(A\)</span>, it follows that <span class="math notranslate nohighlight">\(A_N\)</span> is a square matrix. Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic solution, <span class="math notranslate nohighlight">\(A_N\)</span> is regular (its columns are linearly independent) and <span class="math notranslate nohighlight">\(\vec{x}=A_{N}^{-1}\cdot \vec{b}\)</span> is uniquely determined by <span class="math notranslate nohighlight">\(A_N\)</span>. Repeating the same argument for <span class="math notranslate nohighlight">\(\vec{x}'\)</span> yields <span class="math notranslate nohighlight">\(\vec{x}'=A_{N}^{-1}\cdot \vec{b}= \vec{x}\)</span>.</p>
</div>
<div class="proof lemma admonition" id="5-lem:basic-sol">
<p class="admonition-title"><span class="caption-number">Lemma 172 </span> (NEEDS TITLE 5-lem:basic-sol)</p>
<div class="lemma-content section" id="proof-content">
<p>If a linear program in a standard form has an optimal solution, then it has also a basic optimal solution. Moreover, a basic optimal solution can be found in polynomial time.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>[Sketch]
The existence of a basic optimal solution is a well-known linear programming fact, e.g. the standard simplex algorithm works by traversing the set of basic feasible solutions until it finds an optimal one <span id="id3">[<a class="reference internal" href="references.html#id117"><span>Matouvsek07</span></a>]</span>. For computing an optimal basic solution, we can use one of the polynomial-time interior-point methods for linear programming, such as the path-following method <span id="id4">[<a class="reference internal" href="references.html#id114"><span>Kar84</span></a>,<a class="reference internal" href="references.html#id111"><span>Gon92</span></a>]</span>. While these methods work by traversing the interior of the polyhedron of feasible solutions, they converge, in polynomial time, to a point that is closer to the optimal basic solution than to all the other basic solutions. By a process called <strong>purification,</strong> such a point can be then converted to the closest basic solution, i.e. to the optimal one <span id="id5">[<a class="reference internal" href="references.html#id111"><span>Gon92</span></a>]</span>.</p>
</div>
<div class="proof theorem admonition" id="5-thm:lpmp-basic-dim">
<p class="admonition-title"><span class="caption-number">Theorem 173 </span> (NEEDS TITLE 5-thm:lpmp-basic-dim)</p>
<div class="theorem-content section" id="proof-content">
<p>One can find, in polynomial time, an optimal deterministic strategy in a given strongly connected  mean-payoff MDP.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>First, we use <a class="reference internal" href="#5-lem:basic-sol">Lemma 172</a> to find a basic optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> of $\lp_{\mathit{mp}}.
We check if it is pure. If yes, we are done. Otherwise,</p>
<p>there is <span class="math notranslate nohighlight">\(v\in V and two distinct actions \)</span>a,b<span class="math notranslate nohighlight">\( such that \)</span>\lpsol{x}<em>{(v,a)}&gt;0<span class="math notranslate nohighlight">\( and \)</span>\lpsol{x}</em>{(v,b)}&gt;0.<span class="math notranslate nohighlight">\( Let \)</span> S = {v \in Vmid \exists a \text{ s.t. }\lpsol{x}_{(v,a)}&gt;0} <span class="math notranslate nohighlight">\(. By~\Cref{5-cor:mp-scc-extraction}, we can partition \)</span>S into several subsets, each of which induces a strongly connected sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}. Let \)</span>Q<span class="math notranslate nohighlight">\( be a class of this partition containing \)</span>v<span class="math notranslate nohighlight">\(. We have that the optimal mean-payoff value of every vertex in \)</span>\mdp_Q<span class="math notranslate nohighlight">\( is the same as in \)</span>\mathcal{M}. This is because,
as in the beginning of the proof of~\Cref{5-cor:mp-scc-optimality}, we can transform <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> into another optimal solution of the same value as <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> which has non-zero entries only for components indexed by <span class="math notranslate nohighlight">\((q,a)\)</span> with <span class="math notranslate nohighlight">\(q\in Q\)</span>. All these computations can be easily implemented in polynomial time.</p>
<p>We argue that <span class="math notranslate nohighlight">\(Q\)</span> is a strict subset of <span class="math notranslate nohighlight">\(V. Indeed, assume that \)</span>Q=V. Then <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> induces a randomized strategy <span class="math notranslate nohighlight">\(\sigma\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}. Moreover, since \)</span>\lpsol{x}<span class="math notranslate nohighlight">\( is a basic solution, it has at most \)</span>|V+1<span class="math notranslate nohighlight">\( positive entries, and since it is non-pure, it must have exactly \)</span>n+1<span class="math notranslate nohighlight">\( positive entries, i.e.  {prf:ref}`5-lem:basic-cond-unique` is applicable to \)</span>\lpsol{x}<span class="math notranslate nohighlight">\(, since \)</span>\lp_{\mathit{mp}} has exactly <span class="math notranslate nohighlight">\(|V+1\)</span> constraints. Now we define a new strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M} by slightly changing the behaviour in \)</span>v<span class="math notranslate nohighlight">\(. To this end, choose some \)</span>\eps&gt;0<span class="math notranslate nohighlight">\( and put \)</span>\sigmaâ(a\mid v)=\sigma(a\mid v)-\eps<span class="math notranslate nohighlight">\( and \)</span>\sigmaâ(b\mid v)=\sigma(b\mid v)+\eps<span class="math notranslate nohighlight">\(; we choose \)</span>\eps<span class="math notranslate nohighlight">\( small enough so that both quantities are still non-zero. The chain \)</span>\mathcal{M}{\sigmaâ}<span class="math notranslate nohighlight">\( is still strongly connected. Now let \)</span>\vec{x}â = \Xi(\sigmaâ)<span class="math notranslate nohighlight">\(. Then \)</span>\vec{x}â<span class="math notranslate nohighlight">\( is a solution of \)</span>\lp_{\mathit{mp}} which is still basic, with a set of non-zero components being the same as in <span class="math notranslate nohighlight">\(\lpsol{x}\)</span>. At the same time, <span class="math notranslate nohighlight">\(\vec{x}'\neq \lpsol{x}\)</span>, since <span class="math notranslate nohighlight">\(\sigma\neq {\sigma'}\)</span> and <span class="math notranslate nohighlight">\(\Xi\)</span> is a bijection ( <a class="reference internal" href="#5-lem:sol-strat-correspondence">Lemma 168</a>). But this is a contradiction with  <a class="reference internal" href="#5-lem:basic-cond-unique">Lemma 171</a>.</p>
<p>Hence, <span class="math notranslate nohighlight">\(\mdp_Q\)</span> is a strict sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M} in which the value of every vertex is the same as in the original MDP. We can perform a recursive call of the aforementioned computation on \)</span>\mdp_Q<span class="math notranslate nohighlight">\( (compute basic optimal solution of \)</span>\lp_{\mathit{mp}}, check purity, possibly extract and recurse on a sub-MDP).
The depth of recursion is bounded by <span class="math notranslate nohighlight">\(|V\)</span>, so the running time is polynomial. Since each sub-MDP obtained during the recursion is non-empty, and the size of the MDPs decreases, the recursion must eventually terminate with a basic optimal solution (in some sub-MDP <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>) that is pure. This yields a memoryless deterministic strategy in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> whose value is equal to the optimal value in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> Such a strategy can be extended to whole <span class="math notranslate nohighlight">\(\mathcal{M} by solving almost sure reachability to \)</span> \mathcal{M} $, as described in the previous sub-section.</p>
</div>
<div class="proof lemma admonition" id="lemma-12">
<p class="admonition-title"><span class="caption-number">Lemma 174 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
</div>
</div>
</div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}% \\%Each strategy $\sigma$ induces a solution $\lpsol{x}$ of $\lp_{\mathit{mp}} whose objective value is at least $\mathbb{E}\sigma_v[\mathtt{MeanPayoff}.$\\%
````{admonition} Proof
:class: dropdown tip\\%
````\\%\\%reachability values, we denote by $\mathtt{DiscountedPayoff}{k}(\pi$ the \\%payoff accumulated during the first $k$ steps of $\pi, i.e. the number \\%\, c\play_i)$. \\%lemma can be proved by an easy induction.\\%\begin{lemma}\\%For each $k\geq 0$ and each vertex $v$ it holds that \\%(\mathcal{D}k(\vec{0}))_v
\end{aligned}\end{align} \]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
%
%
%Now $\mathtt{DiscountedPayoff}\pi = \lim_{k\rightarrow 

%dominated 

%\lim_{k\rightarrow 

%$k$ we have $\mathtt{DiscountedPayoff}{k}(\pi\leq \max_{e\in 

%$)

%Hence 

%\begin{align*}

%\sup_{\sigma}\mathbb{E}\sigma_v[\lim_{k\rightarrow \infty}\mathtt{DiscountedPayoff}k]\\

%\\

%=\big(\sup_{k\geq 1} \mathcal{V}k(\vec{0})\big)_v = \big(\lim_{k\rightarrow 

%\end{align*}



%Note that the last equality in the first line follows from (XXX - SET UP SOME 

%line 

%$\big(\mathcal{V}\vec{0})\big)_v,\big(\mathcal{V}2(\vec{0})\big)_v,\dots$ is 

%vector 

%

%\label{5-lem:reach-value-limit}

%\end{theorem}

%The previous theorem yields a simple algorithm for approximation of 

%consists of iterating $\mathcal{V} with initial seed $\vec{0}$, which yields 

%disadvantage of value iteration is that it might not converge to the true 

%the MDP in Figure~\ref{xxx}. However,...

%



%\end{theorem}









%(v_0,v_1)(v_1,v_2)\cdots(v_{k-1},v_k)$ we put

%\label{5-eq:cylinder-probs}

%\begin{cases}

%\prod_{i=1}^{k} \sum_{a \in A\sigma(a\mid )

%\end{equation}
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5_MDP"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="mean_payoff_properties.html" title="previous page">Mean-payoff in MDPs: General properties and linear programming</a>
    <a class='right-next' id="next-link" href="end_components.html" title="next page">End components</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>