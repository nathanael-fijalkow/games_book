
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bibliographic references &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Stochastic Games" href="../6_Stochastic/index.html" />
    <link rel="prev" title="Optimal reachability" href="optimal_reachability.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     Büchi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Markov Decision Processes
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff_strongly_connected.html">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html#min-left-1-x-3-1-y-3-1-x-9-1-y-right-right-frac-1-4-max-x-y-in-0-1-2-min-left-4-6y-6-2x-6y-br-right">
     \min\left(
{(1-x) +  3 (1-y)},
{3(1-x) - 9(1-y)}
\right)\right)\
=&amp;
\frac{1}{4}\max_{(x,y)\in[0,1]^2}
\min\left(
4 - 6y,
-6 -2x + 6y
     <br/>
     \right)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="bibliographic-references">
<span id="sec-references"></span><h1>Bibliographic references<a class="headerlink" href="#bibliographic-references" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\newcommand{\expv}{\mathbb{E}} \newcommand{\discProbDist}{f} \newcommand{\sampleSpace}{S} \newcommand{\sigmaAlg}{\mathcal{F}} \newcommand{\probm}{\mathbb{P}} \newcommand{\rvar}{X} \\\newcommand{\actions}{A} \newcommand{\colouring}{c} \newcommand{\probTranFunc}{\Delta} \newcommand{\edges}{E} \newcommand{\colours}{C} \newcommand{\mdp}{\mathcal{M}} \newcommand{\vinit}{v_0} \newcommand{\cylProb}{p} \newcommand{\emptyPlay}{\epsilon} \newcommand{\objective}{\Omega} \newcommand{\genColour}{\textsc{c}} \newcommand{\quantObj}{f} \newcommand{\quantObjExt}{\bar{\quantObj}} \newcommand{\indicator}[1]{\mathbf{1}_{#1}} \newcommand{\eps}{\varepsilon} \newcommand{\maxc}{\max_{\colouring}} 
\newcommand{\winPos}{W_{&gt;0}}
\newcommand{\winAS}{W_{=1}}
\newcommand{\cylinder}{\mathit{Cyl}}
\newcommand{\PrePos}{\text{Pre}_{&gt;0}}
\newcommand{\PreAS}{\text{Pre}_{=1}}
\newcommand{\PreOPPos}{\mathcal{P}_{&gt;0}}
\newcommand{\OPAS}{\mathcal{P}_{=1}}
\newcommand{\safeOP}{\mathit{Safe_{=1}}}
\newcommand{\closed}{\mathit{Cl}}\\\newcommand{\reachOP}{\mathcal{V}}
\newcommand{\discOP}{\mathcal{D}}
\newcommand{\valsigma}{\vec{x}^{\sigma}}
\newcommand{\lp}{\mathcal{L}}
\newcommand{\lpdisc}{\lp_{\mathit{disc}}}
\newcommand{\lpreach}{\lp_{\mathit{reach}}}
\newcommand{\lpmp}{\lp_{\mathit{mp}}}
\newcommand{\lpsol}[1]{\bar{\vec{#1}}}
\newcommand{\lpsolg}[1]{\bar{#1}}
\newcommand{\lpmpdual}{\lpmp^{\mathit{dual}}}
\newcommand{\actevent}[3]{\actions^{#1}_{#2,#3}} 
\newcommand{\MeanPayoffSup}{\MeanPayoff^{\;+}}
\newcommand{\MeanPayoffInf}{\MeanPayoff^{\;-}}
\newcommand{\mcprob}{P}
\newcommand{\invdist}{\vec{z}}
\newcommand{\hittime}{T}
\newcommand{\playPay}{\textsf{p-Payoff}}
\newcommand{\stepPay}{\textsf{s-Payoff}}
\newcommand{\Pay}{\textsf{Payoff}}
\newcommand{\mec}{M}
\newcommand{\OPS}{\mathcal{S}_{=1}}
\newcommand{\smallmp}{\mathit{mp}}
\newcommand{\vgood}{v_{\mathit{good}}}
\newcommand{\vbad}{v_{\mathit{bad}}}
\newcommand{\finact}{fin}
\newcommand{\mecs}{\mathit{MEC}}
\newcommand{\slice}[2]{#1_{#2-}}
\newcommand{\ReachOp}{\mathcal{R}}
\newcommand{\dPayoffStep}[1]{\DiscountedPayoff^{\;(#1)}}
\newcommand{\solvset}{S}
\newcommand{\Eve}{\textrm{Eve}}
\newcommand{\Adam}{\textrm{Adam}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Zinfty}{\Z \cup \set{\pm \infty}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rinfty}{\R \cup \set{\pm \infty}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Qinfty}{\Q \cup \set{\pm \infty}}
\newcommand{\argmax}{\textrm{argmax}}
\newcommand{\argmin}{\textrm{argmin}}
\newcommand{\Op}{\mathbb{O}}
\newcommand{\Prob}{\mathbb{P}} \newcommand{\dist}{\mathcal{D}} \newcommand{\Dist}{\dist} \newcommand{\supp}{\textrm{supp}} 
\newcommand{\game}{\mathcal{G}} \renewcommand{\Game}{\game} \newcommand{\arena}{\mathcal{A}} \newcommand{\Arena}{\arena} 
\newcommand{\col}{\textsf{col}} \newcommand{\Col}{\col} 
\newcommand{\mEve}{\mathrm{Eve}}
\newcommand{\mAdam}{\mathrm{Adam}}
\newcommand{\mRandom}{\mathrm{Random}}
\newcommand{\vertices}{V} \newcommand{\VE}{V_\mEve} \newcommand{\VA}{V_\mAdam} \newcommand{\VR}{V_\mRandom} 
\newcommand{\ing}{\textrm{In}}
\newcommand{\Ing}{\ing}
\newcommand{\out}{\textrm{Out}}
\newcommand{\Out}{\out}
\newcommand{\dest}{\Delta} 
\newcommand{\WE}{W_\mEve} \newcommand{\WA}{W_\mAdam} 
\newcommand{\Paths}{\textrm{Paths}} \newcommand{\play}{\pi} \newcommand{\first}{\textrm{first}} \newcommand{\last}{\textrm{last}} 
\newcommand{\mem}{\mathcal{M}} \newcommand{\Mem}{\mem} 
\newcommand{\Pre}{\textrm{Pre}} \newcommand{\PreE}{\textrm{Pre}_\mEve} \newcommand{\PreA}{\textrm{Pre}_\mAdam} \newcommand{\Attr}{\textrm{Attr}} \newcommand{\AttrE}{\textrm{Attr}_\mEve} \newcommand{\AttrA}{\textrm{Attr}_\mAdam} \newcommand{\rank}{\textrm{rank}}
\newcommand{\Win}{\textrm{Win}} 
\newcommand{\Lose}{\textrm{Lose}} 
\newcommand{\Value}{\textrm{val}} 
\newcommand{\ValueE}{\textrm{val}_\mEve} 
\newcommand{\ValueA}{\textrm{val}_\mAdam}
\newcommand{\val}{\Value} 
\newcommand{\Automaton}{\mathbf{A}} 
\newcommand{\Safe}{\mathtt{Safe}}
\newcommand{\Reach}{\mathtt{Reach}} 
\newcommand{\Buchi}{\mathtt{Buchi}} 
\newcommand{\CoBuchi}{\mathtt{CoBuchi}} 
\newcommand{\Parity}{\mathtt{Parity}} 
\newcommand{\Muller}{\mathtt{Muller}} 
\newcommand{\Rabin}{\mathtt{Rabin}} 
\newcommand{\Streett}{\mathtt{Streett}} 
\newcommand{\MeanPayoff}{\mathtt{MeanPayoff}} 
\newcommand{\DiscountedPayoff}{\mathtt{DiscountedPayoff}}
\newcommand{\Energy}{\mathtt{Energy}}
\newcommand{\TotalPayoff}{\mathtt{TotalPayoff}}
\newcommand{\ShortestPath}{\mathtt{ShortestPath}}
\newcommand{\Sup}{\mathtt{Sup}}
\newcommand{\Inf}{\mathtt{Inf}}
\newcommand{\LimSup}{\mathtt{LimSup}}
\newcommand{\LimInf}{\mathtt{LimInf}}
\newcommand{\NL}{\textrm{NL}}
\newcommand{\PTIME}{\textrm{PTIME}}
\newcommand{\NP}{\textrm{NP}}
\newcommand{\UP}{\textrm{UP}}
\newcommand{\coNP}{\textrm{coNP}}
\newcommand{\coUP}{\textrm{coUP}}
\newcommand{\PSPACE}{\textrm{PSPACE}}\end{aligned}\end{align} \]</div>
<p>There is a broad field of study related to Markov decision processes, with a history going as far as  1950’s <span id="id1">[<a class="reference internal" href="#id102"><span>Bel57</span></a>]</span>. It is beyond the scope of this chapter to provide a comprehensive overview of the related literature. Nonetheless, in this section we provide pointers to the most significant works connected to our techniques as well as to works that can serve as a starting point for a further study.</p>
<p>One of the most widely used references for MDP-related research is the textbook by Puterman <span id="id2">[<a class="reference internal" href="#id122"><span>Put05</span></a>]</span>. The textbook views MDPs from an operations research point-of-view, focusing on finite-horizon, discounted, total-reward, and average reward (an alternative name for mean-payoff) objectives. Regular objectives fall outside of the book’s focus, though reachability can be viewed as a special case of the positive bounded total reward objectives studied in the book. An in-depth study of the textbook will impart to its reader the knowledge of many useful techniques for MDP analysis, though a reader who is a newcomer to MDPs might feel somewhat intimidated by its sheer volume and generality. In this chapter, we follow Puterman’s exposition mainly in the discounted payoff, albeit in a rather condensed form.</p>
<p>For mean-payoff MDPs, <span id="id3">[<a class="reference internal" href="#id122"><span>Put05</span></a>]</span> follows similar blueprint as in the discounted case: first characterizing the optimal values via a suitable optimality equation and then deriving the value iteration, strategy improvement, and linear programming methods from this characterization. We use the linear programming as our foundational stone, focusing on the relationship between strategies and feasible solutions of the program. We note that value and strategy iteration for mean-payoff MDPs come with super-polynomial lower bounds, see, e.g. <span id="id4">[<a class="reference internal" href="#id109"><span>Fea10a</span></a>,<a class="reference internal" href="#id110"><span>Fea10b</span></a>]</span>, or <span id="id5">[<a class="reference internal" href="#id122"><span>Put05</span></a>]</span>, where it is shown that strategy improvement converges at least as fast as value iteration.</p>
<p>Also, <span id="id6">[<a class="reference internal" href="#id122"><span>Put05</span></a>]</span> makes the initial analysis of mean-payoff MDPs in the context of <strong>unichain</strong> MDPs, and then extends to arbitrary MDPs, with strongly connected MDPs treated as a special case of the latter. While unichain is an important theoretical concept, in the context of formal methods and automata it is preferable to work with strongly connected MDPs. We also note that all the results in the mean-payoff sections hold also for <span class="math notranslate nohighlight">\(\MeanPayoffSup\)</span>. Almost all of the proofs are the same, with an important exception of \Cref{5-cor:mp-value-bound}, where Fatou’s lemma cannot be used to prove that <span class="math notranslate nohighlight">\(\playPay(\vinit,\sigma) \leq \stepPay(\vinit,\sigma)\)</span>. Instead, we could use <strong>martingale techniques</strong> here. Martingales are an important concept in probability theory <span id="id7">[<a class="reference internal" href="#id127"><span>Wil91</span></a>]</span>, with applications e.g. in analysis of infinite-state MDPs and stochastic games <span id="id8">[<a class="reference internal" href="#id104"><span>BrazdilBrovzekEKuvcera11</span></a>]</span>. We can use martingales to strengthen  <a class="reference internal" href="mean_payoff_properties.html#5-lem:dual-bound-step">Lemma 159</a> by showing that the probability  of <span class="math notranslate nohighlight">\(\sum_{i=0}^{n-1}\colouring(\play_i) \geq \sqrt{n}\cdot \expv^\sigma_{\vinit}[\sum_{i=0}^{n-1}\colouring(\play_i)]\)</span> converges (with an exponential rate of decay) to <span class="math notranslate nohighlight">\(0\)</span> as <span class="math notranslate nohighlight">\(n\rightarrow \infty\)</span>, which allows us to prove the required bound for <span class="math notranslate nohighlight">\(\limsup\)</span>.</p>
<p>The notion of a (M)EC as well as many techniques we use in the EC section are due to de Alfaro, whose thesis <span id="id9">[<a class="reference internal" href="#id108"><span>dA97</span></a>]</span> details the evolution of the concept and its relation to similar notions. The algorithm for MEC decomposition is taken from <span id="id10">[<a class="reference internal" href="#id107"><span>CH11</span></a>]</span>, where more advanced algorithms as well as use of MECs in parity MDPs are discussed.</p>
<p>For an overview of literature related to verification of temporal properties in MDPs, we refer the reader to the monograph <span id="id11">[<a class="reference internal" href="#id100"><span>BK08</span></a>]</span>.</p>
<p>MDPs are also used as a prime model in reinforcement learning (RL), one of the classical yet rapidly evolving sub-fields of AI. For RL-centric view of MDPs, we point the reader towards the textbooks <span id="id12">[<a class="reference internal" href="#id125"><span>SB18</span></a>,<a class="reference internal" href="#id103"><span>Ber07</span></a>]</span>.</p>
<p id="id13"><dl class="citation">
<dt class="label" id="id99"><span class="brackets">ADoleansD00</span></dt>
<dd><p>Robert B. Ash and Catherine A. Doléans-Dade. <em>Probability and Measure Theory</em>. Academic Press, 2000. ISBN 9780120652020.</p>
</dd>
<dt class="label" id="id121"><span class="brackets">Novotny15</span></dt>
<dd><p>Petr Novotný. <em>Controller Synthesis for Resource-Aware Systems</em>. Ph.D. thesis, Masaryk University, 2015.</p>
</dd>
<dt class="label" id="id122"><span class="brackets">Put05</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>,<a href="#id5">3</a>,<a href="#id6">4</a>)</span></dt>
<dd><p>Martin L. Puterman. <em>Markov Decision Processes: Discrete Stochastic Dynamic Programming</em>. John Wiley &amp; Sons, 2005.</p>
</dd>
<dt class="label" id="id123"><span class="brackets">Sav70</span></dt>
<dd><p>Walter J. Savitch. Relationships between Nondeterministic and Deterministic Tape Complexities. <em>Journal of Computer and System Sciences</em>, 4(2):177–192, 1970. <a class="reference external" href="https://doi.org/10.1016/S0022-0000(70)80006-X">doi:10.1016/S0022-0000(70)80006-X</a>.</p>
</dd>
<dt class="label" id="id118"><span class="brackets">Lad75</span></dt>
<dd><p>Richard E. Ladner. The circuit value problem is log space complete for ¶. <em>SIGACT News</em>, 7(1):18–20, 1975. URL: <a class="reference external" href="http://doi.acm.org/10.1145/990518.990519">http://doi.acm.org/10.1145/990518.990519</a>, <a class="reference external" href="https://doi.org/10.1145/990518.990519">doi:10.1145/990518.990519</a>.</p>
</dd>
<dt class="label" id="id106"><span class="brackets">CDH10</span></dt>
<dd><p>Krishnendu Chatterjee, Laurent Doyen, and Thomas A. Henzinger. Qualitative Analysis of Partially-Observable Markov Decision Processes. In <em>Proceedings of the International Symposium on Mathematical Foundations of Computer Science, MFCS'10</em>, 258–269. Springer-Verlag, 2010.</p>
</dd>
<dt class="label" id="id101"><span class="brackets">Bar68</span></dt>
<dd><p>Erwin H. Bareiss. Sylvester's identity and multistep integer-preserving Gaussian elimination. <em>Mathematics of Computation</em>, 22:565–578, 1968.</p>
</dd>
<dt class="label" id="id126"><span class="brackets">Tse90</span></dt>
<dd><p>Paul Tseng. Solving H-horizon, stationary Markov decision problems in time proportional to \(\log (H)\). <em>Operation Research Letters</em>, 9(5):287–297, 1990.</p>
</dd>
<dt class="label" id="id112"><span class="brackets">Gar07</span></dt>
<dd><p>David J. H. Garling. <em>Inequalities: A Journey Into Linear Analysis</em>. Cambridge University Press, 2007. ISBN 978-0-521-69973-0.</p>
</dd>
<dt class="label" id="id114"><span class="brackets">HDJ12</span></dt>
<dd><p>Romain Hollanders, Jean-Charles Delvenne, and Raphaël M. Jungers. The complexity of policy iteration is exponential for discounted Markov decision processes. In <em>Proceedings of the IEEE Conference on Decision and Control, CDC'12</em>, volume, 5997–6002. IEEE Computer Society, 2012.</p>
</dd>
<dt class="label" id="id116"><span class="brackets">Kar84</span></dt>
<dd><p>Narendra Karmarkar. A new polynomial-time algorithm for linear programming. <em>Combinatorica</em>, 4(4):373–395, 1984.</p>
</dd>
<dt class="label" id="id128"><span class="brackets">Ye11</span></dt>
<dd><p>Yinyu Ye. The simplex and policy-iteration methods are strongly polynomial for the Markov decision problem with a fixed discount rate. <em>Mathematics of Operations Research</em>, 36(4):593 – 603, 2011.</p>
</dd>
<dt class="label" id="id119"><span class="brackets">Matouvsek07</span></dt>
<dd><p>Jiří Matoušek. <em>Understanding and Using Linear Programming</em>. Universitext. Springer-Verlag, 2007.</p>
</dd>
<dt class="label" id="id120"><span class="brackets">Nor98</span></dt>
<dd><p>J.R. Norris. <em>Markov Chains</em>. Volume 2 of Cambridge Series on Statistical and Probabilistic Mathematics. Cambridge University Press, 1998.</p>
</dd>
<dt class="label" id="id113"><span class="brackets">Gon92</span></dt>
<dd><p>Clovis C. Gonzaga. Path-following methods for linear programming. <em>SIAM Review</em>, 34(2):167–224, 1992.</p>
</dd>
<dt class="label" id="id105"><span class="brackets">CLRS09</span></dt>
<dd><p>Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Cliffor Stein. <em>Introduction to Algorithms, Third Edition</em>. MIT Press, 2009.</p>
</dd>
<dt class="label" id="id102"><span class="brackets"><a class="fn-backref" href="#id1">Bel57</a></span></dt>
<dd><p>Richard Bellman. A Markovian decision process. <em>Journal of Mathematics and Mechanics</em>, pages 679–684, 1957.</p>
</dd>
<dt class="label" id="id109"><span class="brackets"><a class="fn-backref" href="#id4">Fea10a</a></span></dt>
<dd><p>John Fearnley. <em>Strategy Iteration Algorithms for Games and Markov Decision Processes</em>. PhD thesis, University of Warwick, 2010.</p>
</dd>
<dt class="label" id="id110"><span class="brackets"><a class="fn-backref" href="#id4">Fea10b</a></span></dt>
<dd><p>John Fearnley. Exponential lower bounds for policy iteration. In <em>Proceedings of the International Colloquium on Automata, Languages and Programming, ICALP'10</em>, 551–562. Springer-Verlag, 2010.</p>
</dd>
<dt class="label" id="id127"><span class="brackets"><a class="fn-backref" href="#id7">Wil91</a></span></dt>
<dd><p>David Williams. <em>Probability with Martingales</em>. Cambridge University Press, 1991.</p>
</dd>
<dt class="label" id="id104"><span class="brackets"><a class="fn-backref" href="#id8">BrazdilBrovzekEKuvcera11</a></span></dt>
<dd><p>Tomáš Brázdil, Václav Brožek, Kousha Etessami, and Antonín Kučera. Approximating the termination value of one-counter MDPs and stochastic games. In <em>Proceedings of the International Colloquium on Automata, Languages and Programming, ICALP'11</em>, 332–343. Springer-Verlag, 2011.</p>
</dd>
<dt class="label" id="id108"><span class="brackets"><a class="fn-backref" href="#id9">dA97</a></span></dt>
<dd><p>Luca de Alfaro. <em>Formal Verification of Probabilistic Systems</em>. PhD thesis, Stanford University, 1997.</p>
</dd>
<dt class="label" id="id107"><span class="brackets"><a class="fn-backref" href="#id10">CH11</a></span></dt>
<dd><p>Krishnendu Chatterjee and Monika Henzinger. Faster and dynamic algorithms for maximal end-component decomposition and related graph problems in probabilistic verification. In <em>Proceedings of the Symposium on Discrete Algorithms, SODA'11</em>, 1318–1336. Society for Industrial and Applied Mathematics, 2011.</p>
</dd>
<dt class="label" id="id100"><span class="brackets"><a class="fn-backref" href="#id11">BK08</a></span></dt>
<dd><p>Christel Baier and Joost-Pieter Katoen. <em>Principles of Model Checking</em>. MIT Press, 2008.</p>
</dd>
<dt class="label" id="id125"><span class="brackets"><a class="fn-backref" href="#id12">SB18</a></span></dt>
<dd><p>Richard S. Sutton and Andrew G. Barto. <em>Reinforcement Learning: An Introduction</em>. MIT Press, 2nd edition, 2018.</p>
</dd>
<dt class="label" id="id103"><span class="brackets"><a class="fn-backref" href="#id12">Ber07</a></span></dt>
<dd><p>Dimitri P. Bertsekas. <em>Dynamic Programming and Optimal Control</em>. Athena Scientific, 4th edition, 2007.</p>
</dd>
</dl>
</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5_MDP"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="optimal_reachability.html" title="previous page">Optimal reachability</a>
    <a class='right-next' id="next-link" href="../6_Stochastic/index.html" title="next page">Stochastic Games</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>