
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nash Equilibria for games in normal form &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Admissible strategies" href="admissible_strategies.html" />
    <link rel="prev" title="Multiplayer Games" href="index.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     BÃ¼chi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../5_MDP/index.html">
   Markov Decision Processes
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_strongly_connected.html">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Infinite
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../9_Timed/index.html">
   Timed Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/state_space_representation.html">
     State-Space Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/controllable_predecessor_operator.html">
     Controllable-Predecessor Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/backward_algorithm.html">
     Backward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/forward_algorithm.html">
     Forward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10_Pushdown/index.html">
   Pushdown Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/profiles.html">
     Profiles and regularity of the winning regions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/parity.html">
     Parity pushdown games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11_Counters/index.html">
   Games with Counters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/counters.html">
     Vector games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/dim1.html">
     Games in dimension one
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/avag.html">
     Asymmetric games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/resource.html">
     Resource-conscious games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/complexity.html">
     The complexity of asymmetric monotone games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multi
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12_Multiobjectives/index.html">
   Games with multiple objectives
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/mean_payoff_energy.html">
     Mean-payoff and energy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/total_payoff_shortest_path.html">
     Total-payoff and shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/beyond_worst_case.html">
     Beyond worst-case synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/percentile.html">
     Percentile queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Multiplayer Games
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Nash Equilibria for games in normal form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="admissible_strategies.html">
     Admissible strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definitions">
   Definitions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-nash-equilibrium-problem">
   The Nash equilibrium problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deviators">
   Deviators
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deviator-game">
   Deviator Game
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm-for-parity-objectives">
     Algorithm for Parity Objectives
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extensions-of-nash">
   Extensions of Nash
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#subgame-perfect">
     Subgame Perfect
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#robust-equilibria">
     Robust equilibria
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extension-to-games-with-hidden-actions">
     Extension to games with hidden actions
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="nash-equilibria-for-games-in-normal-form">
<span id="sec-nash-equilibria-normal-form"></span><h1>Nash Equilibria for games in normal form<a class="headerlink" href="#nash-equilibria-for-games-in-normal-form" title="Permalink to this headline">Â¶</a></h1>
<div class="math notranslate nohighlight">
\[\newcommand{\Eve}{\textrm{Eve}}
\newcommand{\Out}{\out}
\newcommand{\last}{\textrm{last}}
\newcommand{\out}{\textrm{Out}}\]</div>
<p>The normal form games we consider differ from the matrix games of Chapter <a class="reference internal" href="../7_Concurrent/index.html#chap-concurrent"><span class="std std-ref">Concurrent Games</span></a>, in that each player has their own payoff.
So for instance, when player 1 chooses column Hawk, and player 2 chooses
row Dove, the payoff for player 1 is <span class="math notranslate nohighlight">\(\payoff_{P_1}(\text{Hawk}, \text{Dove}) = 4\)</span>.</p>
<p>Let us call a vector of strategies specifying a strategy for each player a <strong>strategy profile</strong>. In normal-form games, each cell of the table <span class="math notranslate nohighlight">\(\Delta\)</span> corresponds to a strategy profile.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 355 </span> (NEEDS TITLE AND LABEL)</p>
<div class="definition-content section" id="proof-content">
<p>A <strong>Nash equilibrium</strong> is a <strong>stable</strong> strategy profile in which
strategy is a best response against the other strategies.</p>
<p>A <strong>Nash equilibrium</strong> is a <strong>stable</strong> strategy profile in which
strategy is a best response against the other strategies.</p>
</div>
</div><p>Thus a Nash equilibrium is a stable situation in the sense that
no player has an incentive in changing their strategy.
Nash proved that when
players are allowed to randomise among all their strategies, there always
exists a Nash equilibrium.</p>
<div class="proof theorem admonition" id="theorem-1">
<p class="admonition-title"><span class="caption-number">Theorem 356 </span> (NEEDS LABEL Existence of Nash equilibria)</p>
<div class="theorem-content section" id="proof-content">
<p>In every normal-form game with a finite number of
players, each having a finite number of pure strategies, there exists a
randomised Nash equilibrium.</p>
</div>
</div><p>Note that not all games contain pure Nash equilibria.
For example, in the rock-paper-scissors game, the best response to rock
is paper, to paper is scissors, and to scissors is rock, so none of these
pure strategies can be an equilibrium.</p>
<p>For finding a pure Nash equilibrium in a normal-form game, there is a simple
polynomial time algorithm.
For each strategy profile, we look for each player whether they have a better
response than their current strategy.
If no player has a better response, the strategy profile is a Nash equilibrium,
otherwise we move to the next one, and if none satisfies the condition then there is no equilibrium.</p>
<div class="proof example admonition" id="example-2">
<p class="admonition-title"><span class="caption-number">Example 357 </span> (NEEDS LABEL Medium Access Control)</p>
<div class="example-content section" id="proof-content">
<p>Consider a medium access control
problem, where several users share access to a wireless channel. A
communication over the channel is successful if there are no collisions,
that is, if a single user is transmitting their message only. During each
slot, each user chooses either to transmit or to idle. Intuitively, the
number of packets transmitted without collision decreases with
the number of users emitting in the same slot. Furthermore each attempt
at transmitting has a cost. An example payoff for two players,
is represented in Table~\ref{ex:medium-access}.</p>
<p>\begin{table}
\caption{A game of medium access.}
\label{ex:medium-access}
\begin{center}
\begin{tabular}[c]{|&#64;{\hspace{1em}}l&#64;{\hspace{1em}}|&#64;{\hspace{1em}}c&#64;{\hspace{1em}}c&#64;{\hspace{1em}}|}
\hline
&amp; Emit &amp; Wait\
\hline
Emit &amp; -1, -1 &amp; 2, 0\
Wait &amp; 0 , 2 &amp; 0, 0\
\hline
\end{tabular}
\end{center}
\end{table}</p>
</div>
</div><p>We encourage the reader to find the Nash equilibria of the above game.</p>
<p>The game described above corresponds to a single slot of this system. In
a practical scenario, there would be a succession of slots and the payoff would be
the sum of payoffs over all slots. Normal-form games are thus not
sufficient to represent games with repetitions and to study the
evolution of the behaviours as the game evolves.</p>
<p>One possibilty to model repetition is to use
<strong>games in extensive form</strong> which are games played on finite trees.
However such games only model a fixed number of repetitions unlike
infinite or arbitrary duration games as studied in this book. We thus
study, in the rest of this chapter, algorithms for games played on
graphs.</p>
<div class="section" id="definitions">
<span id="subsec-definitions"></span><h2>Definitions<a class="headerlink" href="#definitions" title="Permalink to this headline">Â¶</a></h2>
<div class="proof definition admonition" id="definition-3">
<p class="admonition-title"><span class="caption-number">Definition 358 </span> (NEEDS TITLE AND LABEL)</p>
<div class="definition-content section" id="proof-content">
<p>A multiplayer <strong>arena</strong> (\mathcal{A}) with <span class="math notranslate nohighlight">\(k\)</span> players is a tuple</p>
<p>(\langle V, \Act,\Delta,(c_P)_{P\in \Agt} \rangle ), where:</p>
<ul>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(V\) is a finite set of vertices;
</pre></div>
</div>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Agt = \{1,2,\ldots,k\}\) is the set of players;
</pre></div>
</div>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Act\) is a finite set of actions, a tuple \((a_P)_{P \in \Agt}\)
</pre></div>
</div>
<p>containing one action (a_P) for each player <span class="math notranslate nohighlight">\(A\)</span> is called a
<strong>move</strong>, thus (\Act^k) is the set of possible moves;</p>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Delta : V \times \Act^k \to V\) is the transition function which
</pre></div>
</div>
<p>associates to a pair of vertices and moves the resulting state;</p>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \((c_P)_{P \in \Agt}\) is a tuple of colouring functions
</pre></div>
</div>
<p>with <span class="math notranslate nohighlight">\(c_P : V \rightarrow C\)</span> for each <span class="math notranslate nohighlight">\(P \in \Agt\)</span>.</p>
</li>
</ul>
<p>A multiplayer <strong>arena</strong> (\mathcal{A}) with <span class="math notranslate nohighlight">\(k\)</span> players is a tuple</p>
<p>(\langle V, \Act,\Delta,(c_P)_{P\in \Agt} \rangle ), where:</p>
<ul>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(V\) is a finite set of vertices;
</pre></div>
</div>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Agt = \{1,2,\ldots,k\}\) is the set of players;
</pre></div>
</div>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Act\) is a finite set of actions, a tuple \((a_P)_{P \in \Agt}\)
</pre></div>
</div>
<p>containing one action (a_P) for each player <span class="math notranslate nohighlight">\(A\)</span> is called a
<strong>move</strong>, thus (\Act^k) is the set of possible moves;</p>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \(\Delta : V \times \Act^k \to V\) is the transition function which
</pre></div>
</div>
<p>associates to a pair of vertices and moves the resulting state;</p>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> \((c_P)_{P \in \Agt}\) is a tuple of colouring functions
</pre></div>
</div>
<p>with <span class="math notranslate nohighlight">\(c_P : V \rightarrow C\)</span> for each <span class="math notranslate nohighlight">\(P \in \Agt\)</span>.</p>
</li>
</ul>
</div>
</div><div class="proof example admonition" id="example-4">
<p class="admonition-title"><span class="caption-number">Example 359 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>A simple three-player concurrent game is represented in <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>.
Vertices are <span class="math notranslate nohighlight">\(v_0\)</span>, <span class="math notranslate nohighlight">\(v_1\)</span>, <span class="math notranslate nohighlight">\(v_2\)</span>, <span class="math notranslate nohighlight">\(v_3\)</span> and <span class="math notranslate nohighlight">\(v_4\)</span>.</p>
<p>Players are named <span class="math notranslate nohighlight">\(P_1\)</span>, <span class="math notranslate nohighlight">\(P_2\)</span>, <span class="math notranslate nohighlight">\(P_3\)</span>.
The set of actions is <span class="math notranslate nohighlight">\(\Act = \{ a , b\}\)</span>.
The transition relation is given by the edges in the graph, for instance
<span class="math notranslate nohighlight">\(\Delta(s_0, (a, b, a))\)</span> is <span class="math notranslate nohighlight">\(v_1\)</span>. In our figures, <span class="math notranslate nohighlight">\(\ast\)</span> represents
an arbitrary action.
The colouring function is represented below vertices as tuples ranging over players.
For instance, a vertex labelled by <span class="math notranslate nohighlight">\((1,1,0)\)</span> assigns
the first two players the colour <span class="math notranslate nohighlight">\(1\)</span>, and the third player the colour <span class="math notranslate nohighlight">\(0\)</span>,
In particular, <span class="math notranslate nohighlight">\(c_{P_1}(v_2) = 1\)</span>, and <span class="math notranslate nohighlight">\(c_{P_3}(v_2)= 0\)</span>.</p>
<p>A simple three-player concurrent game is represented in <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>.
Vertices are <span class="math notranslate nohighlight">\(v_0\)</span>, <span class="math notranslate nohighlight">\(v_1\)</span>, <span class="math notranslate nohighlight">\(v_2\)</span>, <span class="math notranslate nohighlight">\(v_3\)</span> and <span class="math notranslate nohighlight">\(v_4\)</span>.</p>
<p>Players are named <span class="math notranslate nohighlight">\(P_1\)</span>, <span class="math notranslate nohighlight">\(P_2\)</span>, <span class="math notranslate nohighlight">\(P_3\)</span>.
The set of actions is <span class="math notranslate nohighlight">\(\Act = \{ a , b\}\)</span>.
The transition relation is given by the edges in the graph, for instance
<span class="math notranslate nohighlight">\(\Delta(s_0, (a, b, a))\)</span> is <span class="math notranslate nohighlight">\(v_1\)</span>. In our figures, <span class="math notranslate nohighlight">\(\ast\)</span> represents
an arbitrary action.
The colouring function is represented below vertices as tuples ranging over players.
For instance, a vertex labelled by <span class="math notranslate nohighlight">\((1,1,0)\)</span> assigns
the first two players the colour <span class="math notranslate nohighlight">\(1\)</span>, and the third player the colour <span class="math notranslate nohighlight">\(0\)</span>,
In particular, <span class="math notranslate nohighlight">\(c_{P_1}(v_2) = 1\)</span>, and <span class="math notranslate nohighlight">\(c_{P_3}(v_2)= 0\)</span>.</p>
</div>
</div><div class="figure align-center" id="fig-example1">
<img alt="../_images/13-fig:example1.png" src="../_images/13-fig:example1.png" />
<p class="caption"><span class="caption-number">Fig. 94 </span><span class="caption-text">Example of a three-player concurrent arena. The symbol <span class="math notranslate nohighlight">\(\ast\)</span> on edges can be replaced by either <span class="math notranslate nohighlight">\(a\)</span> or <span class="math notranslate nohighlight">\(b\)</span>.</span><a class="headerlink" href="#fig-example1" title="Permalink to this image">Â¶</a></p>
</div>
<p>A <strong>history</strong> of the multiplayer arena</p>
<p>({\mathcal A}) is a finite sequence of states and moves ending with a
state, i.e.~a word in ((V \cdot \Act^\Agt)^* \cdot V). Note that unlike
for two player games we include actions in the history, because knowing
the source and target vertices does not mean you know which player chose
which actions.</p>
<p>For a history <span class="math notranslate nohighlight">\(\pi\)</span>, we write (\pi_i) the <span class="math notranslate nohighlight">\(i\)</span>-th vertex of <span class="math notranslate nohighlight">\(\pi\)</span>, starting from <span class="math notranslate nohighlight">\(0\)</span>, and</p>
<p>(\move_i(\pi)) its <span class="math notranslate nohighlight">\(i\)</span>-th move, thus
(\pi = \pi_0 \cdot \move_0(\pi \cdot \pi_1 \cdots \move_{n-1}(\pi)\cdot \pi_n), and
with this notation <span class="math notranslate nohighlight">\(\move_i(\pi)_P\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th action of player <span class="math notranslate nohighlight">\(P\)</span> in <span class="math notranslate nohighlight">\(h\)</span>.
The length <span class="math notranslate nohighlight">\(|\pi|\)</span> of such a history is <span class="math notranslate nohighlight">\(n + 1\)</span>. We write
<span class="math notranslate nohighlight">\(\textrm{last}\pi)\)</span> the last vertex of h, i.e. (\pi_{|\pi|-1}).
A play (\rho) is an
infinite sequence of vertices and moves, i.e.~an element of
((V \cdot \Act^{\Agt})^\omega).</p>
<div class="proof definition admonition" id="definition-5">
<p class="admonition-title"><span class="caption-number">Definition 360 </span> (NEEDS LABEL Strategy and coalition)</p>
<div class="definition-content section" id="proof-content">
<p>A strategy is a function which associates an action to each history.
We often write <span class="math notranslate nohighlight">\(\sigma_A\)</span> for a strategy of player <span class="math notranslate nohighlight">\(P\)</span>.
A coalition <span class="math notranslate nohighlight">\(\Coalition\)</span> is a set of players in <span class="math notranslate nohighlight">\(\Agt\)</span>, and we write</p>
<p><span class="math notranslate nohighlight">\(-\Coalition\)</span> for the remaining players, that is <span class="math notranslate nohighlight">\(-\Coalition = Agt \setminus \Coalition\)</span>.
Let (\Coalition) be a coalition, a strategy (\sigma_\Coalition) for (\Coalition) is a function
which associates a strategy (\sigma_P) to each player (P\in \Coalition).
Given a strategy <span class="math notranslate nohighlight">\(\sigma_\Coalition\)</span>, when it is clear from the context, we simply
write (\sigma_P) for (\sigma_\Coalition(P)).</p>
</div>
</div><div class="proof definition admonition" id="definition-6">
<p class="admonition-title"><span class="caption-number">Definition 361 </span> (NEEDS LABEL Outcomes)</p>
<div class="definition-content section" id="proof-content">
<p>A history (\pi) is compatible
with the strategy (\sigma_\Coalition) for coalition <span class="math notranslate nohighlight">\(\Coalition\)</span> if, for all (k &lt; |\pi| - 1) and all
(P \in \Coalition), ((\move_k(\pi))<em>P = \sigma_P(\pi{\le k})), and
(\Delta(\pi_k, \move_k(\pi)) = \pi</em>{k+1}). A play (\rho) is compatible with
the strategy (\sigma_\Coalition) if all its prefixes are. We write</p>
<p>(\Out_{\mathcal{A}}(v_0, \sigma_\Coalition)) for the set of plays in (\mathcal{A}) that
are compatible with strategy (\sigma_\Coalition) and have initial vertex
(v_0). Let (\Out_{\mathcal{A}}(\sigma_\Coalition)) denote the union
of (\Out_{\mathcal{A}}(v_0, \sigma_\Coalition)) for all <span class="math notranslate nohighlight">\(v_0\)</span>,
and (\Out_{\mathcal{A}}(v_0)) the union of all (\Out_{\mathcal{A}}(v_0, \sigma_\Coalition)).
The subscript <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> can be omitted if it is clear from the context.
These paths are called <strong>outcomes</strong> of (\sigma_\Coalition) from
(v_0).</p>
</div>
</div><p>Note that
when the coalition (\Coalition) is composed of all the players
the outcome from a given state is unique.</p>
<div class="proof example admonition" id="example-7">
<p class="admonition-title"><span class="caption-number">Example 362 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>Consider in the example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, the following
strategies:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P_1\)</span> always plays <span class="math notranslate nohighlight">\(a\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_1}(\pi) = a\)</span> for all histories <span class="math notranslate nohighlight">\(\pi\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P_2\)</span> plays <span class="math notranslate nohighlight">\(a\)</span> in <span class="math notranslate nohighlight">\(v_0\)</span> if it is the first state and then always plays <span class="math notranslate nohighlight">\(b\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_2}(v_0) = a\)</span> and <span class="math notranslate nohighlight">\(\sigma_{P_2}(\pi) = b\)</span> for all <span class="math notranslate nohighlight">\(\pi \ne v_0\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P_3\)</span> always plays <span class="math notranslate nohighlight">\(b\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_3}(\pi) = b\)</span>.</p></li>
</ul>
<p>The outcome from <span class="math notranslate nohighlight">\(v_0\)</span> in that case is
\begin{align*}
\outv_0, \sigma_{{P_1, P_2, P_3}}) ~ = &amp; ~ v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, b, b)
\cdot v_4 \cdot (a, b, b) \cdot\
&amp; \left(v_0 \cdot (a, b, b)
\cdot v_1 \cdot (a, b, b)
\cdot v_3 \cdot (a, b, b)\right)^\omega
\end{align*}</p>
<p>Consider in the example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, the following
strategies:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P_1\)</span> always plays <span class="math notranslate nohighlight">\(a\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_1}(\pi) = a\)</span> for all histories <span class="math notranslate nohighlight">\(\pi\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P_2\)</span> plays <span class="math notranslate nohighlight">\(a\)</span> in <span class="math notranslate nohighlight">\(v_0\)</span> if it is the first state and then always plays <span class="math notranslate nohighlight">\(b\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_2}(v_0) = a\)</span> and <span class="math notranslate nohighlight">\(\sigma_{P_2}(\pi) = b\)</span> for all <span class="math notranslate nohighlight">\(\pi \ne v_0\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P_3\)</span> always plays <span class="math notranslate nohighlight">\(b\)</span>, i.e. <span class="math notranslate nohighlight">\(\sigma_{P_3}(\pi) = b\)</span>.</p></li>
</ul>
<p>The outcome from <span class="math notranslate nohighlight">\(v_0\)</span> in that case is
\begin{align*}
\outv_0, \sigma_{{P_1, P_2, P_3}}) ~ = &amp; ~ v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, b, b)
\cdot v_4 \cdot (a, b, b) \cdot\
&amp; \left(v_0 \cdot (a, b, b)
\cdot v_1 \cdot (a, b, b)
\cdot v_3 \cdot (a, b, b)\right)^\omega
\end{align*}</p>
</div>
</div><div class="proof definition admonition" id="definition-8">
<p class="admonition-title"><span class="caption-number">Definition 363 </span> (NEEDS LABEL Multiplayer game)</p>
<div class="definition-content section" id="proof-content">
<p>A <strong>payoff</strong> function associates a real number to each outcome.
We will be mostly be interested in solving games with qualitative
objectives, that is payoffs that take values <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>A <strong>multiplayer game</strong> ((\mathcal{A}, (\payoff_P)_{P \in \Agt})) is given by a multiplayer arena <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, an initial
vertex <span class="math notranslate nohighlight">\(v_0\)</span> and payoff function <span class="math notranslate nohighlight">\(\payoff_P\)</span> for each player <span class="math notranslate nohighlight">\(P\)</span>.
When <span class="math notranslate nohighlight">\(\payoff_P\)</span> is qualitative we simply write <span class="math notranslate nohighlight">\(\Omega_P\)</span>
for the corresponding objective.</p>
</div>
</div></div>
<div class="section" id="the-nash-equilibrium-problem">
<span id="subsec-algorithm-for-finding-nash-equilibria"></span><h2>The Nash equilibrium problem<a class="headerlink" href="#the-nash-equilibrium-problem" title="Permalink to this headline">Â¶</a></h2>
<p>In this section we will present an algorithm to compute
Nash equilibria in
multiplayer games.
The problem we are interested in is to decide the existence of a Nash
equilibrium in which the objectives of a given set of players are
satisfied.</p>
<div class="admonition-problem admonition">
<p class="admonition-title">Problem</p>
<p><strong>INPUT</strong>:
\parbox[t]{0.75\textwidth}{Multiplayer game <span class="math notranslate nohighlight">\((\mathcal{A}, (\payoff_P)_{P \in \Agt})\)</span>, payoff
bounds <span class="math notranslate nohighlight">\((b_P)_{P\in\ \Agt}\)</span>, and initial vertex <span class="math notranslate nohighlight">\(v_0\)</span>}</p>
<p><strong>QUESTION</strong>:
\parbox[t]{0.75\textwidth}{is there
a Nash equilibrium <span class="math notranslate nohighlight">\(\sigma_{\Agt}\)</span> such that for all
<span class="math notranslate nohighlight">\(P \in \Agt, \payoff_P(\textrm{Out}v_0,\sigma_{\Agt}})) \ge b_P\)</span>?}</p>
</div>
<p>\todo{OS: I donât know how to fix this alignment issue}</p>
<p>The algorithm is based on a reduction to zero-sum two-players games,
which allows us to use algorithms presented in the previous chapters of
this book. More precisely, we present the <strong>deviator game</strong>, which is
a transformation of a concurrent multiplayer game into a turn-based
zero-sum game, such that there are strong links between equilibria in
the former and winning strategies in the latter. The proofs of
this section are independent of the type of objectives we consider.</p>
</div>
<div class="section" id="deviators">
<span id="subsection-deviators"></span><h2>Deviators<a class="headerlink" href="#deviators" title="Permalink to this headline">Â¶</a></h2>
<p>A central notion we use is that of <strong>deviators</strong>. These are the
players who have played different moves from those prescribed in a given
profile, thus causing a deviation from the expected outcome. Formally, a
deviator from move
(a_{\Agt}) to (aâ_{\Agt}) is a player
(D \in \Agt) such that (a_D \ne aâ_D) . We denote the set of
deviators by</p>
<div class="math notranslate nohighlight">
\[
        \Dev(a_{\Agt} , a'_{\Agt} ) = \{D \in \Agt \mid a_D \ne a'_D \}.
\]</div>
<p>We extend the definition to pairs of histories and strategies by
taking the union of deviator sets of each step along the history.
Formally,</p>
<div class="math notranslate nohighlight">
\[
\Dev(\pi, \sigma_{\Agt}) = \bigcup_{0\le i &lt; |h|}~ \Dev(\move_i(\pi), \sigma_{\Agt}(\pi_{\le i})).
\]</div>
<p>For an infinite play (\rho), we define</p>
<p>(\Dev(\rho, \sigma_{\Agt} ) = \bigcup_{i \in \mathbb{N}} \Dev(\move_i(\rho), \sigma_{\Agt}(\rho_{\le i} ))).
Intuitively, having chosen a strategy profile (\sigma_{\Agt}) and
observed a play (\rho), deviators represent the players that must have
changed their strategies from (\sigma_{\Agt}) in order to generate
(\rho).</p>
<div class="proof lemma admonition" id="13-lem:deviator">
<p class="admonition-title"><span class="caption-number">Lemma 364 </span> (NEEDS TITLE 13-lem:deviator)</p>
<div class="lemma-content section" id="proof-content">
<p>Given a play (\rho), strategy profile <span class="math notranslate nohighlight">\(\sigma_\Agt\)</span>, a coalition (\Coalition)
contains (\Dev(\rho)), if and only if, there exists a strategy
(\sigmaâ<em>\Coalition) such that (\textrm{Out}rho_1, \sigma</em>{-\Coalition}, \sigmaâ_\Coalition) = \rho).</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Assume that coalition (\Coalition) contains
(\Dev(\rho, \sigma_{\Agt})). We define the strategy (\sigma_\Coalition) to be
such that for all (i\in \mathbb{N}),
(\sigma_\Coalition(\rho_{\le i} ) = (\move_i(\rho))<em>\Coalition). By hypothesis, we have,
for all indices (i),
(\Dev(\move_i(\rho), \sigma</em>{\Agt}(\rho_{\leq i})) \subseteq \Coalition), so for
all players (A\not\in \Coalition),
(\sigma_A(\rho_{\le i}) = (\move_i(\rho))<em>A). Then
(\Delta(\rho_i, \sigmaâ</em>\Coalition(\rho_{\le i}), \sigma_{-\Coalition}(\rho_{\le i})) = \rho_{i+1}).
Hence (\rho) is the outcome of the profile
((\sigma_{-\Coalition}, \sigmaâ_\Coalition)).</p>
<p>For the other direction, let (\sigma_{\Agt}) be a strategy profile,
(\sigmaâ<em>\Coalition) a strategy for coalition (\Coalition), and
(\rho \in Out_G(\rho_0 , \sigma</em>{-\Coalition}, \sigmaâ<em>\Coalition)). We have for all
indices (i) that
(\move_i(\rho) = (\sigma</em>{-\Coalition}(\rho_{\le i}), \sigmaâ<em>\Coalition(\rho</em>{\le i}))).
Therefore for all players (A \not\in \Coalition),
((\move_i(\rho))<em>A = \sigma_A(\rho</em>{\le i})). Then
(\Dev(\move_i(\rho), \sigma_{\Agt}(\rho_{\le i})) \subseteq \Coalition). Hence
(\Dev(\rho, \sigma_{\Agt}) \subseteq \Coalition).</p>
</div>
<div class="proof example admonition" id="example-10">
<p class="admonition-title"><span class="caption-number">Example 365 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>In the example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, we consider again the strategies,
such that for all histories <span class="math notranslate nohighlight">\(\pi\)</span>, <span class="math notranslate nohighlight">\(\sigma_{P_1}(\pi) = a\)</span>,
<span class="math notranslate nohighlight">\(\sigma_{P_2}(v_0) = a\)</span> and if <span class="math notranslate nohighlight">\(\pi \ne v_0\)</span>, <span class="math notranslate nohighlight">\(\sigma_{P_2}(\pi) = b\)</span>,
and <span class="math notranslate nohighlight">\(\sigma_{P_3}(\pi) = b\)</span>.
Then <span class="math notranslate nohighlight">\(\Dev(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1 \cdot
  (a, b, a) \cdot v_2, \sigma_{\Agt})\)</span> is the union of:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0), (a, a, b)) = \Dev((a, a, b), (a, a, b)) = \varnothing\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0 \cdot (a, a, b) \cdot v_2), (a, a, b)) =
\Dev( (a, b, b), (a, a, b)) = \{P_2\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1), (a, b, a)) =
\Dev( (a, b, b), (a, b, a)) = \{P_3\}\)</span>.</p></li>
</ul>
<p>We obtain
<span class="math notranslate nohighlight">\(\Dev(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1 \cdot
  (a, b, a) \cdot v_2, \sigma_{\Agt}) = \{ P_2, P_3\}\)</span>.
This means that both <span class="math notranslate nohighlight">\(P_2\)</span> and <span class="math notranslate nohighlight">\(P_3\)</span> need to change their strategies
from <span class="math notranslate nohighlight">\(\sigma_{\Agt}\)</span> to obtain the given history.</p>
<p>In the example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, we consider again the strategies,
such that for all histories <span class="math notranslate nohighlight">\(\pi\)</span>, <span class="math notranslate nohighlight">\(\sigma_{P_1}(\pi) = a\)</span>,
<span class="math notranslate nohighlight">\(\sigma_{P_2}(v_0) = a\)</span> and if <span class="math notranslate nohighlight">\(\pi \ne v_0\)</span>, <span class="math notranslate nohighlight">\(\sigma_{P_2}(\pi) = b\)</span>,
and <span class="math notranslate nohighlight">\(\sigma_{P_3}(\pi) = b\)</span>.
Then <span class="math notranslate nohighlight">\(\Dev(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1 \cdot
  (a, b, a) \cdot v_2, \sigma_{\Agt})\)</span> is the union of:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0), (a, a, b)) = \Dev((a, a, b), (a, a, b)) = \varnothing\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0 \cdot (a, a, b) \cdot v_2), (a, a, b)) =
\Dev( (a, b, b), (a, a, b)) = \{P_2\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Dev(\sigma_{\Agt}(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1), (a, b, a)) =
\Dev( (a, b, b), (a, b, a)) = \{P_3\}\)</span>.</p></li>
</ul>
<p>We obtain
<span class="math notranslate nohighlight">\(\Dev(v_0 \cdot (a, a, b) \cdot v_2 \cdot (a, a, b) \cdot v_1 \cdot
  (a, b, a) \cdot v_2, \sigma_{\Agt}) = \{ P_2, P_3\}\)</span>.
This means that both <span class="math notranslate nohighlight">\(P_2\)</span> and <span class="math notranslate nohighlight">\(P_3\)</span> need to change their strategies
from <span class="math notranslate nohighlight">\(\sigma_{\Agt}\)</span> to obtain the given history.</p>
</div>
</div><p>Note that Nash equilibria are defined only with respect to deviations by
single players, that is, we require all players to achieve worse or equal
payoffs than the prescribed profile when they single-handedly change
strategies. Thus, only the outcomes with singleton deviator sets
will be of interest for us in the next section where we present the algorithm.</p>
</div>
<div class="section" id="deviator-game">
<span id="id1"></span><h2>Deviator Game<a class="headerlink" href="#deviator-game" title="Permalink to this headline">Â¶</a></h2>
<p>We now present an algorithm to reduce multiplayer games to two-player games
using the notion of deviators we just defined.</p>
<p>Given a <strong>game</strong>
(\mathcal{G} = (\mathcal{A}, (\payoff_A)_{A \in \Agt})),</p>
<p>we define the deviator game, denoted (\devg(\mathcal{G})).</p>
<p>Intuitively, in this game, Eve needs to play
according to an equilibrium, while Adam tries to find a profitable
deviation for any player. The vertices are (Vâ = V \times 2^{\Agt}),
where the second component, a subset of (\Agt), records the deviators
of the current history.</p>
<p>At each step, Eve chooses an action profile, and Adam chooses the move
that will apply. Adam can either respect Eveâs choice, or pick a
different action profile in which case the deviators will be added to
the second component of the vertex. The game begins in
((v_0 , \varnothing)) and then proceeds as follows: from a vertex
((v, D)), Eve chooses an action profile (a_{\Agt}), and Adam chooses
a possibly different one (aâ<em>{\Agt}). The next vertex is
((\Delta(v, aâ</em>{\Agt} ), D \cup \Dev(a_{\Agt} , aâ_{\Agt} ))).</p>
<div class="proof example admonition" id="example-11">
<p class="admonition-title"><span class="caption-number">Example 366 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>An example of a partial construction of the deviator game for the
example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, is given in figure <code class="xref std std-numref docutils literal notranslate"><span class="pre">13-fig:ex-dev</span></code>.
We cannot represent the full construction here, as there are 40 vertices.</p>
<p>An example of a partial construction of the deviator game for the
example of <a class="reference internal" href="#fig-example1"><span class="std std-numref">Fig. 94</span></a>, is given in figure <code class="xref std std-numref docutils literal notranslate"><span class="pre">13-fig:ex-dev</span></code>.
We cannot represent the full construction here, as there are 40 vertices.</p>
</div>
</div><p>\begin{figure}
\begin{center}
\begin{tikzpicture}
\draw (0,0) node[draw, inner sep=7pt] (I) {<span class="math notranslate nohighlight">\(v_0, \varnothing\)</span>};
\draw (80:4) node[draw, inner sep=7pt] (S10) {<span class="math notranslate nohighlight">\(v_1, \varnothing\)</span>};
\draw (62:4.5) node[draw, inner sep=7pt] (S11) {<span class="math notranslate nohighlight">\(v_1, \{P_1\}\)</span>};
\draw (44:5) node[draw, inner sep=7pt] (S12) {<span class="math notranslate nohighlight">\(v_1, \{P_2\}\)</span>};
\draw (26:6) node[draw, inner sep=7pt] (S13) {<span class="math notranslate nohighlight">\(v_1, \{P_3\}\)</span>};
\draw (8:7) node[draw, inner sep=7pt] (S14) {<span class="math notranslate nohighlight">\(v_1, \{P_1, P_2\}\)</span>};
\draw (-8:6) node[draw, inner sep=7pt] (S15) {<span class="math notranslate nohighlight">\(v_1, \{P_1, P_3\}\)</span>};
\draw (-26:5) node[draw, inner sep=7pt] (S16) {<span class="math notranslate nohighlight">\(v_1, \{P_2, p_3\}\)</span>};
\draw (-44:4.5) node[draw, inner sep=7pt] (S17) {<span class="math notranslate nohighlight">\(v_1, \{P_1, P_2, P_3\}\)</span>};
\draw (-76:4) node[draw, inner sep=7pt] (C2) {<span class="math notranslate nohighlight">\(v_2, \varnothing\)</span>};
\draw (-88:4) node[below] {<span class="math notranslate nohighlight">\(\dots\)</span>};
\draw[-latexâ] (-1, 0) â (I);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, b, a), (a, b, a)\)</span>  \ <span class="math notranslate nohighlight">\((b, a, a), (b, a, a)\)</span>} (S10);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, a), (b, a, a)\)</span> \ <span class="math notranslate nohighlight">\((a, b, a), (b, a, b)\)</span>} (S11);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, a), (a, b, a)\)</span> \ <span class="math notranslate nohighlight">\((b, b, a), (b, a, a)\)</span>} (S12);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, b, a), (a, b, b)\)</span> \ <span class="math notranslate nohighlight">\((b, a, a), (b, a, b)\)</span>} (S13);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, b, a), (b, a, a)\)</span> \ <span class="math notranslate nohighlight">\((b, a, a), (a, b, a)\)</span>} (S14);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, a), (b, a, b)\)</span> \ <span class="math notranslate nohighlight">\((b, b, a), (a, b, b)\)</span>} (S15);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, a), (a, b, b)\)</span> \ <span class="math notranslate nohighlight">\((b, b, a), (b, a, b)\)</span>} (S16);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, b, a), (b, a, b)\)</span> \ <span class="math notranslate nohighlight">\((b, a, a), (a, b, b)\)</span>} (S17);
\draw[-latexâ] (I) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, a), (a, a, a)\)</span> \ <span class="math notranslate nohighlight">\((b, b, b), (b, b, b)\)</span>} (C2);
\end{tikzpicture}
\caption{Example a deviator game construction.}
\label{13-fig:ex-dev}
\end{center}
\end{figure}</p>
<p>We define projections (\proj_{V}) and (\proj_{\Dev}) from (Vâ) to</p>
<p>(V) and from (Vâ) to (2^{\Agt}) respectively, as well as
(\proj_{\Act}) from (Act^{\Agt} \times Act^{\Agt}) to (Act^{\Agt}) which
maps to the second component of the product, that is, Adamâs action.</p>
<p>For a history or play (\rho), define (\pi_{\textrm{Out}\rho)) as the play
(\rhoâ) for which, (\rhoâ<em>i = \proj_V(\rho_i)) and
(\move_i(\rhoâ) = \proj</em>{\Act}(\move_i(\rho))) for all <span class="math notranslate nohighlight">\(i\)</span>. This is thus the play
induced by Adamâs actions.
Let us also denote <span class="math notranslate nohighlight">\(\Dev(\rho) = \proj_{\Dev}(\textrm{last}\rho))\)</span>.</p>
<p>We can associate a strategy of Eve to each strategy profile
(\sigma_{\Agt}) such that she chooses the moves prescribed by
(\sigma_{\Agt}) at each history of (\devg(\mathcal{G})). Formally, we write
(\kappa(\sigma_{\Agt})) for the strategy defined by
(\kappa(\sigma_{\Agt})(\pi) = \sigma_{\Agt}(\proj_{\textrm{Out}\pi))) for all histories <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<p>The following lemma states the correctness of the construction of the
deviator game (\devg(\mathcal{G})), in the sense that it records the set of
deviators in the strategy profile suggested by Adam with respect to the
strategy profile suggested by Eve.</p>
<div class="proof lemma admonition" id="13-prop:correctness-deviator-game">
<p class="admonition-title"><span class="caption-number">Lemma 367 </span> (NEEDS TITLE 13-prop:correctness-deviator-game)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> be a multiplayer game, <span class="math notranslate nohighlight">\(v\)</span> a vertex, (\sigma_{\Agt}) a
strategy profile, and (\sigma_{\exists} = \kappa(\sigma_{\Agt})) the
associated strategy in the deviator game.</p>
<ol>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> If \(\rho \in \Out_{\devg(\mathcal{G})}((v,\emptyset),\sigma_\exists)\), then
</pre></div>
</div>
<p>(\Dev(\proj_{\textrm{Out}\rho), \sigma_{\Agt} ) = \Dev(\rho)).</p>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span> If \(\rho \in \Out_G(v)\) and for all index \(i\),
</pre></div>
</div>
<p>(\rhoâ<em>i = (\rho_i , \Dev(\rho</em>{\le i} , \sigma_{\Agt}))) and
(\move_i(\rhoâ) = (\sigma_{\Agt} (\rho_{\le i} ), \move_i(\rho))), then
(\rhoâ \in \Out_{\devg(\mathcal{G})}((v,\emptyset), \sigma_\exists)).</p>
</li>
</ol>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We prove that for all <span class="math notranslate nohighlight">\(i\)</span>,
(\Dev(\proj_{\textrm{Out}\rho_{\le i} , \sigma_{\Agt}) = \proj_{\Dev} (\rho_{\le i} )),
which implies the property. The property holds for i = 0, since
initially both sets are empty. Assume now that it holds for (i \ge 0).
Then:
\begin{align*}
\Dev(\proj_{\textrm{Out}\rho_{\le i+1}) , \sigma_{\Agt} ) = &amp; \Dev(\proj_{\textrm{Out}\rho_{\le i}), \sigma_{\Agt} ) \cup \Dev(\sigma_{\Agt} (\proj_{\textrm{Out}\rho_{\le i})), \proj_{\Act} (\move_{i+1} (\rho))) \
&amp; \text{(by definition of deviators)}\
=&amp; \Dev (\rho_{\le i} ) \cup \Dev(\sigma_{\Agt} (\proj_{\textrm{Out}(\rho_{\le i}), \proj_{\Act} (\move_{i+1} (\rho))) \
&amp; \text{(by induction hypothesis)} \
= &amp; \Dev (\rho_{\le i} ) \cup \Dev(\sigma_\exists (\rho_{\le i} ), \proj_{\Act} (\move_{i+1}(\rho))) \
&amp; \text{(by definition of (\sigma_\exists) )}\
= &amp; \Dev (\rho_{\le i} ) \cup \Dev(\move_{i+1}(\rho)) \
&amp; \text{(by assumption (\rho \in \Out_{\devg(\mathcal{G})} ((v,\emptyset), \sigma_\exists)))}\
= &amp; \Dev(\rho_{\le i+1} ) \
&amp; \text{(by construction of (\devg(\mathcal{G})))} \
\end{align*}</p>
<p>Which concludes the induction.</p>
<p>We now prove the second part. The property is shown by induction. It
holds for (v_0). Assume it is true up to index (i&gt;0), then
\begin{align*}
\Deltaâ(\rhoâ<em>i , \sigma</em>\exists(\rhoâ<em>{\le i}), \move_i(\rho)) = &amp;
\Deltaâ((\rho_i , \Dev(\rho</em>{\le i} , \sigma_{\Agt})), \sigma_{\exists} (\rhoâ<em>{\le i} ), \move_i(\rho))\
&amp;  \text{(by definition of (\rhoâ))} \
= &amp; \Delta(\rho_i , \move_i(\rho)), \Dev(\rho</em>{\le i}, \sigma_{\Agt}) \cup \Dev(\sigma_{\exists}(\rhoâ<em>{\le i}), \rho</em>{i+1} )) \
&amp;  \text{(by construction of (\Deltaâ) )}\
= &amp; (\rho_{i+1} , \Dev(\rho_{\le i}, \sigma_{\Agt} ) \cup \Dev(\sigma_{\exists}(\rhoâ<em>{\le i}), \rho</em>{i+1} )) \
&amp; \text{(since (\rho) is an outcome of the game)} \
= &amp; (\rho_{i+1} , \Dev(\rho_{\le i} , \sigma_{\Agt} ) \cup \Dev(\sigma_{\Agt} (\rho_{\le i}), \rho_{i+1} )) \
&amp; \text{(by construction of (\sigma_\exists))} \
= &amp; (\rho_{i+1} , \Dev(\rho_{\le i+1} , \sigma_{\Agt} ))\
&amp; \text{(by definition of deviators)} \
= &amp; \rhoâ_{i+1}. \
\end{align*}</p>
</div>
<p>The objective of Eve in the deviator game is defined so that winning
strategies correspond to equilibria of the original game. First, as an
intermediary step, given coalition (\Coalition), player (P) and
bound (b), we will construct an objective stating that we can ensure
that the payoff of <span class="math notranslate nohighlight">\(P\)</span> will not exceed <span class="math notranslate nohighlight">\(b\)</span> even if players in <span class="math notranslate nohighlight">\(\Coalition\)</span> change
their strategies.
Consider the following objective in (\devg(\mathcal{G})):</p>
<div class="math notranslate nohighlight">
\[
  \Omega(\Coalition, P, b) = \{\rho \in \Out_{\devg(\mathcal{G})} \mid \Dev(\rho) \subseteq \Coalition \Rightarrow \payoff_P(\proj_{\textrm{Out}\rho)) \le b\}.
\]</div>
<p>Intuitively, this says that if only players
in <span class="math notranslate nohighlight">\(\Coalition\)</span> deviated from the strategy suggested by Eve, then the payoff
of <span class="math notranslate nohighlight">\(P\)</span> is smaller than <span class="math notranslate nohighlight">\(b\)</span>.
We now show that a strategy ensuring bound (b) for the payoff of
<span class="math notranslate nohighlight">\(P\)</span> against coalition (\Coalition) corresponds to a winning strategy for
(\Omega(\Coalition, P, b)) in the deviator game.</p>
<div class="proof lemma admonition" id="lemma-13">
<p class="admonition-title"><span class="caption-number">Lemma 368 </span> (NEEDS TITLE AND LABEL  \label{13-lem:omegaCAg})</p>
<div class="lemma-content section" id="proof-content">
<p>Let (\Coalition \subseteq \Agt) be a coalition,
(\sigma_{\Agt}) be a strategy profile, (b \in \mathbb{R}) a bound,
and (P) a player. For all strategies (\sigmaâ<em>\Coalition), vertex <span class="math notranslate nohighlight">\(v_0\)</span>,
and coalition \Coalition, (\payoff_P(\Out</em>{\devg(\mathcal{G})}(v_0, \sigma_{-\Coalition}, \sigmaâ<em>\Coalition)) \le b) if, and
only if, (\kappa(\sigma</em>{\Agt})) is winning in (\devg(\mathcal{G})) for objective
(\Omega(\Coalition, P, b)).</p>
<p>\label{13-lem:omegaCAg}
Let (\Coalition \subseteq \Agt) be a coalition,
(\sigma_{\Agt}) be a strategy profile, (b \in \mathbb{R}) a bound,
and (P) a player. For all strategies (\sigmaâ<em>\Coalition), vertex <span class="math notranslate nohighlight">\(v_0\)</span>,
and coalition \Coalition, (\payoff_P(\Out</em>{\devg(\mathcal{G})}(v_0, \sigma_{-\Coalition}, \sigmaâ<em>\Coalition)) \le b) if, and
only if, (\kappa(\sigma</em>{\Agt})) is winning in (\devg(\mathcal{G})) for objective
(\Omega(\Coalition, P, b)).</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let (\rho) be an outcome of
(\sigma_\exists=\kappa(\sigma_{\Agt}) \in \devg(\mathcal{G})). By Lemma
\ref{13-prop:correctness-deviator-game}, we have that
(\Dev(\rho) = \Dev(\proj_V(\rho),\sigma_{\Agt})). By Lemma
\ref{13-lem:deviator}, (\proj_V(\rho)) is the outcome of
((\sigma_{-\Dev(\rho)},\sigmaâ<em>{\Dev(\rho)})) for some
(\sigmaâ</em>{\Dev(\rho)}). If (\Dev(\rho) \subseteq \Coalition), then
(\payoff_P(\proj_V(\rho)) = \payoff_P(\sigma_{-\Coalition},\sigma_{\Coalition\setminus \Dev(\rho)}, \sigmaâ<em>{\Dev(\rho)}) = \payoff_P(\sigma</em>{-\Coalition},\sigmaââ_{\Coalition}))
where (\sigmaââ<em>P = \sigmaâ<em>P) if (P \in \Dev(\rho)) and (\sigma_P)
otherwise. By hypothesis, this payoff is smaller than or equal to (b).
This holds for
all outcomes (\rho) of (\sigma</em>\exists), thus (\sigma</em>\exists) is
a winning strategy for (\Omega(\Coalition,P,b)).</p>
<p>For the other direction, assume (\sigma_\exists = \kappa(\sigma_{\Agt}))
is a winning strategy in (\devg(\mathcal{G})) for (\Omega(\Coalition,P,b)). Let
(\sigmaâ<em>\Coalition) be a strategy for (\Coalition) and (\rho) the outcome of
((\sigmaâ</em>{\Coalition},\sigma_{-{\Coalition}})). By
Lem.~\ref{13-lem:deviator},
(\Dev(\rho,\sigma_{\Agt}) \subseteq \Coalition). By
Lem.~\ref{13-prop:correctness-deviator-game},
(\rhoâ= (\rho_j, \Dev(\rho_{\le j},\sigma_{\Agt}))<em>{j\in \mathbb{N}}) is
an outcome of (\sigma</em>\exists). We have that
(\Dev(\rhoâ) = \Dev(\rho,\sigma_{\Agt}) \subseteq \Coalition). Since
(\sigma_\exists) is winning, (\rho) is such that
(\payoff_P(\proj_V(\rho)) \le b). Since
(\payoff_{P}(\proj_V(\rhoâ)) = \payoff_{P}(\rho)),
this shows that for all strategies (\sigmaâ<em>\Coalition),
(\payoff_P(\sigma</em>{-\Coalition},\sigmaâ_\Coalition) \le b).</p>
</div>
<p>Now, Eve can show that there is a Nash equilibrium in a given game
by proving that whenever there is a single deviator,
the deviating player does not gain more than without the deviation,
while she does not have to prove anything on plays involving several
deviators.</p>
<div class="proof theorem admonition" id="13-thm:dev-nash">
<p class="admonition-title"><span class="caption-number">Theorem 369 </span> (NEEDS TITLE 13-thm:dev-nash)</p>
<div class="theorem-content section" id="proof-content">
<p>Let (\mathcal{G} = (\mathcal{A}, (\payoff_P)<em>{P \in \Agt})) be a game, (\sigma</em>{\Agt}) a strategy
profile in (\mathcal{G}), vertex <span class="math notranslate nohighlight">\(v_0\)</span>, and (F = (\payoff_P(\Out_{\mathcal{A}}(v_0,\sigma_{\Agt})))<em>{P\in \Agt})
the payoff
profile of (\sigma</em>{\Agt}) from <span class="math notranslate nohighlight">\(v_0\)</span>. The strategy profile (\sigma_{\Agt}) is a
Nash equilibrium if, and only if, strategy (\kappa(\sigma_{\Agt})) is
winning in (\devg(\mathcal{A})) for the objective (N(F)) defined by:</p>
<div class="math notranslate nohighlight">
\[N(F) = \{\rho \mid |\Dev(\rho)| \ne 1\}
    \cup \bigcup_{P\in \Agt} \{\rho \mid \Dev(\rho) = \{P\}
    \land \payoff_P(\proj_{\textrm{Out}\rho)) \le F_P\}.\]</div>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>By  <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">13-lem:omegaCAg</span></code>, (\sigma_{\Agt}) is a Nash
equilibrium if, and only if, for each player (P),</p>
<p>(\kappa(\sigma_{\Agt})) is winning for</p>
<p>(\Omega({P}, P, F_P)).
So it is enough to show that for each player (P),
(\kappa(\sigma_{\Agt})) is winning for
(\Omega({P},P, F_P)) if,</p>
<p>and only if, (\kappa(\sigma_{\Agt})) is winning for (N(F)).</p>
<p><strong>Implication</strong> Let (\rho) be an outcome of
(\kappa(\sigma_{\Agt})).</p>
<ul class="simple">
<li><p>If (|\Dev(\rho)| \ne 1), then (\rho) is in (N(F)) by
definition.</p></li>
<li><p>If (|\Dev(\rho)| = 1), then for ({P} = \Dev(\rho)),
(\payoff_P(\proj_{\textrm{Out}\rho)) \leq F_P) because
(\kappa(\sigma_{\Agt})) is winning for
(\Omega(\Dev(\rho), P, F_P)). Therefore (\rho) is
in (N(F)).</p></li>
</ul>
<p>This holds for all outcomes (\rho) of (\kappa(\sigma_{\Agt})) and shows
that (\kappa(\sigma_{\Agt})) is winning for (N(F)).</p>
<p><strong>Reverse implication</strong>
Assume that
(\kappa(\sigma_{\Agt})) is winning for (N(F)). We now show that
(\kappa(\sigma_{\Agt})) is winning for
(\Omega({P},P, F_P)) for each player (P). Let
(\rho) be an outcome of (\kappa(\sigma_{\Agt})), we have
(\rho \in N(F)). We show that (\rho) belongs to
(\Omega({P}, P, F_P)):</p>
<ul class="simple">
<li><p>If (\Dev(\rho) = \varnothing) then (\rho = \outv_0, \sigma_{\Agt})) and
(\payoff_P(\rho) = F_P), so (\rho) is in
(\Omega({P},P, F_P))</p></li>
<li><p>If (\Dev(\rho) \not\subseteq { P }), then
(\rho \in \Omega(\Coalition,P,F_P)) by definition.</p></li>
<li><p>Otherwise (\Dev(\rho) = {P}). Since (\rho \in N(F)),
(\payoff_P(\rho) \le F_P). Hence
(\rho \in \Omega(\Coalition,P,F_P)).</p></li>
</ul>
<p>This holds for all outcomes (\rho) of (\kappa(\sigma_{\Agt})) and shows
it is winning for (\Omega({P},P,F_P)) for each
player (P\in \Agt), which shows that (\sigma_{\Agt}) is a Nash
equilibrium.</p>
</div>
<div class="section" id="algorithm-for-parity-objectives">
<span id="subsec-algorithm-for-parity-objectives"></span><h3>Algorithm for Parity Objectives<a class="headerlink" href="#algorithm-for-parity-objectives" title="Permalink to this headline">Â¶</a></h3>
<p>We now focus on the case of Parity objectives.
Recall that
Each player <span class="math notranslate nohighlight">\(P\)</span> has
a colouring function <span class="math notranslate nohighlight">\(c_P : V \rightarrow \mathbb{N}\)</span>, inducing the parity objective <span class="math notranslate nohighlight">\(\Omega_A\)</span>.</p>
<p>Thus the payoff <span class="math notranslate nohighlight">\(\payoff_Ps\)</span> assigns 1 to paths belonging to <span class="math notranslate nohighlight">\(\Omega_A\)</span> and 0
to the others.</p>
<p>We now give an algorithm for the Nash equilibrium problem with parity
objectives. Given a payoff for each player ((F_P)<em>{P\in \Agt} ),
we can deduce from the previous theorem an algorithm that
constructs a Nash equilibrium if there exists one. We construct the
deviator game and note that we can reduce the number of vertices as
follows: since  (\Dev(\rho</em>{\le k})) is nondecreasing,
we know that \textrm{Eve}wins whenever this set has at least two elements.
In the construction, states with at least two deviators can be replaced by a
sink vertex that is winning for \textrm{Eve} This means that the constructed
game has at most (n \times (|\Agt| + 1) + 1) states.</p>
<p>The objective can be expressed as a Parity condition in the following
way:</p>
<ul class="simple">
<li><p>for each vertex (vâ = (v, { P })), (câ(vâ) = c_P(v) + 1) if
(F_P = 0) and (2 \cdot \max_v c_P(v) ) otherwise;</p></li>
<li><p>for each vertex (vâ = (v, D)) with (|D| \ne 1), (câ(vâ) = 2 \cdot \max_v c_P(v))
i.e.~it is winning for Eve.</p></li>
</ul>
<p>Notice that the colouring function <span class="math notranslate nohighlight">\(c'\)</span> inverts the parity
in the case where there is a single deviator who is losing in the
prescribed strategy profile (that is, <span class="math notranslate nohighlight">\(F_P=0\)</span>). In fact,
when <span class="math notranslate nohighlight">\(F_P=1\)</span>, the player cannot obtain more since they are already winning
so the colour is set to <span class="math notranslate nohighlight">\(2\cdot \max_v c_P(v) \)</span> which is winning for \textrm{Eve}</p>
<div class="proof lemma admonition" id="lemma-15">
<p class="admonition-title"><span class="caption-number">Lemma 370 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>We have (\maxinf(câ(\rho_i)) \in 2 \mathbb{N}) if, and
only if, (\rho\in N(F)),
where <span class="math notranslate nohighlight">\(N(F)\)</span> is as defined in  <a class="reference internal" href="#13-thm:dev-nash">Theorem 369</a>.</p>
<p>We have (\maxinf(câ(\rho_i)) \in 2 \mathbb{N}) if, and
only if, (\rho\in N(F)),
where <span class="math notranslate nohighlight">\(N(F)\)</span> is as defined in  <a class="reference internal" href="#13-thm:dev-nash">Theorem 369</a>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>For the implication, we will prove the contrapositive.
Let (\rho) be a play not in (N(F)), then since the deviators can only
increase along a play, we have that (\Dev(\rho) = { P }) for some
player (P) and (\payoff_P(\rho) &gt; F_P). This means
(F_P = 0) and (\maxinf(c_P(\rho_i)) \in 2 \mathbb{N}). By
definition of (câ) this implies that
(\maxinf(câ(\rho_i)) \in 2 \mathbb{N} + 1) which proves the
implication.</p>
<p>For the other implication, let (\rho) be such that
(\maxinf(câ(\rho_i)) \in 2 \mathbb{N} + 1). By definition of
(câ) this means (\rho) contains infinitely many states of the form
((v, {P})) with (F_P = 0). Since the deviators only increase
along the run, there is a player (P) such that (\rho) stays in the
component (V \times {P}) after some index (k). Then for (i\geq k),
(câ(\rho_i) = c_P(\rho_i)+1), hence
(\maxinf(câ(\rho_i)) = \maxinf(c_P(\rho_i)) + 1).
Therefore (\maxinf(c_P(\rho_i)) \in 2 \mathbb{N}), which means
(\payoff_P(\rho) = 1 &gt; F_P). By definition of (N(F)),
(\rho\not\in N(F)).</p>
</div>
<p>Given that the size of the game is polynomial and that parity games can
be decided in quasipolynomial time (see \Cref{3-corollary:quasipoly}), the preceeding lemma
implies the following theorem.</p>
<div class="proof theorem admonition" id="theorem-16">
<p class="admonition-title"><span class="caption-number">Theorem 371 </span> (NEEDS TITLE AND LABEL)</p>
<div class="theorem-content section" id="proof-content">
<p>For parity games, there is a quasipolynomial algorithm to decide whether there is a Nash
equilibrium with a given payoff.</p>
<p>For parity games, there is a quasipolynomial algorithm to decide whether there is a Nash
equilibrium with a given payoff.</p>
</div>
</div></div>
</div>
<div class="section" id="extensions-of-nash">
<span id="subsection-extensions-of-nash-equilibria"></span><h2>Extensions of Nash<a class="headerlink" href="#extensions-of-nash" title="Permalink to this headline">Â¶</a></h2>
<p>Equilibria</p>
<div class="section" id="subgame-perfect">
<span id="subsection-subgame-perfect-equilibria"></span><h3>Subgame Perfect<a class="headerlink" href="#subgame-perfect" title="Permalink to this headline">Â¶</a></h3>
<p>Equilibria</p>
<p>Nash equilibria present the disadvantage that once a player has deviated,
the others will try to punish him, forgetting everything about their own
objectives.
If we were to observe the game after this point of
deviation, it would not look like the players are playing rationally and
in fact it would not correspond to a Nash equilibrium. The concept of
<strong>subgame perfect equilibria</strong> refines the concept of Nash
equilibrium by imposing that at each step of the history, the strategy
behaves like Nash equilibrium if we were to start the game now. Formally,
let us write (\sigma_P \circ h) the strategy which maps all histories
(hâ) to (\sigma_P(h \cdot hâ)), that is the strategy that behave
like (\sigma_P) after (h). Then ((\sigma_P)<em>{P\in \Agt}) is a
<strong>subgame perfect equilibrium</strong> if for all histories (h),
((\sigma_P \circ h)</em>{P \in \Agt}) is a Nash equilibrium.</p>
<p>Imposing such a strong restriction is justified by the fact that subgame
perfect Nash equilibria exist for a large class of games. In particular
subgame perfect equilibria always exist in turn-based games with
reachability objectives.</p>
<div class="proof example admonition" id="example-17">
<p class="admonition-title"><span class="caption-number">Example 372 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>Consider the example of <code class="xref std std-numref docutils literal notranslate"><span class="pre">13-fig:ex-subgame</span></code>.
There is a Nash equilibria whose outcome goes through states
<span class="math notranslate nohighlight">\(v_0 \rightarrow v_1 \rightarrow \Omega_1\)</span>.
In this equilibrium, Player <span class="math notranslate nohighlight">\(1\)</span> should play <span class="math notranslate nohighlight">\(b\)</span> in <span class="math notranslate nohighlight">\(v_2\)</span>,
so that the best response of Player <span class="math notranslate nohighlight">\(2\)</span> is to play <span class="math notranslate nohighlight">\(a\)</span> at <span class="math notranslate nohighlight">\(v_0\)</span>.
Intuitively, player <span class="math notranslate nohighlight">\(1\)</span> is threatening player <span class="math notranslate nohighlight">\(2\)</span>, to make them
both lose from <span class="math notranslate nohighlight">\(v_2\)</span>, but this threat is not credible,
and the profile is not a subgame perfect equilibrium.
In fact, once <span class="math notranslate nohighlight">\(v_2\)</span> is reached it is better for Player <span class="math notranslate nohighlight">\(1\)</span>
to play <span class="math notranslate nohighlight">\(a\)</span> so it is unlikely that the player will execute the said threat.
The only subgame perfect equilibrium of this game ends in
the vertex satisfying both
<span class="math notranslate nohighlight">\(\Omega_1\)</span> and <span class="math notranslate nohighlight">\(\Omega_2\)</span>.</p>
<p>Consider the example of <code class="xref std std-numref docutils literal notranslate"><span class="pre">13-fig:ex-subgame</span></code>.
There is a Nash equilibria whose outcome goes through states
<span class="math notranslate nohighlight">\(v_0 \rightarrow v_1 \rightarrow \Omega_1\)</span>.
In this equilibrium, Player <span class="math notranslate nohighlight">\(1\)</span> should play <span class="math notranslate nohighlight">\(b\)</span> in <span class="math notranslate nohighlight">\(v_2\)</span>,
so that the best response of Player <span class="math notranslate nohighlight">\(2\)</span> is to play <span class="math notranslate nohighlight">\(a\)</span> at <span class="math notranslate nohighlight">\(v_0\)</span>.
Intuitively, player <span class="math notranslate nohighlight">\(1\)</span> is threatening player <span class="math notranslate nohighlight">\(2\)</span>, to make them
both lose from <span class="math notranslate nohighlight">\(v_2\)</span>, but this threat is not credible,
and the profile is not a subgame perfect equilibrium.
In fact, once <span class="math notranslate nohighlight">\(v_2\)</span> is reached it is better for Player <span class="math notranslate nohighlight">\(1\)</span>
to play <span class="math notranslate nohighlight">\(a\)</span> so it is unlikely that the player will execute the said threat.
The only subgame perfect equilibrium of this game ends in
the vertex satisfying both
<span class="math notranslate nohighlight">\(\Omega_1\)</span> and <span class="math notranslate nohighlight">\(\Omega_2\)</span>.</p>
</div>
</div><p>\begin{figure}
\begin{center}<br />
\begin{tikzpicture}
\draw (0,0) node[draw, inner sep=7pt] (V0) {<span class="math notranslate nohighlight">\(v_0\)</span>};
\draw (3,1) node[draw, inner sep=7pt] (V1) {<span class="math notranslate nohighlight">\(v_1\)</span>};
\draw (3,-1) node[draw, inner sep=7pt] (V2) {<span class="math notranslate nohighlight">\(v_2\)</span>};
\draw (6,2) node[draw, inner sep=7pt] (V3) {<span class="math notranslate nohighlight">\(\Omega_1\)</span>};
\draw (6,0.6) node[draw, inner sep=7pt] (V4) {<span class="math notranslate nohighlight">\(\Omega_2\)</span>};
\draw (6,-0.6) node[draw, inner sep=7pt] (V5) {<span class="math notranslate nohighlight">\(\Omega_1, \Omega_2\)</span>};
\draw (6,-2) node[draw, inner sep=7pt] (V6) {<span class="math notranslate nohighlight">\(\varnothing\)</span>};</p>
<p>\draw[-latexâ] (-1, 0) â (V0);
\draw[-latexâ] (V0) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, a)\)</span>} (V1);
\draw[-latexâ] (V0) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, b)\)</span>} (V2);
\draw[-latexâ] (V1) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((a, \ast)\)</span>} (V3);
\draw[-latexâ] (V1) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((b, \ast)\)</span>} (V4);
\draw[-latexâ] (V2) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((a, \ast)\)</span>} (V5);
\draw[-latexâ] (V2) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((b, \ast)\)</span>} (V6);
\draw[-latexâ] (V3) .. controls +(2,1) and +(2,-1) .. (V3);
\draw[-latexâ] (V4) .. controls +(2,1) and +(2,-1) .. (V4);
\draw[-latexâ] (V5) .. controls +(2,1) and +(2,-1) .. (V5);
\draw[-latexâ] (V6) .. controls +(2,1) and +(2,-1) .. (V6);
\end{tikzpicture}
\caption{Two-player game with reachability objectives. The goal of
player 1 is to reach a state labeled with <span class="math notranslate nohighlight">\(\Omega_1\)</span> and that of
player 2 is to reach a state labeled with <span class="math notranslate nohighlight">\(\Omega_2\)</span>. }
\label{13-fig:ex-subgame}
\end{center}
\end{figure}</p>
</div>
<div class="section" id="robust-equilibria">
<span id="subsec-robust-equilibria"></span><h3>Robust equilibria<a class="headerlink" href="#robust-equilibria" title="Permalink to this headline">Â¶</a></h3>
<p>The notion of robust equilibria refines Nash equilibria in two ways:</p>
<ul class="simple">
<li><p>a robust equilibrium is <strong>resilient</strong>, i.e.~when a small coalition
change its strategy, none of the players of the coalition improves their
payoff;</p></li>
<li><p>it is <strong>immune</strong>, i.e.~when a small coalition changes its strategy,
it does not decrease the payoffs of the non-deviating players.</p></li>
</ul>
<p>The size of small coalitions is determined by parameter (k) for
resilience and (t) for immunity. When a strategy is both
(k)-resilient and (t)-immune, it is called a ((k,t))-robust
equilibrium.</p>
<p>The motivation behind this concept is to address these two weaknesses of
Nash equilibra:</p>
<ul class="simple">
<li><p>There is no guarantee on payoffs when two (or more) players deviate together.
Such a situation can occur in networks if the same person controls several devices
(a laptop and a phone for instance) and can then coordinate their
behaviours. In this case, the devices would be considered as different
players and Nash equilibria can offer no guarantee.</p></li>
<li><p>When a deviation occurs, the strategies of the equilibrium can punish
the deviating user without any regard for the payoffs of the others. This
can result in a situation where, because of a faulty device, nobody
can use the protocol anymore.</p></li>
</ul>
<p>By comparison, finding resilient equilibria with (k&gt;1),
ensures that clients have no interest in forming coalitions (up
to size (k)), and finding immune equilibria with (t&gt;0)
ensures that other clients will not suffer from some players (up to
(t)) behaving differently from what was expected.</p>
<p>The deviator construction can be reused for finding such equilibria. We
only need to adapt the objectives. Given a game (G=(\mathcal{A}, (\payoff_P)<em>{P \in \Agt})), a
strategy profile (\sigma</em>{\Agt}), and parameters (k), (t), we have</p>
<ul class="simple">
<li><p>The strategy profile (\sigma_{\Agt}) is (k)-resilient if, and only
if, strategy (\kappa(\sigma_{\Agt})) is winning in (\devg(\mathcal{A})) for the
<strong>resilience objective</strong> (\mathcal{R}(k,F)) where
(F = (\payoff_P(\Out_{\mathcal{A}}(v_0, \sigma_{\Agt})))<em>{P \in \Agt}) is the payoff profile of
(\sigma</em>{\Agt}) and (\mathcal{R}(k,F)) is defined by:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{array}{ll}
      \mathcal{R}(k,F) = &amp; \{ \rho \in \Out_{\devg(\mathcal{A})}\mid ~ |\Dev(\rho)| &gt; k \} \\
                          &amp;\cup
                            \{ \rho  \in \Out_{\devg(\mathcal{A})} \mid ~ |\Dev(\rho)| = k \land \forall P \in \Dev(\rho).\ \payoff_{P}(\proj_{\textrm{Out}\rho)) \le F_P\} \\
                          &amp; \cup \{ \rho  \in \Out_{\devg(\mathcal{A})}\mid ~ |\Dev(\rho)| &lt; k \land \forall P \in \Agt.\ \payoff_{P}(\proj_{\textrm{Out}\rho)) \le F_P\}.
    \end{array}
  \end{split}\]</div>
<ul class="simple">
<li><p>The strategy profile (\sigma_{\Agt}) is (t)-immune if, and only if,
strategy (\kappa(\sigma_{\Agt})) is winning for the <strong>immunity
objective</strong> (\mathcal{I}(t,F)) where
(F = (\payoff(\Out_{\mathcal{A}}(v_0, \sigma_{\Agt})))<em>{P \in \Agt}) is the payoff profile of
(\sigma</em>{\Agt}) and (\mathcal{I}(t,F)) is defined by:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{array}{ll}
    \mathcal{I}(t,F) = &amp; \{ \rho  \in \Out_{\devg(\mathcal{A})} \mid |\Dev(\rho)| &gt; t \}  \\
      &amp; \cup \{ \rho  \in \Out_{\devg(\mathcal{A})} \mid ~ \forall P \in \Agt \setminus \Dev(\rho).\  F_P \le \payoff_{P}(\proj_{\textrm{Out}\rho)) \}.
    \end{array}
  \end{split}\]</div>
<ul class="simple">
<li><p>The strategy profile (\sigma_{\Agt}) is a ((k,t))-robust profile in
(G) if, and only if, (\kappa(\sigma_{\Agt})) is winning for the
<strong>robustness objective</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
        \mathcal{R}(k,t,F)= \mathcal{R}(k,F) \cap \mathcal{I}(t,F),
        \]</div>
<p>where
(F = (\payoff_P(\Out_{\mathcal{A}}(v_0, \sigma_{\Agt})))<em>{P \in \Agt}) is the payoff profile of
(\sigma</em>{\Agt}).</p>
<p>We omit the proof and encourage the reader to do it by themselves.</p>
</div>
<div class="section" id="extension-to-games-with-hidden-actions">
<span id="subsec-extension-to-games-with-hidden-actions"></span><h3>Extension to games with hidden actions<a class="headerlink" href="#extension-to-games-with-hidden-actions" title="Permalink to this headline">Â¶</a></h3>
<p>In most practical cases, players only have a partial view of the
state of the system; so they may not be able, for instance, to
detect a deviating player immediately.
Studying equilibria in general imperfect information as in \Cref{chap:signal}
would be well adapted in such situations.
Unfortunately, these games are too powerful in general since
the existence of Nash equilibria is undecidable in this case.</p>
<p>Nevertheless, the problem is decidable for a restricted form of imperfect
information where the players observe the visited states
but do not see the played actions; thus the actions are <strong>hidden</strong>.</p>
<p>We will thus consider strategies defined as functions from (V^*) to (Act),
which represents the fact that playersâ decision can only depend on observed
sequence of states but not on other playersâ actions.</p>
<p>In this case, deviators cannot be defined as obviously as before, as it may
not always be possible to identify one unique deviator responsible for a
deviation. The construction will thus maintain a set of <strong>suspects</strong>, those players that might have been
responsible for the observed deviation.
Formally, suspects for an edge ((v, vâ)) with respect to a move
((a_P)_{P\in \Agt}) are players (P) such that there is (aâ_P) and
(\Delta(aâ<em>P, a</em>{-P}) = (v, vâ)). Rather than computing the
union of deviators along a history, we now consider the intersection of
suspects. That is, if at vertex <span class="math notranslate nohighlight">\(v\)</span>, the suspect set is <span class="math notranslate nohighlight">\(S\)</span>, and the strategy profile is <span class="math notranslate nohighlight">\(\sigma_\Agt\)</span>,
and if the next vertex is <span class="math notranslate nohighlight">\(v'\)</span>, then
the suspect set becomes <span class="math notranslate nohighlight">\(S \cap \{ P \in \Agt \mid \exists a'_P, \Delta(a'_P, a_{-P}) = (v, v')\}\)</span>.</p>
<p>The <strong>suspect game</strong> can be defined just like the deviator game by replacing the deviators component
by the suspects component.
The objective for Eve is that no suspect player improves their payoff. In fact, in
case of deviation, we know that the deviator belongs to the set of suspects although
we cannot know which one has deviated for sure so Eve must ensure this for all suspects.</p>
<div class="proof example admonition" id="example-18">
<p class="admonition-title"><span class="caption-number">Example 373 </span> (NEEDS TITLE AND LABEL)</p>
<div class="example-content section" id="proof-content">
<p>Consider the example of figure~\ref{fig:hidden}.
If actions were visible there would be an equilibrium ending in the
state labeled with <span class="math notranslate nohighlight">\(\Omega_3\)</span>: player 3 simply has to punish the player
who would deviate from this path.
But if we now consider hidden actions, in case of a deviation, player 3
would observe that the play went arrives in <span class="math notranslate nohighlight">\(v_1\)</span> instead of <span class="math notranslate nohighlight">\(v_2\)</span>
and both Player 1 and Player 2 are suspects.
Since Player 3 cannot punish both players at the same time, there is no
Nash equilibrium ending satisfying <span class="math notranslate nohighlight">\(\Omega_3\)</span>.</p>
<p>Consider the example of figure~\ref{fig:hidden}.
If actions were visible there would be an equilibrium ending in the
state labeled with <span class="math notranslate nohighlight">\(\Omega_3\)</span>: player 3 simply has to punish the player
who would deviate from this path.
But if we now consider hidden actions, in case of a deviation, player 3
would observe that the play went arrives in <span class="math notranslate nohighlight">\(v_1\)</span> instead of <span class="math notranslate nohighlight">\(v_2\)</span>
and both Player 1 and Player 2 are suspects.
Since Player 3 cannot punish both players at the same time, there is no
Nash equilibrium ending satisfying <span class="math notranslate nohighlight">\(\Omega_3\)</span>.</p>
</div>
</div><p>\begin{figure}
\begin{center}
\begin{tikzpicture}
\draw (0,0) node[draw, inner sep=7pt] (V0) {<span class="math notranslate nohighlight">\(v_0\)</span>};
\draw (3,1) node[draw, inner sep=7pt] (V1) {<span class="math notranslate nohighlight">\(v_1\)</span>};
\draw (3,-1) node[draw, inner sep=7pt] (V2) {<span class="math notranslate nohighlight">\(v_2\)</span>};
\draw (6,2) node[draw, inner sep=7pt] (V3) {<span class="math notranslate nohighlight">\(\Omega_1\)</span>};
\draw (6,0.6) node[draw, inner sep=7pt] (V4) {<span class="math notranslate nohighlight">\(\Omega_2\)</span>};
\draw (6,-0.6) node[draw, inner sep=7pt] (V5) {<span class="math notranslate nohighlight">\(\Omega_3\)</span>};
\draw (6,-2) node[draw, inner sep=7pt] (V6) {<span class="math notranslate nohighlight">\(\varnothing\)</span>};</p>
<p>\draw[-latexâ] (-1, 0) â (V0);
\draw[-latexâ] (V0) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, a, \ast)\)</span>\<span class="math notranslate nohighlight">\((b, b, \ast)\)</span>} (V1);
\draw[-latexâ] (V0) â node[sloped, text width=1cm]{<span class="math notranslate nohighlight">\((a, b, \ast)\)</span> \ <span class="math notranslate nohighlight">\((b, a, \ast)\)</span>} (V2);
\draw[-latexâ] (V1) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, \ast, a)\)</span>} (V3);
\draw[-latexâ] (V1) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, \ast, b)\)</span>} (V4);
\draw[-latexâ] (V2) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, \ast, a)\)</span>} (V5);
\draw[-latexâ] (V2) â node[sloped, text width=1cm, above]{<span class="math notranslate nohighlight">\((\ast, \ast, b)\)</span>} (V6);
\draw[-latexâ] (V3) .. controls +(2,1) and +(2,-1) .. (V3);
\draw[-latexâ] (V4) .. controls +(2,1) and +(2,-1) .. (V4);
\draw[-latexâ] (V5) .. controls +(2,1) and +(2,-1) .. (V5);
\draw[-latexâ] (V6) .. controls +(2,1) and +(2,-1) .. (V6);
k\end{tikzpicture}
\caption{Three-player game with hidden actions. The goal of
player <span class="math notranslate nohighlight">\(i\)</span> is to reach a state labeled with <span class="math notranslate nohighlight">\(\Omega_i\)</span>.}
\label{fig:hidden}
\end{center}
\end{figure}</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./13_Multiplayer"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Multiplayer Games</a>
    <a class='right-next' id="next-link" href="admissible_strategies.html" title="next page">Admissible strategies</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>