At the beginning of the chapter we described three families of algorithms: 
strategy improvement, attractor decomposition, and value iterations.

\vskip1em
Let us first clarify the relationship between the separation framework discussed in \cref{3-sec:separation}
and the value iteration paradigm presented in \cref{3-sec:value_iteration}.
Both are families of algorithms: 
\begin{itemize}
	\item An $(n,d)$-separating automaton $\Automaton$ induces an algorithm for solving parity games in time 
$O(m \cdot |\Automaton|)$ where $|\Automaton|$ is the size of $\Automaton$, meaning the number of states.
	\item An $(n,d/2)$-universal tree $T$ induces a value iteration algorithm for solving parity games in time 
proportional to $|T|$ where $|T|$ is the size of $T$, meaning the number of leaves (the exact complexity depends on the cost of computing $\delta$ in $T$, which is typically small).
\end{itemize}
These two families are in a strong sense equivalent:

\begin{theorem}\hfill
\begin{itemize}
	\item An $(n,d)$-separating automaton induces an $(n,d/2)$-universal tree of the same size;
	\item An $(n,d/2)$-universal tree induces an $(n,d)$-separating automaton of the same size.
\end{itemize}
\end{theorem}
We do not prove this theorem here but note that it can be stated more generally for any positionally determined objective,
replacing universal trees by the notion of universal graphs.

The main advantage of the value iteration presentation is the space complexity, which for a good choice of the universal tree
can be made very small (quasilinear).

\vskip1em
In terms of complexity, the strategy improvement has exponential complexity, while both attractor decompositions and value iterations algorithms have quasipolynomial complexity.
Let us make a finer comparison: the complexity of the attractor decomposition algorithm is a polynomial multiplied by the (non polynomial) term
\[
\binom{\lceil \log(n) \rceil + d - 1}{\lceil \log(n) \rceil},
\]
while for the value iteration algorithm the complexity is a polynomial multiplied by the (also non polynomial) term
\[
\binom{\lceil \log(n) \rceil + d/2 - 1}{\lceil \log(n) \rceil}.
\]
The key difference is that the former performs an induction using all priorities, while the latter considers only odd priorities hence the dependence in $d/2$.
Although our presentation of the attractor decomposition algorithm does not make it explicit, 
this class of algorithms is also related to the notion of universal trees; 
however an algorithm is induced not by one $(n,d/2)$-universal tree, but by two: one for each player,
which are then interleaved to organise the recursive calls of the algorithm.

\vskip1em
Since both value iteration and attractor decomposition algorithms are connected to the combinatorial notion of universal trees,
the next question is whether the construction given in \cref{3-sec:value_iteration} is optimal.
The answer is unfortunately yes, there exists a lower bound on the size of universal trees which matches this construction up to polynomial factors.

\vskip1em
The last question we discuss here is whether there exists a quasipolynomial strategy improvement algorithm.
In particular a natural attempt would be to use universal trees for this endeavour.
Unfortunately, this fails: \cref{3-lem:key_property} explains that for the particular choice of the lattice $Y$,
functions $\mu : V \to Y$ can be used both to certify that a graph satisfies parity or that it satisfies the complement of parity.
Both implications are used in the correctness proof of the algorithm.
This symmetric feature is lost with universal trees, which only satisfy one of the two implications, stated in \cref{3-lem:progress_measure}.
