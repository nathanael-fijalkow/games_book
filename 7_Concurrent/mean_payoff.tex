In this section we consider concurrent mean-payoff games. 
We will show that in general, any  $\epsilon$-optimal strategy in some concurrent mean-payoff games are quite complex. 
We will first, however, show that finding the value of a concurrent mean-payoff game can be done in polynomial space.

\begin{lemma}\label{lemm:class_meanpayoff}
Concurrent mean-payoff games are determined and the value is the limit of the value of the corresponding time-limited game as well as the limit of the corresponding discounted game, for the discount factor going to 0 from above.
There is an polynomial time algorithm, ala Lemma~\ref{lem:val1}, for finding the set of vertices where a finite memory strategy suffice to ensure $1-\epsilon$ (recall that all rewards are in $\{0,1\}$).
For any fixed number $n$, there is a polynomial time algorithm for approximating the value in a concurrent mean-payoff game with $n$ vertices (i.e. the running time is polynomial in the number of actions)
\end{lemma}
We will not show this lemma, but simply note that the $\epsilon$-optimal strategies known for general concurrent mean-payoff games  can be viewed as playing the corresponding discounted game with a variable discount factor that depends on how ``nice'' the rewards has been up to now. Basically, in each round you play the optimal strategy in the corresponding discounted game with a discount factor $\gamma$. Whenever 
 your rewards are close to or better than the value, you decrease $\gamma$ towards 0 and in each round your rewards are much worse than the value you let $\gamma$ increase, except not bigger than the initial $\gamma$ in the first round. Much of this section will argue that many natural candidates for simpler types of strategies does not work.


We will show that approximating the value, however, can, as mentioned, be done in polynomial space. The proof relies on Proposition~22 from~\cite{HKLMT:2011}, stating the following:
\begin{proposition}
Let $\epsilon=2^{-j}$, where $j$ is some positive integer, and the probabilities be rational numbers where the nominator and denominator have bitsize at most $\tau$. Also, let $\lambda=\epsilon^{\tau m^{O(n^2)}}$. Consider some state $s$ and let the value of that state in the $\lambda$ discounted game be $v_{\lambda}$ and the value in mean-payoff game be $v$, then $|v-v_{\lambda}|<\epsilon$.
\end{proposition}

We will use that to again reduce to the existential theory over the reals. 
For a fixed discount factor $\gamma$, we can easily express the value of the corresponding discounted game, like we expressed the value of a concurrent reachability game.
We have that the value $v$ is then $v=\lim_{\gamma\rightarrow 0^+} f(\gamma)$, where $f$ is the found expression.
I.e. for any $\epsilon$, there is a $\gamma'$ such that for all $\gamma<\gamma$, we have that $|f(\gamma)-v|\leq \epsilon$.
Also, that $v>c$ means that there is $\epsilon$, such that $v-\epsilon>c$.

The problem is thus to come up with a polynomial sized formula to express that $\lambda$ is $\epsilon^{\tau m^{O(n^2)}}=2^{-j \tau m^{O(n^2)}}$.

That can be done as follows, using $\ell=O(n^2)\cdot \log(m)+\log(j\tau)$ many variables, $v_0,v_1,\dots v_{\ell-1}$:
\[
v_0=1/2
\]
and for all $0<i< \ell$, we have that
\[
v_i=v_{i-1}\cdot v_{i-1}.
\]
Using induction, we see that $v_i=2^{-2^{i}}$, i.e., $v_1=1/2=2^{-2^0}$ and \[
v_i=v_{i-1}\cdot v_{i-1}=2^{-2^{i-1}}\cdot 2^{-2^{i-1}}=2^{-2^{i-1}-2^{i-1}}=2^{-2^{i}}\]
In particular, \[
v_{\ell-1}=2^{-2^{\ell}}=2^{-2^{O(n^2)\cdot \log(m)+\log(j\tau)}}=2^{-j\tau m^{O(n^2)}}
\] is the value we wanted for $\lambda$.
Thus, for a given number $v$, we can test if the value of a concurrent  $\lambda$-discounted game is above $v+\epsilon$, which, using the proposition above, implies that $v$ is below the value of the corresponding concurrent mean-payoff game. On the other hand, the proposition also implies that if the value of the concurrent  $\lambda$-discounted game is below $v-\epsilon$, then the value of the concurrent mean-payoff game is below $v$. Being able to answer these questions lets you easily approximate the value of a concurrent mean-payoff using binary search. 

We get the following lemma.
\begin{lemma}
Approximating the value of a concurrent mean-payoff game can be in done in polynomial space
\end{lemma}



We will now consider a specific, well-studied example of a concurrent mean-payoff game, since it shows that many natural kinds of strategies do not suffice in general.
The game is called the big match and is defined as follows:
There are 3 vertices, $\{0,s,1\}$, where the vertices in $\{0,1\}$ are absorbing, and with value equal to their name.
The last vertex $s$ has a 2x2-matrix and for all $i,j$ for $i\neq j$, we have that 
$c(s,1,1)=1$, and for $i\neq 1\neq j$ we have that $c(s,1,1)=0$.
Also,  $\dest(s,1,i)=s$ for each $i$, $\dest(s,2,1)=0$ and $\dest(s,2,2)=1$. There is an illustration in Figure \ref{7-fig:bm}.
The value of the Big Match is $1/2$.

\begin{figure}

\center
\begin{tikzpicture}[node distance=3cm,-{stealth},shorten >=2pt]
\ma{s}[$s:$]{2}{2};

\node at (s-1-1.center) {$1$};
\node at (s-2-1.center) {$0^*$};
\node at (s-1-2.center) {$0$};
\node at (s-2-2.center) {$1^*$};


\end{tikzpicture}
\caption{The Big Match}\label{7-fig:bm}
\end{figure}

Consider a finite-memory strategy $\sigma$ for Eve. We will argue that $\sigma$ cannot guarantee $\epsilon$ (any strategy can guarantee $-1$, since the colors are between $0$ and $1$) for any $0<\epsilon$. Let $\tau$ be the stationary strategy for Adam that plays $1$ with pr. $\epsilon/2$.
Then playing $\sigma$ against $\tau$, we get an Markov chain, where the vertex space is pairs of memory states and game vertices. 
In Markov chains, eventually, with pr. 1, a set of vertices $S$ is reached such that the set of vertices visited infinitely often is $S$. Such a set is called ergodic.
The set $S$ can clearly only contain 1 game vertex, since whenever $s$ is left, it is never entered again.
Hence, if $S$ contains $s$, the pr. that play will ever reach $\{0,1\}$ is 0.
In the MC we get from the players playing $\sigma$ and $\tau$, let $T_{\epsilon/2}$ be such that with pr. $\epsilon/2$ some ergodic set has been reached. 
Let $\tau'$ be the strategy that plays $\tau$ for $T_{\epsilon/2}$ and afterwards plays $2$. 

When $\sigma$ is played against $\tau'$, either we reach $\{0,1\}$ and Adam plays 1 only finitely many times, while in $s$ (the latter because there are only finitely many numbers below $T_{\epsilon/2}$). Thus, for Eve to win a play, the play needs to reach vertex 1. There are two ways to do so, either Eve stops before $T_{\epsilon/2}$ or after. In the former case, the pr. to reach $1$ is only $\epsilon/2$ (because Adam needs to play $2$ at the time, which is only done with pr. $\epsilon/2$). The latter only happens with pr. $\epsilon/2$ by definition of $T_{\epsilon/2}$ (because, Adam could play $2$ for an arbitrary number of steps while following $\tau$ but $s$ would not be left anyway).

We get the following lemma.

\begin{lemma}\label{lemm:no_finite_meanpayoff}
No finite memory strategy can guarantee more than $0$ in the Big Match.
\end{lemma}

The principle of sunken cost states that, when acting rationally, one should disregard cost already paid. We will next argue that this does not apply (naively) to the Big Match.
A strategy following the principle of sunken cost would not depend on past cost paid and thus, in each step $T$, there is a pr. $p_T$ of stopping for Eve.
Such strategies are called Markov strategies in the Big Match.
Fix some Markov strategy $\sigma$ for Eve. We will argue, like before, that $\sigma$ cannot guarantee more than $\epsilon$ for any $\epsilon>0$.
Note that Eve does not depend on the choices of Adam and thus, either she stops with pr. 1 or she does not.
In the former case, Adam just plays $1$ forever. When Eve stops, the vertex reached is thus $-1$.
Alternately, if Eve does not stop with pr. 1, there must be a time $T$, such that she only stops with pr. $\epsilon$ after $T$ (this is actually also the case even if she stops with pr. 1). 
Adam's strategy is then to play $1$ for $T$ steps and $2$ thereafter. Observe that the pr. to reach $1$ is thus at most $\epsilon$, in that it must be that Eve stops after $T$. If she does not stop (or stops in $0$), there will be only finitely many 1s.

We see the following:
\begin{lemma}\label{lemm:no_markov_meanpayoff}
No Markov strategy can guarantee more than $0$ in the Big Match
\end{lemma}
