
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Concurrent discounted games &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Concurrent reachability games" href="reachability.html" />
    <link rel="prev" title="Matrix games" href="matrix_games.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     BÃ¼chi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../5_MDP/index.html">
   Markov Decision Processes
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_strongly_connected.html">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Concurrent Games
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Infinite
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../9_Timed/index.html">
   Timed Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/state_space_representation.html">
     State-Space Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/controllable_predecessor_operator.html">
     Controllable-Predecessor Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/backward_algorithm.html">
     Backward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/forward_algorithm.html">
     Forward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10_Pushdown/index.html">
   Pushdown Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/profiles.html">
     Profiles and regularity of the winning regions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/parity.html">
     Parity pushdown games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11_Counters/index.html">
   Games with Counters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/counters.html">
     Vector games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/dim1.html">
     Games in dimension one
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/avag.html">
     Asymmetric games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/resource.html">
     Resource-conscious games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/complexity.html">
     The complexity of asymmetric monotone games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multi
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12_Multiobjectives/index.html">
   Games with multiple objectives
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/mean_payoff_energy.html">
     Mean-payoff and energy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/total_payoff_shortest_path.html">
     Total-payoff and shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/beyond_worst_case.html">
     Beyond worst-case synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/percentile.html">
     Percentile queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13_Multiplayer/index.html">
   Multiplayer Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/nash_equilibria_normal_form.html">
     Nash Equilibria for games in normal form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/admissible_strategies.html">
     Admissible strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="concurrent-discounted-games">
<span id="sec-discounted"></span><h1>Concurrent discounted games<a class="headerlink" href="#concurrent-discounted-games" title="Permalink to this headline">Â¶</a></h1>
<p>In this section we focus on concurrent discounted games.
The key property of these games is that to a high degree, only the relative early part of the play matters.
We will first argue that the value iteration algorithm works and especially converges to the value of the game and then that there are stationary optimal strategies in concurrent discounted games.
While the value iteration algorithm also works for the games considered in the latter sections, we will not explicitly show it there, since the proofs become much more complex. The argument here however will allow us to show quite a few more statements in essence as corollaries of the theorem that value iteration works.</p>
<p>The value iteration algorithm is based on the concept of finite-horizon (or time limited) games. It is also sometimes referred to as dynamic programming.
Specifically, apart from the usual definition of a game, there is an additional integer <span class="math notranslate nohighlight">\(T\)</span>, denoting how many rounds are remaining initially, and a vector <span class="math notranslate nohighlight">\(v\)</span>, assigning a reward to each node if the game ends in that node with 0 rounds remaining. After round <span class="math notranslate nohighlight">\(T\)</span> the reward is 0.
I.e. for <span class="math notranslate nohighlight">\(T=0\)</span>, the outcome reward from node <span class="math notranslate nohighlight">\(x\)</span> is <span class="math notranslate nohighlight">\(v_x\)</span> in the first round and 0 in each later round.
Let <span class="math notranslate nohighlight">\(\text{valOp}^T(v)\)</span> be the vector that assigns to each node its value in the game with time-limit <span class="math notranslate nohighlight">\(T\)</span> with vector <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>In general this formulation leads to a simple dynamic algorithm that computes <span class="math notranslate nohighlight">\(\text{valOp}^T(v)\)</span> inductively in <span class="math notranslate nohighlight">\(T\)</span>.
We have that <span class="math notranslate nohighlight">\(\text{valOp}^0(v)=v\)</span> and given <span class="math notranslate nohighlight">\(\text{valOp}^{T-1}(v)\)</span> it is easy to compute <span class="math notranslate nohighlight">\(\text{valOp}^T(v)\)</span> because, if Eve selects row <span class="math notranslate nohighlight">\(i\)</span> and Adam column <span class="math notranslate nohighlight">\(j\)</span> in node <span class="math notranslate nohighlight">\(x\)</span> in the first round, the outcome is</p>
<div class="math notranslate nohighlight">
\[
\sum_{v\in V} \text{valOp}^{T-1}(v) \Delta(x,i,j)(v)
\]</div>
<p>and thus <span class="math notranslate nohighlight">\(( \text{valOp}^T(v))_x\)</span> is the value of the matrix <span class="math notranslate nohighlight">\(M^{T,x,v}\)</span>, where entry <span class="math notranslate nohighlight">\(i,j\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\sum_{v\in V} \text{valOp}^{T-1}(v) \Delta(x,i,j)(v)
\]</div>
<p>It is common to start with the all-0 vector for <span class="math notranslate nohighlight">\(v\)</span> when using the value iteration algorithm.</p>
<p>The following lemma shows many interesting properties of concurrent discounted games.</p>
<div class="proof lemma admonition" id="cor:long">
<p class="admonition-title"><span class="caption-number">Lemma 231 </span> (NEEDS TITLE cor:long)</p>
<div class="lemma-content section" id="proof-content">
<p>Concurrent discounted games have the following properties:</p>
<ul class="simple">
<li><p>The value iteration algorithm converges for any initial vector <span class="math notranslate nohighlight">\(v\)</span></p></li>
<li><p>The value iteration algorithm has an unique fix-point, independent of the initial vector <span class="math notranslate nohighlight">\(v\)</span>.</p></li>
<li><p>There are optimal stationary strategies in concurrent discounted games and the unique fix-point of the value iteration algorithm is the value (thus, the games are determined)</p></li>
<li><p>The value of a concurrent discounted game can approximated in PPAD</p></li>
<li><p>There are <span class="math notranslate nohighlight">\(\epsilon\)</span>-optimal stationary strategies with patience below <span class="math notranslate nohighlight">\(\frac{m\log(\epsilon/2)}{\log(1-\gamma)\epsilon}\)</span>.</p></li>
</ul>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The first item comes from considering the vectors <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(\text{valOp}^1(v)\)</span>. We thus have that <span class="math notranslate nohighlight">\(\text{valOp}^{T+1}(v)\in [ \text{valOp}^{T}(v)-(1-\gamma)^T, \text{valOp}^{T}(v)+(1-\gamma)^T]\)</span> for all <span class="math notranslate nohighlight">\(T\)</span>. The statement then comes from that <span class="math notranslate nohighlight">\(\sum_{i=1}^\infty (1-\gamma)^i\)</span> is a converging sum.</p>
<p>The second item comes from considering two fix-points, <span class="math notranslate nohighlight">\(u,v\)</span>. I.e., <span class="math notranslate nohighlight">\(\text{valOp}^1(v)=v\)</span> and thus <span class="math notranslate nohighlight">\(\text{valOp}^T(v)=v\)</span> for all <span class="math notranslate nohighlight">\(T\)</span>. Similar for <span class="math notranslate nohighlight">\(u\)</span>.
But, <span class="math notranslate nohighlight">\(v= \text{valOp}^T(v)\in [ \text{valOp}^T(u)-(1-\gamma)^T,  \text{valOp}^T(u)+(1-\gamma)^T]=[u-(1-\gamma)^T, u+(1-\gamma)^T]\)</span>. Since it is true for all <span class="math notranslate nohighlight">\(T\)</span>, we have that <span class="math notranslate nohighlight">\(u=v\)</span>.</p>
<p>\begin{claim}
Consider some <span class="math notranslate nohighlight">\(T\)</span> and the strategy for Eve that plays the first <span class="math notranslate nohighlight">\(T\)</span> steps following an optimal strategy in the finite-horizon game of length <span class="math notranslate nohighlight">\(T\)</span> with vector <span class="math notranslate nohighlight">\(v\)</span>, followed by playing arbitrarily.
Then, the outcome is above <span class="math notranslate nohighlight">\(\text{valOp}^T(v)- (1-\gamma)^T\max_{i} v_i\)</span>.
\end{claim}
\begin{proof}
For any strategy for Adam, the expected reward for the first <span class="math notranslate nohighlight">\(T\)</span> rounds is at least the expected reward in the finite-horizon game. In each remaining round, the reward is at least <span class="math notranslate nohighlight">\(0\)</span> in the real game, but <span class="math notranslate nohighlight">\(v_i\)</span> in round <span class="math notranslate nohighlight">\(T\)</span> for some <span class="math notranslate nohighlight">\(i\)</span> followed by 0âs in the finite-horizon game.
Since the outcome is <span class="math notranslate nohighlight">\(\text{valOp}^T(v)\)</span> in the finite-horizon game, the real outcome is then as described.</p>
</div>
<p>One can show a similar statement for Adam.
For any <span class="math notranslate nohighlight">\(\epsilon&gt;0\)</span> one can pick a big enough <span class="math notranslate nohighlight">\(T\)</span> such that <span class="math notranslate nohighlight">\((1-\gamma)^T\max_{i} v_i\leq \epsilon\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(v^*\)</span> be the unique fix-point of the value iteration algorithm.
Thus, <span class="math notranslate nohighlight">\(v^*= \text{valOp}^T(v^*)\)</span> for all <span class="math notranslate nohighlight">\(T\)</span>. Pick some optimal strategies <span class="math notranslate nohighlight">\(\sigma_x,\tau_x\)</span> in <span class="math notranslate nohighlight">\(M^{T,x,v^*}\)</span> for each <span class="math notranslate nohighlight">\(x\)</span>. Let <span class="math notranslate nohighlight">\(\sigma^*,\tau^*\)</span> be the strategies that play <span class="math notranslate nohighlight">\(\sigma_x,\tau_x\)</span> whenever in node <span class="math notranslate nohighlight">\(x\)</span> in each round.
The strategy <span class="math notranslate nohighlight">\(\sigma,\tau\)</span> are optimal in <span class="math notranslate nohighlight">\(\text{valOp}^T(v^*)\)</span> for each <span class="math notranslate nohighlight">\(T\)</span>, because <span class="math notranslate nohighlight">\(v^*\)</span> is a fix-point.
But, for each <span class="math notranslate nohighlight">\(\epsilon&gt;0\)</span>,  the strategy <span class="math notranslate nohighlight">\(\sigma\)</span> ensures outcome at least <span class="math notranslate nohighlight">\(v-\epsilon\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> ensures outcome at most <span class="math notranslate nohighlight">\(v+\epsilon\)</span> using the claim. Hence, the third item follows.</p>
<p>The fourth item follows from that the value iteration algorithm is a contraction.</p>
<p>For the fifth item, consider the strategy used in the claim.
Let <span class="math notranslate nohighlight">\(T\)</span> be <span class="math notranslate nohighlight">\(\log(\epsilon/2)/\log(1-\gamma)\)</span>, i.e. <span class="math notranslate nohighlight">\(T\)</span> is such that</p>
<div class="math notranslate nohighlight">
\[
\gamma \sum_{i=T}^{\infty}(1-\gamma)^i=\epsilon/2
\]</div>
<p>or in words, <span class="math notranslate nohighlight">\(T\)</span> is such that the total outcome of each step after the <span class="math notranslate nohighlight">\(T\)</span>-th step is at most <span class="math notranslate nohighlight">\(\epsilon/2\)</span>.
Intuitively, if we modify the strategy very little, then the change is unlikely to come up in the first <span class="math notranslate nohighlight">\(T\)</span> steps. More precisely, we will modify our strategy so that the probability that change will matter is less than <span class="math notranslate nohighlight">\(\epsilon/2\)</span>. That implies that the outcome differs by at most <span class="math notranslate nohighlight">\(\epsilon\)</span> from the value.
We will use this intuition together with the argument for the third item to give a bound on the patience of <span class="math notranslate nohighlight">\(\epsilon\)</span>-optimal strategies. Fix some optimal stationary strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve and an arbitrary stationary strategy <span class="math notranslate nohighlight">\(\tau\)</span> for Adam. Let <span class="math notranslate nohighlight">\(\sigma'\)</span> be a stationary strategy obtained from <span class="math notranslate nohighlight">\(\sigma\)</span> rounded greedily  so that each probability is a rational number with denominator</p>
<div class="math notranslate nohighlight">
\[
q=mT/\epsilon=\frac{m\log(\epsilon/2)}{\log(1-\gamma)\epsilon}.
\]</div>
<p>We will argue that <span class="math notranslate nohighlight">\(\sigma'\)</span> is <span class="math notranslate nohighlight">\(\epsilon\)</span>-optimal.</p>
<p>The rounding proceeds inductively as follows for each node <span class="math notranslate nohighlight">\(x\)</span>:
The numbers <span class="math notranslate nohighlight">\(p_i\)</span> are the original probability and the numbers <span class="math notranslate nohighlight">\(p_i'\)</span> are the new probabilities.
For each <span class="math notranslate nohighlight">\(i\)</span>, the number <span class="math notranslate nohighlight">\(p_i'\)</span> is defined as follows: If <span class="math notranslate nohighlight">\(\sum_{j=1}^{i-1}(p_i-p_i')&gt;0\)</span>, then round up (i.e. <span class="math notranslate nohighlight">\(p_i'\)</span> is the smallest rational with denominator <span class="math notranslate nohighlight">\(q\)</span> so that <span class="math notranslate nohighlight">\(p_i&lt;p_i'\)</span>) and otherwise round down, except the last number <span class="math notranslate nohighlight">\(p_\ell'\)</span>, which is such that <span class="math notranslate nohighlight">\(\sum_{j=1}^{\ell}p_i'=1\)</span>.
Note that this ensures that <span class="math notranslate nohighlight">\(-1/q&lt;\sum_{j=1}^{i-1}(p_i-p_i')&lt;1/q\)</span>. It also ensures that <span class="math notranslate nohighlight">\(|p_i-p_i'|&lt;1/q\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> (including for <span class="math notranslate nohighlight">\(i=\ell\)</span>).</p>
<p>For all nodes <span class="math notranslate nohighlight">\(x\)</span> and rounds <span class="math notranslate nohighlight">\(T'\leq T\)</span> we will define some random variables.
Specifically, the random variables denote what happen in round <span class="math notranslate nohighlight">\(T'\)</span> if in node <span class="math notranslate nohighlight">\(x\)</span>.
The random variable <span class="math notranslate nohighlight">\(X_{x,T'}\)</span> (resp. <span class="math notranslate nohighlight">\(Y_{x,T'}\)</span>) denotes the action picked by Eve if Eve follows <span class="math notranslate nohighlight">\(\sigma\)</span> (resp. <span class="math notranslate nohighlight">\(\sigma'\)</span>).
The random variable <span class="math notranslate nohighlight">\(Z_{x,T'}\)</span> denotes the action picked by Adam.
For each action pair <span class="math notranslate nohighlight">\((i,j)\)</span>  the random variable <span class="math notranslate nohighlight">\(W_{x,i,j,T'}\)</span> denotes the node entered in round <span class="math notranslate nohighlight">\(T'+1\)</span>, if Eve picks <span class="math notranslate nohighlight">\(i\)</span> and Adam <span class="math notranslate nohighlight">\(j\)</span>.
(As a side note: Each of the random variables are distributed the same way independent of <span class="math notranslate nohighlight">\(T'\)</span>).
Each of these random variables are independent of each other, except that (as we will define later) the random variables <span class="math notranslate nohighlight">\(X_{x,T'}\)</span> and <span class="math notranslate nohighlight">\(Y_{x,T'}\)</span> for each <span class="math notranslate nohighlight">\(x,T'\)</span> are very much not independent of each other.</p>
<p>We see that we can view the first <span class="math notranslate nohighlight">\(T\)</span> steps of the play when Eve follows <span class="math notranslate nohighlight">\(\sigma\)</span> by only considering the outcome of <span class="math notranslate nohighlight">\(X_{x,T'}\)</span>, <span class="math notranslate nohighlight">\(Z_{x,T'}\)</span> and <span class="math notranslate nohighlight">\(W_{x,i,j,T'}\)</span> for all <span class="math notranslate nohighlight">\(T'\)</span> and <span class="math notranslate nohighlight">\(x\)</span> (even stronger: We only need to consider one <span class="math notranslate nohighlight">\(x,i,j\)</span> for each <span class="math notranslate nohighlight">\(T'\)</span>, because the token is on only one node at a time). Similarly, for <span class="math notranslate nohighlight">\(\sigma'\)</span>, but using <span class="math notranslate nohighlight">\(Y_{x,T'}\)</span> instead of <span class="math notranslate nohighlight">\(X_{x,T'}\)</span>.
For this to work, note that each random variable should be independent, except that the random variables <span class="math notranslate nohighlight">\(X_{x,T'}\)</span> and <span class="math notranslate nohighlight">\(Y_{x',T''}\)</span> need not be independent of each other for any <span class="math notranslate nohighlight">\(x',T''\)</span>. This is precisely the property we had for them!
For each <span class="math notranslate nohighlight">\(x,T'\)</span>,  we will then use a coupling <span class="math notranslate nohighlight">\(C_{x,T'}=(X'_{x,T'},Y'_{x,T'})\)</span>, a distribution over <span class="math notranslate nohighlight">\([m]^2\)</span>, such that <span class="math notranslate nohighlight">\(X'_{x,T}\)</span> is distributed as <span class="math notranslate nohighlight">\(X_{x,T'}\)</span> and <span class="math notranslate nohighlight">\(Y'_{x,T'}\)</span> is distributed as <span class="math notranslate nohighlight">\(Y_{x,T'}\)</span>. We will use a classic result for distributions, called the Coupling Lemma.</p>
<p>To introduce the Coupling Lemma, first, we need the notion of total variation distance. Given two distributions, <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> over a set <span class="math notranslate nohighlight">\(S\)</span>, the total variation distance <span class="math notranslate nohighlight">\(t\)</span> between <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> is</p>
<div class="math notranslate nohighlight">
\[
t(\Delta,\Delta')=\frac{1}{2}\sum_{x\in S} |\Delta(x)-\Delta'(x)|
\]</div>
<div class="proof lemma admonition" id="lemma-1">
<p class="admonition-title"><span class="caption-number">Lemma 232 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>For any distributions <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> over a set <span class="math notranslate nohighlight">\(S\)</span>, we have</p>
<ul class="simple">
<li><p>for all couplings <span class="math notranslate nohighlight">\((X,Y)\)</span> of <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span>, that</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
t(\Delta,\Delta)\leq \Pr[X\neq Y]
\]</div>
<ul class="simple">
<li><p>that there is a coupling <span class="math notranslate nohighlight">\((X',Y')\)</span> of <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> satisfying that</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
t(\Delta,\Delta)= \Pr[X'\neq Y']
\]</div>
<p>For any distributions <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> over a set <span class="math notranslate nohighlight">\(S\)</span>, we have</p>
<ul class="simple">
<li><p>for all couplings <span class="math notranslate nohighlight">\((X,Y)\)</span> of <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span>, that</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
t(\Delta,\Delta)\leq \Pr[X\neq Y]
\]</div>
<ul class="simple">
<li><p>that there is a coupling <span class="math notranslate nohighlight">\((X',Y')\)</span> of <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> satisfying that</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
t(\Delta,\Delta)= \Pr[X'\neq Y']
\]</div>
</div>
</div><p>Because of our rounding, we have that <span class="math notranslate nohighlight">\(t(X'_{x,T'},Y'_{x,T'})&lt;\frac{m}{2q}\)</span>.
Using that with the coupling lemma (the second part to be precise), lets us find a coupling <span class="math notranslate nohighlight">\(C_{x,T'}=(X'_{x,T'},Y'_{x,T'})\)</span>
such that <span class="math notranslate nohighlight">\(\Pr[X'_{x,T'}\neq Y'_{x,T'}]&lt;\frac{m}{2q}\)</span>.</p>
<p>Consider the plays <span class="math notranslate nohighlight">\(\pi_1, \pi_2\)</span> for when Eve follows <span class="math notranslate nohighlight">\(\sigma\)</span> or <span class="math notranslate nohighlight">\(\sigma'\)</span> respectively.
We can view the first <span class="math notranslate nohighlight">\(T\)</span> steps of these plays by considering <span class="math notranslate nohighlight">\(X'_{x,T'}\)</span> instead of <span class="math notranslate nohighlight">\(X_{x,T'}\)</span> and similar when Eve follows <span class="math notranslate nohighlight">\(\sigma'\)</span>.
We can therefore see that the first <span class="math notranslate nohighlight">\(T\)</span> steps two plays are different with probability
<span class="math notranslate nohighlight">\(=p&lt;\frac{mT}{2q}=\epsilon/2\)</span>
using union bounds.</p>
<p>We therefore see that the value for the path <span class="math notranslate nohighlight">\(\pi_1\)</span> cannot differ from the value of <span class="math notranslate nohighlight">\(\pi_2\)</span> with more than <span class="math notranslate nohighlight">\(p\gamma\sum_{i=1}^T(1-\gamma)^i=p\)</span>. I.e. in the worst case, if <span class="math notranslate nohighlight">\(\pi_1\)</span> and <span class="math notranslate nohighlight">\(\pi_2\)</span> differs, the reward is 1 in each step for <span class="math notranslate nohighlight">\(\pi_1\)</span> but 0 in each step for <span class="math notranslate nohighlight">\(\pi_2\)</span>.
Also, the rewards in the steps after step <span class="math notranslate nohighlight">\(T\)</span> can also differ by at most <span class="math notranslate nohighlight">\(1\)</span> and by our choice of <span class="math notranslate nohighlight">\(T\)</span>, we have that outcome contributed from these remaining steps are worth less than <span class="math notranslate nohighlight">\(\epsilon/2\)</span> as well.
Hence, we see that <span class="math notranslate nohighlight">\(\sigma'\)</span> obtains the same as <span class="math notranslate nohighlight">\(\sigma\)</span> except for <span class="math notranslate nohighlight">\(\epsilon\)</span> against any strategy <span class="math notranslate nohighlight">\(\tau\)</span> and is thus <span class="math notranslate nohighlight">\(\epsilon\)</span>-optimal.</p>
<p>\end{proof}</p>
<p>There is a classic problem in geometry called the sum-of-square-roots problem. The problem is defined as follows:
Let <span class="math notranslate nohighlight">\(a,b_1,b_2,\dots,b_n\)</span> be natural numbers. Is <span class="math notranslate nohighlight">\(\sum_{i=1}^n\sqrt{b_i}&gt;a\)</span>?</p>
<p>The problem comes up for decision problems about distances in Euclidean space. It is not known to be in P or NP for that matter, but is in the fourth level of the countering hierarchy, slightly inside PSPACE. The issue is in essence that it is not known how good an approximation of <span class="math notranslate nohighlight">\(\sqrt{b_i}\)</span> is necessary to decide the strict inequality.</p>
<p>We will use the sum-of-square-roots problem to give an informal hardness argument, in that finding the exact value of a concurrent game is in general harder than solving the sum-of-square-roots problem.</p>
<p>Consider the following game <span class="math notranslate nohighlight">\(G\)</span>:
There are three vertices, <span class="math notranslate nohighlight">\(\{0,1,s\}\)</span> where <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> are absorbing, with color 0 and 1 respectively.
The vertex <span class="math notranslate nohighlight">\(s\)</span> is such that (1) <span class="math notranslate nohighlight">\(c(s,i,j)=0\)</span>, (2) <span class="math notranslate nohighlight">\(\Delta(s,i,i)=1\)</span> (for <span class="math notranslate nohighlight">\(i\in \{1,2\}\)</span>), (3) <span class="math notranslate nohighlight">\(\Delta(s,2,1)=0\)</span> and (4) <span class="math notranslate nohighlight">\(\Delta(s,1,i)\)</span> is the uniform distribution over <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(0\)</span>. The game is illustrated in Figure <a class="reference internal" href="#fig-sqroot"><span class="std std-numref">Fig. 57</span></a>.</p>
<p>Consider an optimal stationary strategy in <span class="math notranslate nohighlight">\(G\)</span> for Eve. Let <span class="math notranslate nohighlight">\(p\)</span> be the probability with which she plays the first action. If Adam knows that Eve will follow this strategy, the game devolves into a MDP. We know from that for such there exists optimal positional strategies and thus Adam is either going to play the left or right column always. Clearly, <span class="math notranslate nohighlight">\(0&lt;p&lt;1\)</span> because <span class="math notranslate nohighlight">\(p=0\)</span> or 1 means that either playing the left or right column with probability 1 would ensure that no positive reward ever happens.</p>
<div class="figure align-center" id="fig-sqroot">
<img alt="../_images/7-fig:sqroot.png" src="../_images/7-fig:sqroot.png" />
<p class="caption"><span class="caption-number">Fig. 57 </span><span class="caption-text">Concurrent discounted game with value <span class="math notranslate nohighlight">\(v_s=-2+\sqrt{4+2(1-\gamma)}\)</span></span><a class="headerlink" href="#fig-sqroot" title="Permalink to this image">Â¶</a></p>
</div>
<p>Let <span class="math notranslate nohighlight">\(v_0=0,v_1=1,v_s\)</span> be the values of the three vertices. If he plays the left column, the outcome is <span class="math notranslate nohighlight">\(p(1-\gamma)\)</span>.
If he plays the right column, the outcome is <span class="math notranslate nohighlight">\(p/2(1-\gamma)v_s+(1-p)(1-\gamma)\)</span>. Observe that the former is increasing in <span class="math notranslate nohighlight">\(p\)</span> and the latter is decreasing (since clearly, <span class="math notranslate nohighlight">\(0&lt;(1-\gamma)v_s&lt;v_s\)</span>). Also, both are continues. Thus, the optimum is for <span class="math notranslate nohighlight">\(p(1-\gamma)\)</span> to be equal to <span class="math notranslate nohighlight">\(p/2(1-\gamma)v_s+(1-p)(1-\gamma)\)</span> and both equal to <span class="math notranslate nohighlight">\(v_s\)</span>.
We will first isolate <span class="math notranslate nohighlight">\(v_s\)</span> in <span class="math notranslate nohighlight">\(v_s=p/2(1-\gamma)v_s+(1-p)(1-\gamma)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}v_s&amp;=p/2(1-\gamma)v_s+(1-p)(1-\gamma)\Rightarrow (1-p/2(1-\gamma))v_s=(1-p)(1-\gamma)\Rightarrow \\
v_s&amp;=\frac{(1-p)(1-\gamma)}{1-p/2(1-\gamma)}\enspace .\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(p,\gamma&lt;1\)</span> thus, <span class="math notranslate nohighlight">\(1-p/2(1-\gamma)\neq 0\)</span>.
We then have the equality</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{(1-p)(1-\gamma)}{1-p/2(1-\gamma)}&amp;=p(1-\gamma)\Rightarrow\\(1-p)(1-\gamma)&amp;=p(1-\gamma)(1-p/2(1-\gamma))\Rightarrow\\
0&amp;=\frac{1-\gamma}{2} p^2+2p-1\Rightarrow \\
p&amp;=\frac{-2\pm\sqrt{4+2(1-\gamma)}}{1-\gamma} \enspace .\end{split}\]</div>
<p>We see that <span class="math notranslate nohighlight">\(\frac{-2-\sqrt{4+2(1-\gamma)}}{1-\gamma}&lt;0\)</span>. Thus, <span class="math notranslate nohighlight">\(p=\frac{-2+\sqrt{4+2(1-\gamma)}}{1-\gamma}\)</span>.
Also,</p>
<div class="math notranslate nohighlight">
\[v_s=-2+\sqrt{4+2(1-\gamma)}\enspace .\]</div>
<p>It is straight-forward to modify the construction to get any square-root desired for a fixed <span class="math notranslate nohighlight">\(\gamma\)</span>.</p>
<p>By making such a construction for each number <span class="math notranslate nohighlight">\(\sqrt{b_i}\)</span>, we can make another vertex <span class="math notranslate nohighlight">\(s^*\)</span> that has the value of <span class="math notranslate nohighlight">\((1-\gamma)\frac{\sum_{i=1}^n\sqrt{b_i}}{n}\)</span> with a single action for each player and that goes to a uniformly random vertex.
Observe that decreasing each reward by <span class="math notranslate nohighlight">\(x\)</span>, reduces the value of each vertex by <span class="math notranslate nohighlight">\(x\)</span>. Reduce each reward by <span class="math notranslate nohighlight">\(\frac{an}{1-\gamma}\)</span>.
We can then decide the sum-of-square-roots problem by deciding whether the value of <span class="math notranslate nohighlight">\(s^*\)</span> is strictly above <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>We get the following lemma.</p>
<div class="proof lemma admonition" id="lemma-2">
<p class="admonition-title"><span class="caption-number">Lemma 233 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>The (exact) decision problem for the value is sum-of-square-root hard for concurrent discounted games</p>
<p>The (exact) decision problem for the value is sum-of-square-root hard for concurrent discounted games</p>
</div>
</div><p>We will use this game  <span class="math notranslate nohighlight">\(G\)</span> as an example to illustrate how to make the <span class="math notranslate nohighlight">\(\Delta\)</span>-function deterministic for concurrent games while having the same value and a similar optimal strategy.</p>
<div class="figure align-center" id="fig-sqroot2">
<img alt="../_images/7-fig:sqroot2.png" src="../_images/7-fig:sqroot2.png" />
<p class="caption"><span class="caption-number">Fig. 58 </span><span class="caption-text">Alternate concurrent discounted game with value <span class="math notranslate nohighlight">\(v_s=-2+\sqrt{4+2(1-\gamma)}\)</span></span><a class="headerlink" href="#fig-sqroot2" title="Permalink to this image">Â¶</a></p>
</div>
<p>Consider the following game <span class="math notranslate nohighlight">\(G'\)</span>:
There are three vertices, <span class="math notranslate nohighlight">\(\{0,1,s\}\)</span> where <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> are absorbing, with color 0 and 1 respectively.
The vertex <span class="math notranslate nohighlight">\(s\)</span> is such that (1)
<span class="math notranslate nohighlight">\(c(s,i,j)=0\)</span> for all <span class="math notranslate nohighlight">\(i,j\)</span>, (2) <span class="math notranslate nohighlight">\(\Delta(s,i,j)=s\)</span> for <span class="math notranslate nohighlight">\(i+1=j\)</span> (i.e. for <span class="math notranslate nohighlight">\((i,j)\in \{(1,2),(2,3)\}\)</span>), (3) <span class="math notranslate nohighlight">\(\Delta(s,i,j)=0\)</span> for <span class="math notranslate nohighlight">\(i+j=4\)</span> (i.e. the <code class="docutils literal notranslate"><span class="pre">other'</span> <span class="pre">diagonal,</span> <span class="pre">$(i,j)\in</span> <span class="pre">\{(3,1),(2,2),(1,3)\}$)</span> <span class="pre">and</span> <span class="pre">(4)</span> <span class="pre">$\Delta(s,i,j)=1$</span> <span class="pre">otherwise</span> <span class="pre">(i.e.</span> <span class="pre">for</span> <span class="pre">$(i,j)\in</span> <span class="pre">\{(1,1),(2,1),(3,2),(3,3)\}$).</span>&#160; <span class="pre">The</span> <span class="pre">game</span> <span class="pre">is</span> <span class="pre">illustrated</span> <span class="pre">in</span> <span class="pre">Figure</span> <span class="pre">{numref}</span></code>7-fig:sqroot2`.</p>
<p>We will argue that the value of <span class="math notranslate nohighlight">\(G'\)</span> is equal to that of <span class="math notranslate nohighlight">\(G\)</span>.
We clearly have that the value of <span class="math notranslate nohighlight">\(s\)</span> is in <span class="math notranslate nohighlight">\((0,1)\)</span>.
Consider a stationary strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve
such that <span class="math notranslate nohighlight">\(\sigma(1)\neq \sigma(2)\)</span>. Let <span class="math notranslate nohighlight">\(p_i=\sigma(i)\)</span> for <span class="math notranslate nohighlight">\(i\in \{1,2,3\}\)</span>.
Let <span class="math notranslate nohighlight">\(\sigma'\)</span> be such that <span class="math notranslate nohighlight">\(\sigma'(3)=p_3\)</span> and otherwise, <span class="math notranslate nohighlight">\(\sigma'(i)=\frac{p_1+p_2}{2}\)</span> for <span class="math notranslate nohighlight">\(i\in\{1,2\}\)</span>. Let <span class="math notranslate nohighlight">\(p_i'=\sigma'(i)\)</span> for <span class="math notranslate nohighlight">\(i\in \{1,2,3\}\)</span>.
\begin{claim}
The strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> is at least as good as <span class="math notranslate nohighlight">\(\sigma\)</span>
\end{claim}</p>
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>If Adam plays 1, then the expected outcome is
<span class="math notranslate nohighlight">\(p_1+p_2=p'_1+p'_2\)</span> no matter if Eve plays <span class="math notranslate nohighlight">\(\sigma\)</span> or <span class="math notranslate nohighlight">\(\sigma'\)</span>.
If he plays <span class="math notranslate nohighlight">\(i\)</span> for <span class="math notranslate nohighlight">\(i\in\{2,3\}\)</span>, the expected outcome is <span class="math notranslate nohighlight">\(
\frac{p_{4-i}}{1-p_{i-1}}\)</span> if Eve plays <span class="math notranslate nohighlight">\(\sigma\)</span> and otherwise, if she plays <span class="math notranslate nohighlight">\(\sigma'\)</span>, the expected outcome is<br />
<span class="math notranslate nohighlight">\(\frac{p'_1}{1-p'_2}=\frac{p'_2}{1-p'_1}\)</span>.
Note that <span class="math notranslate nohighlight">\(\frac{p'_1}{1-p'_2}&gt;\min_{i\in\{2,3\}\frac{p_{4-i}}{1-p_{i-1}}}\)</span> and thus, <span class="math notranslate nohighlight">\(\sigma'\)</span> is at least as good a strategy as <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
</div>
<p>A similar argument shows that for any strategy <span class="math notranslate nohighlight">\(\tau\)</span> for Adam the similar strategy <span class="math notranslate nohighlight">\(\tau'\)</span> where <span class="math notranslate nohighlight">\(\tau'(1)=\tau(1)\)</span> and <span class="math notranslate nohighlight">\(\tau'(i)=\frac{\tau(2)+\tau(3)}{2}\)</span> for <span class="math notranslate nohighlight">\(i\in\{2,3\}\)</span> is at least as good as <span class="math notranslate nohighlight">\(\tau\)</span>.
Consider that the players follows such stationary strategies <span class="math notranslate nohighlight">\(\sigma'\)</span> and <span class="math notranslate nohighlight">\(\tau'\)</span>.
Let <span class="math notranslate nohighlight">\(\sigma\)</span> be</p>
<div class="math notranslate nohighlight">
\[\begin{split}\sigma(i)=\begin{cases} \sigma'(1)+\sigma'(2)&amp;\text{if }i=1\\
\sigma'(3)&amp;\text{if }i=2\enspace .\end{cases}\end{split}\]</div>
<p>Similarly, let
<span class="math notranslate nohighlight">\(\tau\)</span> be</p>
<div class="math notranslate nohighlight">
\[\begin{split}\tau(i)=\begin{cases} \tau'(1)&amp;\text{if }i=1\\
\tau'(2)+\tau'(3)&amp;\text{if }i=2\enspace .\end{cases}\end{split}\]</div>
<p>But playing <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> in <span class="math notranslate nohighlight">\(G\)</span> gives the same outcome as playing <span class="math notranslate nohighlight">\(\sigma'\)</span> and <span class="math notranslate nohighlight">\(\tau'\)</span> in <span class="math notranslate nohighlight">\(G'\)</span> as can be seen as follows: In either game, with probability</p>
<div class="math notranslate nohighlight">
\[
\sigma'(1)\tau'(2)+\sigma'(2)\tau'(3)=\frac{\sigma(1)\tau(2)}{2}\]</div>
<p>we play again with a reward of 0, with probability</p>
<div class="math notranslate nohighlight">
\[\sigma'(1)\tau'(3)+\sigma'(2)\tau'(2)+\sigma'(3)\tau'(1)=
\frac{\sigma(1)\tau(2)}{2}
+\sigma(2)\tau(1)
\]</div>
<p>we get absorbed in 0 after a reward of 0 and with probability</p>
<div class="math notranslate nohighlight">
\[
(\sigma'(1)+\sigma'(2))\tau'(1)+(\tau'(2)+\tau'(3))\sigma'(3)
\]</div>
<p>we get absorbed in 1 after a reward of 0.
But this is in particular the case if the players play optimally and thus, the value is the same in the two games.</p>
<p>Before, in Corollary <a class="reference internal" href="#cor:long">Lemma 231</a>, we argued that the patience of <span class="math notranslate nohighlight">\(\epsilon\)</span>-optimal stationary strategies was <span class="math notranslate nohighlight">\(q=\frac{m\log(\epsilon/2)}{\log(1-\gamma)\epsilon}\)</span>.
Giving a similar exponential bound for the optimal stationary strategies is harder than solving the sum-of-square-roots problem, as we will argue next.
Assume that we had an exponential bound for optimal stationary strategies.</p>
<div class="figure align-center" id="fig-exact-hard">
<img alt="../_images/7-fig:exact-hard.png" src="../_images/7-fig:exact-hard.png" />
<p class="caption"><span class="caption-number">Fig. 59 </span><span class="caption-text">Concurrent discounted game that implies that if there is an exponential lower bound on patience, then the sum-of-square-roots problem is in P</span><a class="headerlink" href="#fig-exact-hard" title="Permalink to this image">Â¶</a></p>
</div>
<p>Consider an arbitrary yes-instance of the sum-of-square-roots problem, giving a vertex <span class="math notranslate nohighlight">\(s^*\)</span>. Reduce each reward by <span class="math notranslate nohighlight">\(a\)</span> and in the new game let <span class="math notranslate nohighlight">\(s^*_a\)</span> be the vertex corresponding to <span class="math notranslate nohighlight">\(s^*\)</span>.
We will now create a game that uses the previous game as a sub-game.
The game has 1 additional vertex <span class="math notranslate nohighlight">\(s'\)</span>, which is a 2x2-matrix, such that <span class="math notranslate nohighlight">\(c(s',i,j)=0\)</span> and <span class="math notranslate nohighlight">\(\Delta(s,1,1)=1\)</span> and <span class="math notranslate nohighlight">\(\Delta(s,2,2)=s^*\)</span> and <span class="math notranslate nohighlight">\(\Delta(s,i,j)=0\)</span> for <span class="math notranslate nohighlight">\(i\neq j\)</span>.
There is an illustration in Figure <a class="reference internal" href="#fig-exact-hard"><span class="std std-numref">Fig. 59</span></a>, using the vertex <span class="math notranslate nohighlight">\(s^*\)</span> as above.
Using an argument like above, we see that the probability <span class="math notranslate nohighlight">\(p\)</span> to play the top action in the vertex <span class="math notranslate nohighlight">\(s'\)</span> is such that <span class="math notranslate nohighlight">\(p(1-\gamma)=(1-p)(1-\gamma)x\)</span>, where <span class="math notranslate nohighlight">\(x\)</span> is the value of <span class="math notranslate nohighlight">\(s^*\)</span>. Thus, <span class="math notranslate nohighlight">\(x=\frac{p}{1-p}\)</span>. If <span class="math notranslate nohighlight">\(p\)</span> only needs to be exponential small, then <span class="math notranslate nohighlight">\(x\)</span> is exponentially small as well. This is true for any yes-instance of the sum-of-square-roots problem and thus, we only need polynomially many digits to decide the problem. We can find polynomially many digits of <span class="math notranslate nohighlight">\(\sqrt{b_i}\)</span> for each <span class="math notranslate nohighlight">\(i\)</span> in polynomial time. We get the following lemma.</p>
<div class="proof lemma admonition" id="lemma-3">
<p class="admonition-title"><span class="caption-number">Lemma 234 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>Giving an exponential lower-bound on patience for optimal stationary strategies in concurrent discounted games implies that the sum-of-square-roots problem is in <span class="math notranslate nohighlight">\(\textrm{PTIME}\)</span></p>
<p>Giving an exponential lower-bound on patience for optimal stationary strategies in concurrent discounted games implies that the sum-of-square-roots problem is in <span class="math notranslate nohighlight">\(\textrm{PTIME}\)</span></p>
</div>
</div></div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./7_Concurrent"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="matrix_games.html" title="previous page">Matrix games</a>
    <a class='right-next' id="next-link" href="reachability.html" title="next page">Concurrent reachability games</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>