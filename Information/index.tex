\Cref{part:information} adds an important feature to the study of games: imperfect information.
More precisely, in games with imperfect information, the players prefectly know the rules and the arena, but they
are only getting a partial observation along the course of the game.
\Cref{chap:memory} discusses the different notion of strategies involved in the study of imperfect information games,
showing that there are different ways to define what is a randomised strategy.
\Cref{chap:concurrent} focusses on a restricted class of imperfect information, where the only information loss
is that the players choose their actions at the same time.
\Cref{chap:signal} considers a more general framework where the players do not know which vertex the game is in,
but receive information along the game in the form of signals.

\subsubsection*{Concurrent games}

\begin{definition}
A concurrent arena $\arena$ is a tuple $(G,\Delta)$ where 
\begin{itemize}
	\item $G = (V,E)$ is a graph,
	\item $\Delta : V \times A \times A \to E$ maps the current vertex and a pair of actions to an edge.
\end{itemize}
\end{definition}

\subsubsection*{Imperfect information games}

\begin{definition}
An imperfect information arena $\arena$ is a tuple $(G,\Delta)$ where 
\begin{itemize}
	\item $G = (V,E)$ is a graph,
	\item $\Delta : V \times A \times A \to E \times S$ maps the current vertex and a pair of actions to an edge
	and a signal.
\end{itemize}
\end{definition}

\section*{Randomized strategies}
	\subsection*{Behavioural strategies}
% 		\paragraph{The behavioural approach.} A simple way to randomise strategies, the most usual in Verification-oriented graph games, consists in allowing the player to choose a distribution on the actions, rather than a single action. A \emph{behavioural strategy} is a function from sequences of observations to distributions over the actions: $\bs : \sigE^* \rightarrow \calD(\actE)$. For example, the correct behavioural strategy in Janken plays $\mathtt{rock}$, $\mathtt{paper}$, or $\mathtt{scissors}$, each with probability $\frac{1}{3}$ at each move. Once we have fixed two behavioural strategies $\bs$ and $\tau$, we can define a probability measure $\pbst$ by $\pbst(\vertex_0) = 1$ and, for any history $\history = \vertex_0 (x_1,y_1,v_1) \ldots (x_n,y_n,v_n)$:
% 		  	\begin{eqnarray}
% 			\pbst(\history) & = & \pbst(h_{<n}) \cdot \trans(\vertex_{n-1}\ ,\ \bs(\ObsE(\history))(x_n)\ ,\ \tau(\ObsA(\history))(y_n))(\vertex_n) \enspace. \label{eqn:bvalue}
% 		  	\end{eqnarray}
% 		  	
% %	\subsection{Mixed strategies}
% %		\paragraph{The mixed approach.} Another idea, more popular in classical game theory, is to choose a pure strategy at random. For example, the correct strategy in one-step Janken could be described as a uniform mix of the pure strategy that chooses $\mathtt{rock}$, the one that chooses $\mathtt{paper}$, and the one that chooses $\mathtt{scissors}$. It is a bit more complicated to describe a correct mixed strategy in the repeated game, where the set of pure strategies is uncountable. We say that two pure strategies are \emph{equivalent at depth $n$} if they agree on all the sequences of observations of length at most $n$, and we denote by $[\ps]_{\downarrow n}$ the equivalence class of $\ps$ at depth $n$. We endow the pure strategies with the $\sigma$-algebra $\Xi$ generated by the set of all equivalence classes at finite depth, and we define a \emph{mixed strategy} as a probability measure on the resulting measurable space. Notice that, as the set of actions of Eve $\actE$ is finite, the equivalence classes at finite depth form a semi-ring. By CarathÃ©odory's extension theorem, a mixed strategy is thus uniquely defined by its measure on the pure strategies of finite depth. In repeated Janken, the correct mixed strategy is the one whose measure of any sequence of $\{\mathtt{rock},\mathtt{paper},\mathtt{scissors}\}$ of length $n$ is $3^{-n}$.  
% 
% %		Notice that the measure of a history $\history = \vertex_0 (x_1,y_1,\vertex_1) \ldots (x_n,y_n,\vertex_n)$ under the pure strategies $\ps$ and $\tau$ depends only on their values up to depth $n$ (actually, it depends only on their values up to $|\ObsE(\history_{<n})|$ and $|\ObsA(\history_{<n})|$, respectively, which are both smaller than $n$). Once we have fixed two mixed strategies $\ms$ and $\tau$, we can define the probability measure $\pmsth$ by:
% %		\begin{eqnarray}
% %			\pmsth(\history) = \sum_{[\ps]_{\downarrow n},[\tau]_{\downarrow n}} \ppst(\history) \cdot \theta([\tau]_{\downarrow n}) \cdot \ms([\ps]_{\downarrow n}) \enspace, \label{eqn:mvalue}
% %		\end{eqnarray}
% %	regardless of which strategies are chosen as representatives of each equivalence class.
% 	
% 	\subsection{General strategies}
% 		\paragraph{The general approach.} A third possibility is to combine the behavioural and mixed approaches: a \emph{general} strategy is a measure over the behavioural strategies. As before, we consider the set of equivalence classes at depth $n$. By contrast with the previous case, this set is not finite (or even countable): it is the product of $|\sigE|^n$ unit $|\actE|$-simplexes, on which we can impose the Lebesgue measure. We can thus define the measure of a cylinder $\history$ under two general strategies $\gs$ and $\theta$ as: 
% 			\begin{eqnarray}
% 			\pgsth(\history) = \iint \pbst(h) \cdot d \theta([\tau]_{\downarrow n}) \cdot d \gs([\bs]_{\downarrow n}) \enspace. \label{eqn:gvalue}
% 			\end{eqnarray}
			
	\subsection*{The Big Game}
	
\section*{More expressive power}

	\subsection*{Games with partial information}
% 	
% 		Furthermore, if a player has perfect recall, mixed and behavioural strategies have the same expressive power~\cite{Aum64-AMST}:
% 
% 	\begin{theorem}[Kuhn Theorem~\cite{Kuh53-AMST}]
% 		\label{theorem:kuhn}
% 		In a game of perfect recall, every mixed strategy has an equivalent behavioural strategy.
% 	\end{theorem}
% % 
% % 	\begin{proof}
% % 		Let $\ms$ be a mixed strategy on an arena $\arena$ where Eve has perfect recall. We define a behavioural strategy $\bs$ as follows:
% % % 		\begin{eqnarray*}
% % % 			\bs(\obsE) = 
% % % 		\end{eqnarray*}
% % 
% % 	\end{proof}
% 
% 
% 	These hypotheses have been inconspicuously challenged in recent papers. In this regard, the comparison between~\cite{BGG09-LICS} and~\cite{GS09-ICALP} makes for an enlightening example. At first glance, these two papers look very similar: they both ponder the problem of the existence of almost-sure strategies in games where both players have (asymmetric) imperfect information. A closer examination reveals the differences: Bertrand, Genest, and Gimbert use general strategies, while Gripon and Serre use behavioural strategies; furthermore, in the latter paper, the players cannot observe their own actions. As a consequence, there are cases where the answer to the synthesis problem depends on which model is used. Consider for example the synchronous arena depicted in Figure~\cref\{figure:valuefails}, where the players can distinguish neither vertices nor actions in the dashed area, $\sink$ is a losing sink state, and $\circledcirc$ is her ``target'', for either a reachability or a B{\"u}chi condition.
% 
% 	\begin{figure}[ht]
% 		\begin{center}
% 		\unitlength=1.35mm
% 			\begin{picture}(70,42)(0,0)
% 	%		\put(0,0){\framebox(69,42){}}
% 		
% 				\gasset{Nh=4,Nw=4,polyangle=90}
% 					\node[Nmarks=i, iangle=120](i)(35,27){}
% 					\node[Nmr=0](delay)(35,15){}
% 					\node(a)(10,21){$\aleph$}
% 					\node(b)(59,21){$\beth$}
% 					\node[Nmarks=r](top)(35,39){}
% 					\node(bottom)(35,3){}
% 					\drawline[AHnb=0](36.45,4.45)(33.55,1.55){}
% 					\drawline[AHnb=0](36.45,1.55)(33.55,4.45){}
% 					\drawedge[curvedepth=2,ELpos=40](i,delay){$aA$}
% 					\drawedge[curvedepth=2,ELpos=60](i,delay){$bB$}
% 					\drawedge[curvedepth=-3,ELside=r](i,a){$aB$}
% 					\drawedge[curvedepth=3](i,b){$bA$}
% 					\drawedge[curvedepth=2,ELpos=50](delay,i){$**$}
% % 					\drawedge[curvedepth=2,ELpos=60](delay,i){$a*$}
% 					\drawedge[curvedepth=5](a,top){$a*$}
% 					\drawedge[curvedepth=-5,ELside=r](a,bottom){$b*$}
% 					\drawedge[curvedepth=-5,ELside=r](b,top){$b*$}
% 					\drawedge[curvedepth=5](b,bottom){$a*$}
% 					\drawedge[curvedepth=1.8](top,i){}
% 					\drawccurve[dash={3 1 1 1}0](5,25)(5,17)(65,17)(65,25)
% 			\end{picture}
% 		\end{center}
% 		\caption{Who wins?}
% 		\label{figure:valuefails}
% 	\end{figure}
% 
% 	In this game, each visit to the dashed area goes as follows. As long as Adam and Eve choose the same action in the even moves, the token goes back and forth between $\fullmoon$ and $\Box$. If and when they diverge, the token goes to one of the two symmetric vertices $\aleph$ or $\beth$, then either to $\target$ if Eve repeats her action or to $\sink$ if she chooses the other. The difficulty is that she must randomise her strategy to fool Adam, but she cannot observe the results of this randomisation.
% 
% 	Let us first consider Eve's behavioural strategies in the dashed area, which are by definition of the form $\sigE^* \rightarrow \calD(\actE)$. As Eve always gets the same signal from the dashed area, they are in effect functions from integers. Let $\bs$ be such a strategy, and consider the behavioural counter-strategy $\tau$ for Adam such that $\tau(i)(A) = \bs(i)(a)$. Assuming that the token is still in the dashed area after the $2i$\textsuperscript{th} move, the probability that it reaches $\aleph$ in the next move is $\bs(2i)(a) \cdot \tau(2i)(B)$, and the probability that it reaches $\beth$ in the next move is $\bs(2i)(b) \cdot \tau(2i)(A)$. By definition of $\tau$, these two probabilities are equal. No matter how Eve chooses her $2i+1$\textsuperscript{th} move, the chances that the token reaches $\target$ are equal to the chances that it reaches $\sink$ (there is also a probability $\bs(2i)(a)^2 + \bs(2i)(b)^2$ that the token remains in the dashed area). In the reachability game, this limits Eve's prospects to half chances. In the B{\"u}chi game, the probability that she wins drops to $0$.
% 
% 	On the flip side, there is an almost-sure mixed strategy for Eve in this game. A pure strategy in the dashed area is a function of integers to $\{a,b\}$, \ie an infinite word over $\{a,b\}$, and an equivalence class at finite depth is a finite word over $\{a,b\}$. Consider the mixed strategy $\ms$ such that, for each word $w$ of length $2n$ in $(aa | bb)^*$, the measure of $[w]$ under $\ms$ is $2^{-n}$ . It guarantees that each sequence of two moves starting in the initial vertex has a probability of $\frac{1}{2}$ to send the token to $\target$, and a probability of $\frac{1}{2}$ to send the token back to the initial vertex, no matter what Adam does. It cannot go to $\sink$, as Eve never plays $ab$ or $ba$ from the $\fullmoon$.

