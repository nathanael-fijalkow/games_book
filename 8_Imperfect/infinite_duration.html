
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Infinite duration &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bibliographic references" href="references.html" />
    <link rel="prev" title="Finite duration" href="finite_duration.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     BÃ¼chi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../5_MDP/index.html">
   Markov Decision Processes
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_strongly_connected.html">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Games with Signals
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="finite_duration.html#min-left-1-x-3-1-y-3-1-x-9-1-y-right-right-frac-1-4-max-x-y-in-0-1-2-min-left-4-6y-6-2x-6y-br-right">
     \min\left(
{(1-x) +  3 (1-y)},
{3(1-x) - 9(1-y)}
\right)\right)\
=&amp;
\frac{1}{4}\max_{(x,y)\in[0,1]^2}
\min\left(
4 - 6y,
-6 -2x + 6y
     <br/>
     \right)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="infinite-duration">
<span id="sec-infinite-duration"></span><h1>Infinite duration<a class="headerlink" href="#infinite-duration" title="Permalink to this headline">Â¶</a></h1>
<div class="math notranslate nohighlight">
\[\newcommand{\probimp}[3]{\mathbb{P}^{#1}_{#2}\left({#3}\right)}
\newcommand{\rand}{{\tt rand}}
\newcommand{\Isafe}{{\tt ISafe}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\KK}{\mathcal{K}}
\newcommand{\LLE}{\LL_{\text{Eve},=1}}
\newcommand{\LLA}{\LL_{\text{Adam},&gt;0}}
\newcommand{\can}{\textsf{max}}
\newcommand{\targets}{TT}
\newcommand{\bh}{\setminus}
\newcommand{\signauxdeux}{T}
\newcommand{\actionsun}{A}
\newcommand{\Act}{\text{Act}}
\newcommand{\ini}{\delta_0}
\newcommand{\Eve}{\textrm{Eve}}
\newcommand{\Adam}{\textrm{Adam}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Zinfty}{\Z \cup \set{\pm \infty}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rinfty}{\R \cup \set{\pm \infty}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Qinfty}{\Q \cup \set{\pm \infty}}
\newcommand{\argmax}{\textrm{argmax}}
\newcommand{\argmin}{\textrm{argmin}}
\newcommand{\Op}{\mathbb{O}}
\newcommand{\Prob}{\mathbb{P}} \newcommand{\dist}{\mathcal{D}} \newcommand{\Dist}{\dist} \newcommand{\supp}{\textrm{supp}} 
\newcommand{\game}{\mathcal{G}} \renewcommand{\Game}{\game} \newcommand{\arena}{\mathcal{A}} \newcommand{\Arena}{\arena} 
\newcommand{\col}{\textsf{col}} \newcommand{\Col}{\col} 
\newcommand{\mEve}{\mathrm{Eve}}
\newcommand{\mAdam}{\mathrm{Adam}}
\newcommand{\mRandom}{\mathrm{Random}}
\newcommand{\vertices}{V} \newcommand{\VE}{V_\mEve} \newcommand{\VA}{V_\mAdam} \newcommand{\VR}{V_\mRandom} 
\newcommand{\ing}{\textrm{In}}
\newcommand{\Ing}{\ing}
\newcommand{\out}{\textrm{Out}}
\newcommand{\Out}{\out}
\newcommand{\dest}{\Delta} 
\newcommand{\WE}{W_\mEve} \newcommand{\WA}{W_\mAdam} 
\newcommand{\Paths}{\textrm{Paths}} \newcommand{\play}{\pi} \newcommand{\first}{\textrm{first}} \newcommand{\last}{\textrm{last}} 
\newcommand{\mem}{\mathcal{M}} \newcommand{\Mem}{\mem} 
\newcommand{\Pre}{\textrm{Pre}} \newcommand{\PreE}{\textrm{Pre}_\mEve} \newcommand{\PreA}{\textrm{Pre}_\mAdam} \newcommand{\Attr}{\textrm{Attr}} \newcommand{\AttrE}{\textrm{Attr}_\mEve} \newcommand{\AttrA}{\textrm{Attr}_\mAdam} \newcommand{\rank}{\textrm{rank}}
\newcommand{\Win}{\textrm{Win}} 
\newcommand{\Lose}{\textrm{Lose}} 
\newcommand{\Value}{\textrm{val}} 
\newcommand{\ValueE}{\textrm{val}_\mEve} 
\newcommand{\ValueA}{\textrm{val}_\mAdam}
\newcommand{\val}{\Value} 
\newcommand{\Automaton}{\mathbf{A}} 
\newcommand{\Safe}{\mathtt{Safe}}
\newcommand{\Reach}{\mathtt{Reach}} 
\newcommand{\Buchi}{\mathtt{Buchi}} 
\newcommand{\CoBuchi}{\mathtt{CoBuchi}} 
\newcommand{\Parity}{\mathtt{Parity}} 
\newcommand{\Muller}{\mathtt{Muller}} 
\newcommand{\Rabin}{\mathtt{Rabin}} 
\newcommand{\Streett}{\mathtt{Streett}} 
\newcommand{\MeanPayoff}{\mathtt{MeanPayoff}} 
\newcommand{\DiscountedPayoff}{\mathtt{DiscountedPayoff}}
\newcommand{\Energy}{\mathtt{Energy}}
\newcommand{\TotalPayoff}{\mathtt{TotalPayoff}}
\newcommand{\ShortestPath}{\mathtt{ShortestPath}}
\newcommand{\Sup}{\mathtt{Sup}}
\newcommand{\Inf}{\mathtt{Inf}}
\newcommand{\LimSup}{\mathtt{LimSup}}
\newcommand{\LimInf}{\mathtt{LimInf}}
\newcommand{\NL}{\textrm{NL}}
\newcommand{\PTIME}{\textrm{PTIME}}
\newcommand{\NP}{\textrm{NP}}
\newcommand{\UP}{\textrm{UP}}
\newcommand{\coNP}{\textrm{coNP}}
\newcommand{\coUP}{\textrm{coUP}}
\newcommand{\PSPACE}{\textrm{PSPACE}}\]</div>
<p>Games with infinite duration and imperfect information
are a natural model for applications such as synthesis
of controllers of embedded systems.
This is illustrated by the example of the network controller.
Whereas in the previous section games of finite-duration
were equipped with real-valued payoffs,
here we focus on BÃ¼chi conditions.</p>
<p>\subsection{Playing games with infinite duration and imperfect information }</p>
<p>Notations used for games of finite duration are kept.
On top of that we need to define how probabilities are measured
and the winning conditions.</p>
<blockquote>
<div><p><strong>Measuring probabilities.</strong></p>
</div></blockquote>
<p>The choice of an initial distribution
<span class="math notranslate nohighlight">\(\ini\in\dist(V)\)</span>
and two strategies
<span class="math notranslate nohighlight">\(\sigma:  R_E \to \dist(A)\)</span>
and <span class="math notranslate nohighlight">\(\tau:  R_A \to \dist(A)\)</span>
for Eve and Adam
defines a Markov chain on the set of all finite plays.
This in turn defines a probability measure
<span class="math notranslate nohighlight">\(\mathbb{P}_{\ini}^{\sigma,\tau}\)</span> on the Borel-measurable
subsets of <span class="math notranslate nohighlight">\(\Delta^\omega\)</span>.
The random variables <span class="math notranslate nohighlight">\(V_n,A_n,B_n,S_{n}\)</span> and <span class="math notranslate nohighlight">\(T_{n}\)</span> denote
respectively the <span class="math notranslate nohighlight">\(n\)</span>-th state, action of Eve, action of Adam,
signal received by Eve and Adam,
and we denote <span class="math notranslate nohighlight">\(\pi_n\)</span> the finite play
<span class="math notranslate nohighlight">\(\pi_n = V_0,A_0,B_0,S_0,T_0,V_1,\ldots,S_{n},T_{n},V_{n+1}\)</span>.</p>
<p>The probability measure <span class="math notranslate nohighlight">\(\mathbb{P}_{\ini}^{\sigma,\tau}\)</span> is the only
probability measure over <span class="math notranslate nohighlight">\(\Delta^\omega\)</span> such that
for every <span class="math notranslate nohighlight">\(v\in V\)</span>,
<span class="math notranslate nohighlight">\(\mathbb{P}^{\sigma,\tau}_{\ini}(V_0 = v) = \ini(v)\)</span>
and for every <span class="math notranslate nohighlight">\(n\in\NN\)</span>,
\begin{multline*}
\mathbb{P}^{\sigma,\tau}<em>{\ini}(V</em>{n+1}, S_{n}, T_{n} \mid \pi_n) \
= \sigma(S_0\cdots S_{n-1})(A_{n}) \cdot \tau(T_0\cdots T_{n-1})(B_n) \cdot \Delta(V_n,A_n,B_n)(V_{n+1},S_{n},T_{n})\enspace,
\end{multline*}
where we use standard notations for conditional probability measures.</p>
<p>\newcommand{\win}
\newcommand{\winreach}
\newcommand{\winsafe}
\newcommand{\winbuchi}
\newcommand{\wincobuchi}</p>
<blockquote>
<div><p><strong>Winning conditions.</strong></p>
</div></blockquote>
<p>The set of colours is <span class="math notranslate nohighlight">\(C=\{0,1\}\)</span>.
The reachability, safety, BÃ¼chi and coBÃ¼chi condition
condition are defined as follows:
\begin{align*}
&amp;\winreach={\exists n\in\NN, C_n  = 1}\
&amp;\winsafe={\forall n\in\NN, C_n = 0}\
&amp;\winbuchi={\forall m \in \NN, \exists n \geq m, C_n=1}\
&amp;\wincobuchi = {\exists m \in \NN, \forall n \geq m, C_n = 0}\enspace.
\end{align*}</p>
<p>When the winning condition is <span class="math notranslate nohighlight">\(\win\)</span>,
Eve and Adam use strategies
<span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> and the initial distribution is <span class="math notranslate nohighlight">\(\ini\)</span>,
then Eve wins the game with probability:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}^{\sigma,\tau}_{\ini}(\win)\enspace.
\]</div>
<p>Eve wants to maximise this probability, while Adam wants
to minimise it.</p>
<p>\subsection{The value problem.}</p>
<p>The value problem is computationally intractable
for games with infinite duration and imperfect information.
This holds even for the very simple case
of blind one-player games with reachability conditions.
Those are games where the set of
signals is a singleton and actions of Adam have no influence
on the transition probabilities. These games can be seen
as probabilistic automata, hence the undecidability result of Paz applies.</p>
<p>```{prf:theorem} NEEDS TITLE AND LABEL <span id="id1">[<span>Paz</span>]</span>
Whether Eve has a strategy to win with probability <span class="math notranslate nohighlight">\(\geq \frac{1}{2}\)</span>
is undecidable, even in blind one-player games.</p>
<p>:label: <span id="id2">[<span>Paz</span>]</span>
Whether Eve has a strategy to win with probability <span class="math notranslate nohighlight">\(\geq \frac{1}{2}\)</span>
is undecidable, even in blind one-player games.</p>
<p><span id="id3">[<span>Paz</span>]</span>
Whether Eve has a strategy to win with probability <span class="math notranslate nohighlight">\(\geq \frac{1}{2}\)</span>
is undecidable, even in blind one-player games.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
Actually, the value might not even exist.

```{prf:proposition} NEEDS TITLE AND LABEL  {cite}`repgames`
There is a game with infinite duration imperfect information and B&amp;uuml;chi condition
in which 

$$
\sup_\sigma \inf_\tau \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)
=
\frac{1}{2}
&lt;
1
=
\inf_\tau \sup_\sigma  \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)\enspace.
$$

 
:label:  {cite}`repgames`
There is a game with infinite duration imperfect information and B&amp;uuml;chi condition
in which 

$$
\sup_\sigma \inf_\tau \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)
=
\frac{1}{2}
&lt;
1
=
\inf_\tau \sup_\sigma  \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)\enspace.
$$


 {cite}`repgames`
There is a game with infinite duration imperfect information and B&amp;uuml;chi condition
in which 

$$
\sup_\sigma \inf_\tau \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)
=
\frac{1}{2}
&lt;
1
=
\inf_\tau \sup_\sigma  \mathbb{P}^{\sigma,\tau}_{\ini}(\winbuchi)\enspace.
$$


</pre></div>
</div>
<p>The value however exists for games with reachability condition <span id="id4">[<span>repgames</span>]</span>.</p>
<p>Although the value problem is not decidable,
there are
some other interesting  decision problems to consider.</p>
<p>\subsection{Winning with probability <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(&gt;0\)</span>}</p>
<blockquote>
<div><p><strong>Winning almost-surely or positively.</strong></p>
</div></blockquote>
<p>A strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve is <strong>almost-surely winning</strong>
from an initial distribution <span class="math notranslate nohighlight">\(\ini\)</span> if
\begin{equation*}\label{eq:as}
\forall \tau,
\mathbb{P}^{\sigma,\tau}_{\ini}(\win)=1\enspace.
\end{equation*}
When such an almost-surely strategy <span class="math notranslate nohighlight">\(\sigma\)</span> exists, the initial distribution <span class="math notranslate nohighlight">\(\ini\)</span>
is said to be almost-surely winning (for Eve).</p>
<p>A less enjoyable situation for Eve is when she only has a
positively winning strategy.
A strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve is <strong>positively winning</strong> from
an initial distribution <span class="math notranslate nohighlight">\(\ini\)</span> if
\begin{equation*}  \forall \tau,
\mathbb{P}^{\sigma,\tau}_{\ini}(\win)&gt;0\enspace.
\end{equation*}
When such a strategy <span class="math notranslate nohighlight">\(\sigma\)</span> exists, the initial distribution <span class="math notranslate nohighlight">\(\delta\)</span>
is said to be positively winning (for Eve).
Symmetrically, a
strategy <span class="math notranslate nohighlight">\(\tau\)</span> for Adam is positively winning if it guarantees
<span class="math notranslate nohighlight">\(\forall \sigma, \mathbb{P}^{\sigma,\tau}_{\ini}(\win)&lt;1\)</span>.</p>
<p>The worst situation for Eve is when her opponent has an
almost-surely winning strategy <span class="math notranslate nohighlight">\(\tau\)</span>, which thus ensures <span class="math notranslate nohighlight">\(\mathbb{P}^{\sigma,\tau}_{\ini}(\win)=0\)</span>
whatever strategy <span class="math notranslate nohighlight">\(\sigma\)</span> is chosen by Eve.</p>
<blockquote>
<div><p><strong>Qualitative determinacy.</strong></p>
</div></blockquote>
<div class="proof theorem admonition" id="theo:qdet">
<p class="admonition-title"><span class="caption-number">Theorem 246 </span> (NEEDS TITLE theo:qdet)</p>
<div class="theorem-content section" id="proof-content">
<p>Stochastic games with signals and reachability, safety and BÃ¼chi
winning conditions are qualitatively determined:
either Eve wins almost-surely winning
or Adam wins positively.
Formally, in those games,</p>
<div class="math notranslate nohighlight">
\[
\left(\forall \tau, \exists \sigma,\mathbb{P}^{\sigma,\tau}_{\ini}(\win)=1\right)
\implies
\left(\exists \sigma,\forall \tau ,\mathbb{P}^{\sigma,\tau}_{\ini}(\win)=1\right)\enspace.
\]</div>
</div>
</div><p>The proof of this result is given in the next section.</p>
<p>Since reachability and safety games are dual, a consequence of
Theorem~\ref{theo:qdet}, is that in a reachability game, every initial
distribution is either almost-surely winning for Eve,
almost-surely winning for Adam, or positively
winning for both players.
When a safety condition is satisfied almost-surely for a fixed profile of strategies,
it trivially implies that the safety condition is
satisfied by all consistent plays,
thus for safety games winning <strong>surely</strong> is the same than winning almost-surely.</p>
<p>By contrast, co-BÃ¼chi games are <strong>not</strong> qualitatively determined:</p>
<div class="proof lemma admonition" id="lemma-1">
<p class="admonition-title"><span class="caption-number">Lemma 247 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>There is a co-BÃ¼chi game in which neither Eve has an almost-surely winning strategy
nor Adam has a positively winning strategy.</p>
<p>:label:
There is a co-BÃ¼chi game in which neither Eve has an almost-surely winning strategy
nor Adam has a positively winning strategy.</p>
<p>There is a co-BÃ¼chi game in which neither Eve has an almost-surely winning strategy
nor Adam has a positively winning strategy.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>In this game, Eve observes
everything, Adam is blind (he only observes his own actions),
and Eveâs objective is to visit only finitely many times the <span class="math notranslate nohighlight">\({\large \frownie}\)</span>-state. The initial state is <span class="math notranslate nohighlight">\(\large{\frownie}\)</span>. The set of actions is <span class="math notranslate nohighlight">\(\{a,b,c,d\}\)</span>.
All transitions are deterministic.
\begin{figure}[h]
\begin{center}
\end{center}
\caption{Co-BÃ¼chi games are not qualitatively determined.}
\label{chap9fig4}
\end{figure}</p>
<p>On one hand, no strategy <span class="math notranslate nohighlight">\(\Sigma\)</span>
is almost-surely winning for Eve
for her co-BÃ¼chi objective.
{
Since both players can observe their actions,
it is enough to prove that no behavioral
strategy
<span class="math notranslate nohighlight">\(\sigma\in C^*\to \Delta(I)\)</span> of Eve is almost-surely winning.
Fix strategy <span class="math notranslate nohighlight">\(\sigma\)</span> and assume towards contradiction that <span class="math notranslate nohighlight">\(\sigma\)</span> is almost-surely winning.
We define a strategy <span class="math notranslate nohighlight">\(\tau\)</span>
such that
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau}{\frownie}{ \winbuchi} &gt; 0\)</span>.
Strategy <span class="math notranslate nohighlight">\(\tau\)</span> starts by playing only <span class="math notranslate nohighlight">\(c\)</span>.
The probability to be in state <span class="math notranslate nohighlight">\(\frownie\)</span> at step <span class="math notranslate nohighlight">\(n\)</span> is
<span class="math notranslate nohighlight">\(x^{0}_n = \probimp{\sigma,c^\omega}{\frownie}{V_n=\frownie}\)</span> and since <span class="math notranslate nohighlight">\(\sigma\)</span> is almost-surely winning then <span class="math notranslate nohighlight">\(x^{0}_n \to_n 0\)</span> thus there exists  <span class="math notranslate nohighlight">\(n_0\)</span> such that
<span class="math notranslate nohighlight">\(x^{0}_{n_0}\leq \frac{1}{2}\)</span>.
Then <span class="math notranslate nohighlight">\(\tau\)</span> plays <span class="math notranslate nohighlight">\(d\)</span> at step <span class="math notranslate nohighlight">\(n_0\)</span>.
Assuming the state was <span class="math notranslate nohighlight">\(2\)</span> when <span class="math notranslate nohighlight">\(d\)</span> was played,
the probability to be in state <span class="math notranslate nohighlight">\(\frownie\)</span> at step <span class="math notranslate nohighlight">\(n\geq n_0\)</span> is
<span class="math notranslate nohighlight">\(x^{1}_n = \probimp{\sigma,c^{n_0}dc^\omega}{\frownie}{V_{n}=\frownie\mid V_{n_0}=\frownie}\)</span>
and since <span class="math notranslate nohighlight">\(\sigma\)</span> is almost-surely winning there exists <span class="math notranslate nohighlight">\(n_1\)</span> such that
<span class="math notranslate nohighlight">\(x^{1}_{n_1}\leq  \frac{1}{4}\)</span>.
Then <span class="math notranslate nohighlight">\(\tau\)</span> plays <span class="math notranslate nohighlight">\(d\)</span> at step <span class="math notranslate nohighlight">\(n_1\)</span>.
By induction we keep defining <span class="math notranslate nohighlight">\(\tau\)</span> this way so that
<span class="math notranslate nohighlight">\(\tau=c^{n_0-1}d c^{n_1 - n_0 - 1}dc^{n_2 - n_1 - 1}d \cdots \)</span>.
and for every <span class="math notranslate nohighlight">\(k\in \NN\)</span>,
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau}{\frownie}{
V_{n_{k+1}}=\frownie
\text{ and }
V_{n_{k+1}-1}=2
\mid 
V_{n_{k}}=\frownie
} \geq 1 - \frac{1}{2^{k+1}}\)</span>.
Thus finally
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau}{\frownie}{\winbuchi} \geq
\Pi_{k} (1 - \frac{1}{2^{k+1}})&gt;0\)</span> which contradicts the hypothesis.</p>
<p>}</p>
<p>On the other hand, Adam does not have a positively winning
strategy either.
{
Intuitively, Adam cannot win positively because as time passes, either the play reaches state <span class="math notranslate nohighlight">\(1\)</span> or the chances that Adam plays action <span class="math notranslate nohighlight">\(d\)</span> drop to <span class="math notranslate nohighlight">\(0\)</span>. When these chances are small,
Eve can play action <span class="math notranslate nohighlight">\(c\)</span> and she bets no more <span class="math notranslate nohighlight">\(d\)</span> will be played and the play will stay safe in state <span class="math notranslate nohighlight">\(2\)</span>. If Eve loses her bet
then again she waits until the chances to see another <span class="math notranslate nohighlight">\(d\)</span> are small and then plays action <span class="math notranslate nohighlight">\(c\)</span>. Eve may lose a couple of bets but almost-surely she eventually is right and the <span class="math notranslate nohighlight">\(\wincobuchi\)</span> condition is almost-surely fulfilled.</p>
<p>Finally neither Eve wins almost-surely nor Adam wins positively.
}</p>
</div>
<blockquote>
<div><p><strong>Decidability</strong></p>
</div></blockquote>
<p>\newcommand{\EXPTIME}
\newcommand{\PTIME}</p>
<div class="proof theorem admonition" id="th:main">
<p class="admonition-title"><span class="caption-number">Theorem 248 </span> (NEEDS TITLE th:main)</p>
<div class="theorem-content section" id="proof-content">
<p>Deciding whether the initial distribution of a BÃ¼chi games,
is almost-surely winning for Eve is
2\EXPTIME-complete.
For safety games, the same problem is \EXPTIME-complete.</p>
</div>
</div><p>Concerning winning positively a {\em safety or co-BÃ¼chi game}, one
can use Theorem~\ref{theo:qdet} and the determinacy property: Adam
has a positively winning strategy in the above game if and only if
Eve has no almost-surely winning strategy. Therefore, deciding
when Adam has a positively winning strategy can also be done, with
the same complexity.</p>
<div class="proof theorem admonition" id="th:main2">
<p class="admonition-title"><span class="caption-number">Theorem 249 </span> (NEEDS TITLE th:main2)</p>
<div class="theorem-content section" id="proof-content">
<p>For reachability and BÃ¼chi games where either Eve is perfectly informed about the state
or Adam is
better informed than Eve, deciding whether the initial distribution is
almost-surely winning for Eve is
\EXPTIME-complete.
In safety games
Eve is perfectly
informed {about the state}, the decision problem is in \PTIME.</p>
</div>
</div><p>\subsection{Qualitative determinacy: proof of Theorem~\ref{theo:qdet}}</p>
<blockquote>
<div><p><strong>Beliefs.</strong></p>
</div></blockquote>
<p>The
<strong>belief</strong> of a player
is the set of possible states of the game, according
to the signals received by the player.</p>
<p>\newcommand{\states}{V}
\newcommand{\ar}{\arena}
\newcommand{\action}{a}
\newcommand{\belun}{\mathcal{B}<em>{\text{Eve}}}
\newcommand{\beldeux}{\mathcal{B}</em>{\text{Adam}}}
\newcommand{\deuxbelun}{\mathcal{B}^{(2)}_{Eve}}
\newcommand{\tp}{\Delta}
\newcommand{\parties}[1]{\ensuremath{\mathcal{P}(#1)}}</p>
<div class="proof definition admonition" id="Belief">
<p class="admonition-title"><span class="caption-number">Definition 250 </span> (NEEDS LABEL Belief)</p>
<div class="definition-content section" id="proof-content">
<p>{Let <span class="math notranslate nohighlight">\(\arena\)</span> be an arena with observable actions.}
From an initial set of states <span class="math notranslate nohighlight">\(L\subseteq\states\)</span>, the belief of
Eve after having received signal <span class="math notranslate nohighlight">\(s\)</span> is:
\begin{multline*}
\belun(L,s) =
{ v\in\states \mid \exists l\in L, t\in S \text{ such that } \tp(l,s,t)(v,\Act(s),\Act(t))&gt;0}\enspace.<br />
\end{multline*}</p>
<p>Remark that in this definition we use the fact that actions of Eve are observable,
thus when he receives a signal <span class="math notranslate nohighlight">\(s\in C\)</span> Eve can deduce he played action
<span class="math notranslate nohighlight">\(\action_1(c)\in I\)</span>.
The belief of Eve after having received a sequence of signals <span class="math notranslate nohighlight">\(s_1,\ldots,s_n\)</span> is defined inductively by:</p>
<div class="math notranslate nohighlight">
\[
\belun(L,s_1,s_2,\ldots,s_n)
 = \belun(\belun(L,s_1,\ldots,s_{n-1}),s_n).\enspace
\]</div>
<p>Beliefs of Adam are defined similarly.
{
Given an initial distribution <span class="math notranslate nohighlight">\(\delta\)</span>,
we denote
<span class="math notranslate nohighlight">\(\belun^n\)</span> the random variable defined by}
\begin{align*}
&amp;{\belun^{0} = \supp(\delta)}\
&amp;{\belun^{n+1} =\belun(\supp(\delta),C_1,\ldots,C_{n+1})
= \belun(\belun^n,C_{n+1})
\enspace.}
\end{align*}</p>
</div>
</div><p>We will also rely on the notion of <strong>belief of belief</strong>, called
here <strong>2-belief</strong>, which, roughly speaking, represents for one
player the set of possible beliefs for his (or her) adversary,
as well as the possible current state.</p>
<div class="proof definition admonition" id="2-Belief">
<p class="admonition-title"><span class="caption-number">Definition 251 </span> (NEEDS LABEL 2-Belief)</p>
<div class="definition-content section" id="proof-content">
<p>{Let <span class="math notranslate nohighlight">\(\ar\)</span> be an arena with observable actions.}
From an initial set <span class="math notranslate nohighlight">\({\mathcal{L}} \subseteq \states
  \times \parties{\states}\)</span> of pairs composed of a state and a belief
for Adam, the 2-belief of Eve after having received signal <span class="math notranslate nohighlight">\(c\)</span> is the subset of
<span class="math notranslate nohighlight">\(\states
  \times \parties{\states}\)</span> defined by:</p>
<div class="math notranslate nohighlight">
\[
  \deuxbelun({\mathcal{L}},s) = \{ (v,\beldeux(L,t)) \mid
\exists  (\ell,L) \in {\mathcal{L}},  t\in S,
  \tp(v,s,t)(\ell,\Act(s),\Act(t))
  &gt;0\} \enspace.
  \]</div>
<p>From an initial set <span class="math notranslate nohighlight">\({\mathcal{L}} \subseteq \states
\times \parties{\states}\)</span> of pairs composed of a state and a belief
for Adam, the 2-belief of Eve after having  received a sequence of
signals <span class="math notranslate nohighlight">\(s_1,\ldots,s_n\)</span> is defined inductively by:</p>
<div class="math notranslate nohighlight">
\[
\deuxbelun({\mathcal{L}},s_1,s_2,\ldots,s_n) =
\deuxbelun\left(\deuxbelun\left({\mathcal{L}},s_1,\ldots,s_{n-1}\right),s_n\right)\enspace.
\]</div>
</div>
</div><p>There are natural definitions of <span class="math notranslate nohighlight">\(3\)</span>-beliefs (beliefs on beliefs on beliefs)
and even <span class="math notranslate nohighlight">\(k\)</span>-beliefs however for our purpose, <span class="math notranslate nohighlight">\(2\)</span>-beliefs are enough,
in the following sense:
in BÃ¼chi games the positively winning sets of Adam
can be characterised by fix-point equations on sets of <span class="math notranslate nohighlight">\(2\)</span>-beliefs,
and some positively winning strategies of Adam with finite-memory
can be implemented using <span class="math notranslate nohighlight">\(2\)</span>-beliefs.</p>
<blockquote>
<div><p><strong>Supports positively winning supports.</strong></p>
</div></blockquote>
<p>Note that whether an initial distribution <span class="math notranslate nohighlight">\(\ini\)</span> is almost-surely or
positively winning depends only on its support, because
<span class="math notranslate nohighlight">\(\mathbb{P}^{\sigma,\tau}_{\ini}(\win)
=\sum_{v\in V}\ini(v)\cdot\mathbb{P}^{\sigma,\tau}_{\ini}(\win \mid V_0= v)\)</span>.
As a consequence, we will say that a support
<span class="math notranslate nohighlight">\(L\subseteq V\)</span> is almost-surely or positively winning for a
player if there exists a distribution with support <span class="math notranslate nohighlight">\(L\)</span> which has the
same property.</p>
<p>In the sequel, we will denote <span class="math notranslate nohighlight">\(\LLE\)</span> the set of supports almost-surely winning for Eve
and  <span class="math notranslate nohighlight">\(\LLA\)</span> those positively winning for Adam.</p>
<p>Then the qualitative determinacy theorem is a corollary of the following lemma.</p>
<div class="proof lemma admonition" id="lemma-6">
<p class="admonition-title"><span class="caption-number">Lemma 252 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>In every BÃ¼chi game, every non-empty support
which does not belong to <span class="math notranslate nohighlight">\(\LLA\)</span> belongs to <span class="math notranslate nohighlight">\(\LLE\)</span>.</p>
<p>:label:
In every BÃ¼chi game, every non-empty support
which does not belong to <span class="math notranslate nohighlight">\(\LLA\)</span> belongs to <span class="math notranslate nohighlight">\(\LLE\)</span>.</p>
<p>In every BÃ¼chi game, every non-empty support
which does not belong to <span class="math notranslate nohighlight">\(\LLA\)</span> belongs to <span class="math notranslate nohighlight">\(\LLE\)</span>.</p>
</div>
</div><p>The proof of this lemma relies on the definition of a strategy
called the maximal strategy.
We prove that this strategy is almost-surely winning from any initial
distribution which is not positively winning for Adam.</p>
<div class="proof definition admonition" id="def:maximalstrategy">
<p class="admonition-title"><span class="caption-number">Definition 253 </span> (Maximal strategy)</p>
<div class="definition-content section" id="proof-content">
<p>For every non-empty support <span class="math notranslate nohighlight">\(L\subseteq V\)</span> we define
the set  of {<span class="math notranslate nohighlight">\(L\)</span>-safe} actions for Eve as</p>
<div class="math notranslate nohighlight">
\[
\Isafe(L) = \left\{ a \in A \mid  \forall s \in S, (\Act(s)=a) \implies (\belun(L,s)\not\in\LLA
  )\right\}\enspace,
\]</div>
<p>in other words these are the actions which Eve can play without taking the risk
that her belief is positively winning for Adam.</p>
<p>The <strong>maximal strategy</strong> is the strategy of Eve
which plays the uniform distribution
on <span class="math notranslate nohighlight">\(\Isafe(\belun)\)</span>
when it is not empty and plays the uniform distribution on <span class="math notranslate nohighlight">\(A\)</span> otherwise.
It is denoted <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span>.</p>
</div>
</div><p>To play her maximal strategy at step <span class="math notranslate nohighlight">\(n\)</span>,
Eve only needs to keep track of her belief <span class="math notranslate nohighlight">\(\belun^n\)</span>,
thus <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span> can be implemented by Eve
using a finite-memory device which keeps track of the current belief.
Such a strategy is said to be <strong>belief-based</strong>.
We will use several times  the following technical lemma about belief-based strategies.</p>
<div class="proof lemma admonition" id="lem:borelcantelli">
<p class="admonition-title"><span class="caption-number">Lemma 254 </span> (NEEDS TITLE lem:borelcantelli)</p>
<div class="lemma-content section" id="proof-content">
<p>{Fix a BÃ¼chi game.}
Let <span class="math notranslate nohighlight">\(\LL \subseteq \parties{V}\)</span>
and <span class="math notranslate nohighlight">\(\sigma\)</span> a strategy for player <span class="math notranslate nohighlight">\(1\)</span>.
Assume that
<span class="math notranslate nohighlight">\(\sigma\)</span> is a belief
strategy,
<span class="math notranslate nohighlight">\(\LL\)</span> is downward-closed
(i.e. <span class="math notranslate nohighlight">\(L\in\LL \land L' \subseteq L \implies L'\in \LL\)</span>)
and for every <span class="math notranslate nohighlight">\(L\in\LL\setminus \{\emptyset\}\)</span> and every strategy <span class="math notranslate nohighlight">\(\tau\)</span>,
\begin{align}
\label{eq:pos}
&amp; \probimp{\sigma,\tau}{\delta_L}{\Reach} &gt; 0\enspace,\
\label{eq:belstab}
&amp;\probimp{\sigma,\tau}{\delta_L}{\forall n\in\NN,\belun^n\in \LL} = 1\enspace.
\end{align}
Then <span class="math notranslate nohighlight">\(\sigma\)</span> is almost-surely winning for the BÃ¼chi game from any support
<span class="math notranslate nohighlight">\(L\in \LL\setminus \{\emptyset\}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>{
Since <span class="math notranslate nohighlight">\(\LL\)</span> is downward-closed then <span class="math notranslate nohighlight">\(\forall L\in \LL,\forall l\in L, \{l\}\in\LL\)</span>
thus~\eqref{eq:pos} implies
\be
\forall L\in \LL,\forall l\in L,
\probimp{\sigma,\tau}{\delta_L}{\Reach\mid V_0=l} &gt; 0\enspace.
\label{eq:pos2}
\end{equation}
}
{
Once <span class="math notranslate nohighlight">\(\sigma\)</span> is fixed then the game is a one-player game with state space <span class="math notranslate nohighlight">\(V\times 2^V\)</span> and imperfect information and~\eqref{eq:pos2} implies that in this one-player game,
\be
\label{eq:sigmamproperty}
\forall L\in \LL,\forall l\in L, \forall \tau,
\probimp{\tau}{\delta_L}{\Reach \mid V_0=l} &gt; \varepsilon\enspace,
\ee
where <span class="math notranslate nohighlight">\(N=|K|\cdot 2^{|K|}\)</span>
and <span class="math notranslate nohighlight">\(\varepsilon = p_{\min}^{|K|\cdot 2^{|K|}}\)</span>
and <span class="math notranslate nohighlight">\(p_{\min}\)</span> is the minimal non-zero transition probability.
Moreover~\eqref{eq:belstab} implies that
in this one-player game the second component of the state space is always in <span class="math notranslate nohighlight">\(\LL\)</span>, whatever strategy <span class="math notranslate nohighlight">\(\tau\)</span> is played by player <span class="math notranslate nohighlight">\(2\)</span>.
Remind the definition
\begin{align*}
\winreach={\exists n\in\NN, C_n  = 1}\enspace.
\end{align*}
As a consequence, in this one-player game
for every <span class="math notranslate nohighlight">\(m\in\NN\)</span>,
and every behavioral strategy <span class="math notranslate nohighlight">\(\tau\)</span> and every <span class="math notranslate nohighlight">\(l\in V\)</span>,
\be
\label{eq:sigmamproperty2}
\probimp{\tau}{\delta_L}
{ \exists m \leq n \leq m+ N, C_n = 1 \mid
K_m = l
}
\geq \varepsilon,
\ee
whenever <span class="math notranslate nohighlight">\(\probimp{\tau}{\delta_L}{V_m=l} &gt; 0\)</span>.
}
We use the Borel-Cantelli Lemma to conclude the proof.
According to~\eqref{eq:sigmamproperty2},
for every <span class="math notranslate nohighlight">\(\tau\)</span>, <span class="math notranslate nohighlight">\(L\in\overline{\LL}\)</span>,
<span class="math notranslate nohighlight">\(m\in \NN\)</span>,
\be
\probimp{\tau}{\delta_L}
{ \exists n, mN \leq n &lt; (m+ 1)N, C_n=1
\mid V_{mN}
}
\geq \varepsilon,
\ee
which implies for every behavioral strategy <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(k,m\in\NN\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\probimp{\tau}{\delta_L}
{\forall n,  \left((m\cdot N) \leq n &lt; ((m+k) \cdot N) \implies  C_n \neq 1 \right)}\leq  \left(1 - \varepsilon\right)^k\enspace.
\]</div>
<p>Since <span class="math notranslate nohighlight">\(\sum_k \left(1 - \varepsilon\right)^k\)</span> is finite,
we can apply Borel-Cantelli Lemma for the events
<span class="math notranslate nohighlight">\((\{\forall n, m\cdot N \leq n &lt; (m+k) \cdot N \implies  C_n\neq 1\})_k\)</span>
and we get
<span class="math notranslate nohighlight">\(\nonumber
\probimp{\tau}{\delta_L}{\forall n, m\cdot N \leq n  \implies  C_n\neq 1}=0
\)</span>
thus
\be\label{eq:assss}\nonumber
\probimp{\tau}{\delta_L}{\winbuchi}=1\enspace.
\ee</p>
<p>As a consequence <span class="math notranslate nohighlight">\(\sigma\)</span> is almost-surely winning for the
BÃ¼chi game.</p>
</div>
<p>An important feature of the maximal strategy is the following.</p>
<div class="proof lemma admonition" id="lemma-9">
<p class="admonition-title"><span class="caption-number">Lemma 255 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>In a BÃ¼chi game
with observable actions,
let <span class="math notranslate nohighlight">\(\delta\in\Delta(K)\)</span> be an initial distribution which is not positively
winning for Adam,
i.e. <span class="math notranslate nohighlight">\(\supp(\delta)\not\in\LLA\)</span>.
Then for every strategy <span class="math notranslate nohighlight">\(\tau\)</span> of Adam
\begin{equation}
\label{eq:LLstable}
\mathbb{P}^{\sigma_\can,\tau}_{\delta}(\forall n \in \NN, \belun^n \not\in\LLA )=1\enspace.
\end{equation}</p>
<p>:label:
In a BÃ¼chi game
with observable actions,
let <span class="math notranslate nohighlight">\(\delta\in\Delta(K)\)</span> be an initial distribution which is not positively
winning for Adam,
i.e. <span class="math notranslate nohighlight">\(\supp(\delta)\not\in\LLA\)</span>.
Then for every strategy <span class="math notranslate nohighlight">\(\tau\)</span> of Adam
\begin{equation}
\label{eq:LLstable}
\mathbb{P}^{\sigma_\can,\tau}_{\delta}(\forall n \in \NN, \belun^n \not\in\LLA )=1\enspace.
\end{equation}</p>
<p>In a BÃ¼chi game
with observable actions,
let <span class="math notranslate nohighlight">\(\delta\in\Delta(K)\)</span> be an initial distribution which is not positively
winning for Adam,
i.e. <span class="math notranslate nohighlight">\(\supp(\delta)\not\in\LLA\)</span>.
Then for every strategy <span class="math notranslate nohighlight">\(\tau\)</span> of Adam
\begin{equation}
\label{eq:LLstable}
\mathbb{P}^{\sigma_\can,\tau}_{\delta}(\forall n \in \NN, \belun^n \not\in\LLA )=1\enspace.
\end{equation}</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We only provide a sketch of proof.
The proof is an induction based on the fact that for every non-empty subset <span class="math notranslate nohighlight">\(L\subseteq V\)</span>,</p>
<div class="math notranslate nohighlight">
\[
(L\not \in \LLA) \implies (\Isafe(L)\neq \emptyset)\enspace.
\]</div>
<p>Assume a contrario that <span class="math notranslate nohighlight">\(\Isafe(L) = \emptyset\)</span> for some <span class="math notranslate nohighlight">\(L\not \in \LLA\)</span>.
Then for every action <span class="math notranslate nohighlight">\(a\in A\)</span> there exists a signal <span class="math notranslate nohighlight">\(s_a\in S\)</span>
such that <span class="math notranslate nohighlight">\(\belun(L,s_a)\neq \emptyset\)</span> and <span class="math notranslate nohighlight">\(\belun(L,s_a) \in \LLA\)</span>.
Since <span class="math notranslate nohighlight">\(\belun(L,s_a)\neq \emptyset\)</span>, the definition of the belief operator implies:</p>
<div class="math notranslate nohighlight">
\[
\exists v_a\in L, w_a\in V,  t_a \in T, \text{ such that }  \tp(w_a,s_a,t_a)(v_a,\Act(s),\Act(t_a)) &gt; 0\enspace.
\]</div>
<p>But then Adam can win positively from <span class="math notranslate nohighlight">\(L\)</span> with the following strategy.
At the first round, Adam plays randomly any action in <span class="math notranslate nohighlight">\(A\)</span>.
At the next round, Adam picks up randomly a belief in  <span class="math notranslate nohighlight">\(\LLA\)</span> and
plays forever the corresponding positively winning strategy.
Remark that this strategy of Adam is not described as a behavioural strategy
but rather as a finite-memory strategy. Since actions are observable,
such a finite-memory strategy can be turned into a behavioural one,
see~\cite[Lemma 4.6 and 4.7]{BGGjacm}.</p>
<p>Why is Adam strategy positively winning from <span class="math notranslate nohighlight">\(L\)</span>?
Whatever action <span class="math notranslate nohighlight">\(a\in A\)</span> is played by Eve,
with positive probability she will receive signal <span class="math notranslate nohighlight">\(s_a\)</span>,
because Adam might play the action <span class="math notranslate nohighlight">\(\Act(t_a)\)</span>.
Since <span class="math notranslate nohighlight">\(\belun(L,s_a) \in \LLA\)</span> then there Adam might with positive probability
play a strategy positively winning when the initial belief
of Eve is <span class="math notranslate nohighlight">\(\belun(L,s_a)\)</span>. Thus whatever action Eve chooses,
she might lose with positive probability.</p>
</div>
<p>\medskip</p>
<p>The notion of maximal strategy being defined,
we can complete the proof of Theorem~\ref{theo:qdet}.
For that, we show that
<span class="math notranslate nohighlight">\(\sigma_{\can}\)</span>
is almost-surely
winning from every support not in <span class="math notranslate nohighlight">\(\LLA\)</span>.</p>
<p>Reachability and safety conditions can be easily encoded as BÃ¼chi conditions,
thus it is enough to consider  BÃ¼chi games.</p>
<p>The first step is to prove that for every <span class="math notranslate nohighlight">\(L\in\LLE\)</span>,
for every strategy <span class="math notranslate nohighlight">\(\tau\)</span> of Adam,
\be\label{eq:LLpasM}
\probimp{\sigma_{\can},\tau}{\delta_L}{\winsafe} &lt; 1 \enspace.
\ee
We prove~\eqref{eq:LLpasM} by contradiction.
Assume~\eqref{eq:LLpasM} does not hold for some <span class="math notranslate nohighlight">\(L\in \LLE\)</span>
and strategy <span class="math notranslate nohighlight">\(\tau\)</span>:
\be\label{eq:winsafe}
\probimp{\sigma_{\can},\tau}{\delta_L}{\winsafe } = 1\enspace.
\ee
Under this assumption we use <span class="math notranslate nohighlight">\(\tau\)</span> to build a strategy positively winning from <span class="math notranslate nohighlight">\(L\)</span>,
which will contradict the hypothesis
<span class="math notranslate nohighlight">\(L\in\LLA\)</span>.
Although <span class="math notranslate nohighlight">\(\tau\)</span> is surely winning from <span class="math notranslate nohighlight">\(L\)</span> against the particular strategy <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span>,
there is no reason for <span class="math notranslate nohighlight">\(\tau\)</span> to be positively winning from <span class="math notranslate nohighlight">\(L\)</span>
against all other strategies of player <span class="math notranslate nohighlight">\(1\)</span>.
{
However we can rely on <span class="math notranslate nohighlight">\(\tau\)</span>
in order to define another strategy
<span class="math notranslate nohighlight">\(\tau'\)</span> for Adam positively winning from <span class="math notranslate nohighlight">\(L\)</span>.
The strategy <span class="math notranslate nohighlight">\(\tau'\)</span> is a strategy
which gives positive probability to play <span class="math notranslate nohighlight">\(\tau\)</span>
all along the play,
as well as any strategy in the family
of strategies
<span class="math notranslate nohighlight">\((\tau_{n,B})_{n\in\NN,B\in \LLA}\)</span> defined as follows.
For every <span class="math notranslate nohighlight">\(B\in\LLA\)</span> we choose a strategy <span class="math notranslate nohighlight">\(\tau_B\)</span> positively winning from <span class="math notranslate nohighlight">\(B\)</span>.
Then
<span class="math notranslate nohighlight">\(\tau_{n,B}\)</span> is the strategy which plays
the uniform distribution on <span class="math notranslate nohighlight">\(A\)</span> for the first <span class="math notranslate nohighlight">\(n\)</span> steps then forgets past signals and switches definitively to <span class="math notranslate nohighlight">\(\tau_B\)</span>.</p>
<p>A possible way to implement the  strategy <span class="math notranslate nohighlight">\(\tau'\)</span>
is as follows.
At the beginning of the play
player <span class="math notranslate nohighlight">\(2\)</span> tosses a fair coin. If the result is head then he plays <span class="math notranslate nohighlight">\(\tau\)</span>. Otherwise he keeps
tossing coins and as long as the coin toss is head, player <span class="math notranslate nohighlight">\(2\)</span> plays randomly an action in <span class="math notranslate nohighlight">\(J\)</span> .
The day the coin toss is tail, he picks up randomly some <span class="math notranslate nohighlight">\(B\in\LLA\)</span> and starts playing <span class="math notranslate nohighlight">\(\tau_B\)</span>.
}
Remark that this strategy of Adam is not described as a behavioural strategy
but, since actions are observable,
such a finite-memory strategy can be turned into a behavioural one,
see~\cite[Lemma 4.6 and 4.7]{BGGjacm}.</p>
<p>Now that <span class="math notranslate nohighlight">\(\tau'\)</span> is defined, we prove it is positively winning from <span class="math notranslate nohighlight">\(L\)</span>.
Let <span class="math notranslate nohighlight">\(E\)</span> be the event
{player <span class="math notranslate nohighlight">\(1\)</span> plays only actions that are safe with respect to her belief, i.e.}</p>
<div class="math notranslate nohighlight">
\[
E = \{ \forall n\in \NN, A_n \in \Isafe_\LL(\belun^n)\}\enspace.
\]</div>
<p>Then for every behavioral strategy <span class="math notranslate nohighlight">\(\sigma\)</span>:</p>
<ul class="simple">
<li><p>[\textbullet]
Either <span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{E}=1\)</span>. In this case</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\probimp{\sigma,\tau'}{\delta_L}{\winsafe}&gt; 0\enspace,
\]</div>
<p>because for every {finite play <span class="math notranslate nohighlight">\(\play=v_0a_0b_0s_1t_1v_1\cdots v_n\)</span>,}</p>
<div class="math notranslate nohighlight">
\[
\left(\probimp{\sigma,\tau'}{\delta_L}{\play} &gt; 0\right)
\implies
\left(\probimp{\sigma_{\can},\tau'}{\delta_L}{\play} &gt; 0\right)
\implies
\winsafe\enspace,
\]</div>
<p>where the first implication holds because, by definition of <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span> and <span class="math notranslate nohighlight">\(E\)</span>,
for every <span class="math notranslate nohighlight">\(s_1\cdots s_n\in CS^*, \supp(\sigma(s_1\cdots s_n))\subseteq \supp(\sigma_{\can}(s_1\cdots s_n))\)</span>
while the second implication is from~\eqref{eq:winsafe}.
Thus <span class="math notranslate nohighlight">\(\probimp{\sigma,\tau}{\delta_L}{\winsafe}= 1\)</span> and we get
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{\winsafe} &gt; 0\)</span> by definition of
<span class="math notranslate nohighlight">\(\tau'\)</span>.</p>
<ul class="simple">
<li><p>[\textbullet]
Or <span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{E}&lt;1\)</span>.
Then by definition of <span class="math notranslate nohighlight">\(E\)</span> there exists <span class="math notranslate nohighlight">\(n\in\NN\)</span>
such that</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\probimp{\sigma,\tau'}{\delta_L}{A_n  \not\in
\Isafe_\LL(\belun^n)}&gt;0\enspace.
\]</div>
<p>{
By definition of <span class="math notranslate nohighlight">\(\Isafe_\LL\)</span> it implies
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{\belun^{n+1}  \in \LL}&gt;0\)</span>,
thus there exists <span class="math notranslate nohighlight">\(B\in \LL\)</span> such that
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{\belun^{n+1} =B}&gt;0\)</span>.
By definition of <span class="math notranslate nohighlight">\(\tau'\)</span> we get
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau_{n+1,B}}{\delta_L}{\belun^{n+1} =B}&gt;0\)</span>,
because whatever finite play <span class="math notranslate nohighlight">\(v_0,\ldots, v_{n+1}\)</span> leads with positive probability to
the event <span class="math notranslate nohighlight">\(\{\belun^{n+1} =B\}\)</span>,
the same finite play can occur with
<span class="math notranslate nohighlight">\(\tau_{n+1,B}\)</span> since <span class="math notranslate nohighlight">\(\tau_{n+1,B}\)</span> plays every possible action for the <span class="math notranslate nohighlight">\(n+1\)</span> first steps.
Since <span class="math notranslate nohighlight">\(\tau_{n+1,B}\)</span> coincides with <span class="math notranslate nohighlight">\(\tau_\rand\)</span> for the first <span class="math notranslate nohighlight">\(n+1\)</span> steps then
by definition of beliefs,
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau_{n+1,B}}{\delta_L}{\belun^{n+1} =B}&gt;0\)</span>
and <span class="math notranslate nohighlight">\(B\subseteq \{ k\in K\mid \probimp{\sigma,\tau_{n+1,B}}{\delta_L}{K_{n+1}=k\mid \belun^{n+1} =B}&gt;0\}\)</span>.
Using the definition of <span class="math notranslate nohighlight">\(\tau_B\)</span> we get
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau_{n+1,B}}{\delta_L}{\wincobuchi}&gt;0\)</span>.
}
As a consequence by definition of <span class="math notranslate nohighlight">\(\tau'\)</span>
we get  $ \probimp{\sigma,\tauâ}{\delta_L}{\wincobuchi}</p>
<blockquote>
<div><p>0 $.</p>
</div></blockquote>
<p>In both cases, for every <span class="math notranslate nohighlight">\(\sigma\)</span>,
<span class="math notranslate nohighlight">\(\probimp{\sigma,\tau'}{\delta_L}{\wincobuchi } &gt;0 \)</span>
thus <span class="math notranslate nohighlight">\(\tau'\)</span> is positively winning from <span class="math notranslate nohighlight">\(L\)</span>.
This contradicts the
hypothesis <span class="math notranslate nohighlight">\(L\in \LLE\)</span>. As a consequence we get~\eqref{eq:LLpasM} by contradiction.</p>
<p>\medskip</p>
<p>Using~\eqref{eq:LLpasM},
we apply Lemma~\ref{lem:borelcantelli} to the collection
<span class="math notranslate nohighlight">\(\overline{\LLA}\)</span> and the strategy <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span>.
The collection <span class="math notranslate nohighlight">\(\overline{\LLA}\)</span> is downward-closed because <span class="math notranslate nohighlight">\(\LLA\)</span> is upward-closed: if a support is positively winning for Adam then any greater support is positively winning as well, using the same positively winning strategy.</p>
<p>Thus <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span> is almost-surely winning for the BÃ¼chi game from every support in <span class="math notranslate nohighlight">\(\overline{\LLA}\)</span> i.e. every support which is not positively winning for Adam, hence the game is qualitatively determined.</p>
<p>\subsection{Decidability: proof of Theorem~\ref{th:main} and ~\ref{th:main2}}</p>
<p>\subsubsection{A naâive algorithm}
As a corollary of the proof of qualitative determinacy
(Theorem~\ref{theo:qdet}), we get a maximal strategy <span class="math notranslate nohighlight">\(\sigma_\can\)</span>
for player <span class="math notranslate nohighlight">\(1\)</span> (see Definition~\ref{def:maximalstrategy}) to win
almost-surely BÃ¼chi games.</p>
<div class="proof corollary admonition" id="cor:asmem">
<p class="admonition-title"><span class="caption-number">Corollary 256 </span> (NEEDS TITLE cor:asmem)</p>
<div class="corollary-content section" id="proof-content">
<p>If player <span class="math notranslate nohighlight">\(1\)</span> has an almost-surely winning strategy in a BÃ¼chi
game {with observable actions} then the maximal strategy <span class="math notranslate nohighlight">\(\sigma_{\can}\)</span> is almost-surely
winning.</p>
</div>
</div><p>{
A simple algorithm to decide for which player a
game is winning can be derived from Corollary~\ref{cor:asmem}:
this simple algorithm enumerates all possible belief strategies
and test each one of them to see if it is almost-surely
winning. The test reduces to checking positive winning in one-player co-BÃ¼chi games
and can be done in exponential time.
}
As there is a doubly exponential number of {belief} strategies,
this can be done in time doubly exponential.
This algorithm also appears in <span id="id5">[<span>GS-icalp09</span>]</span>.
This settles the upper bound for Theorem~\ref{th:main}. The lower bounds are established in
Theorem~\ref{theo-hard}, proving that this enumeration algorithm is
optimal for worst case complexity.  While optimal in the worst case,
this algorithm is {likely to be unefficient in practice}.  For instance, if player
<span class="math notranslate nohighlight">\(1\)</span> has no almost-surely winning strategy, then this algorithm will
enumerate every single of the doubly exponential many {possible belief}
strategies.  Instead, we provide fix-point algorithms which do not
enumerate every possible strategy in Theorem~\ref{theo:qdec1} for
reachability games and Theorem~\ref{theo:qdec2} for BÃ¼chi games.
Although they should perform better on games with particular
structures, these fix-point algorithms still have a worst-case
2-\EXPTIME\ complexity.</p>
<p>\subsubsection{A fix-point algorithm for reachability games}</p>
<p>We turn now to the {\color{black} (fix-points)} algorithms which compute the set of supports that
are almost-surely or positively winning for various objectives.
\newcounter{theo:qdec1}
\setcounter{theo:qdec1}{\value{theorem}}</p>
<div class="proof theorem admonition" id="Deciding positive winning in reachability games">
<p class="admonition-title"><span class="caption-number">Theorem 257 </span> (NEEDS LABEL Deciding positive winning in reachability games)</p>
<div class="theorem-content section" id="proof-content">
<p>\label{theo:qdec1} In a reachability game each initial distribution
<span class="math notranslate nohighlight">\(\delta\)</span> is either positively winning for player <span class="math notranslate nohighlight">\(1\)</span> or surely
winning for player <span class="math notranslate nohighlight">\(2\)</span>, and this depends only on
<span class="math notranslate nohighlight">\(\supp(\delta)\subseteq \states\)</span>.
The corresponding partition of <span class="math notranslate nohighlight">\(\parties{\states}\)</span> is computable in
time <span class="math notranslate nohighlight">\(\mathcal{O}\left(|G| \cdot 2^{|\states|}\right)\)</span>, where <span class="math notranslate nohighlight">\(|G| \)</span> denotes
the size of the description of the game,
as the largest fix-point of a monotonic operator
<span class="math notranslate nohighlight">\(\Phi:\parties{\parties{V}}\to \parties{\parties{V}}\)</span>
computable in time linear in <span class="math notranslate nohighlight">\(|G| \)</span>.</p>
</div>
</div><p>We denote <span class="math notranslate nohighlight">\(\targets\)</span> the set of vertices whose colour is <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(\LL_\infty\subseteq \parties{\states\bh\targets}\)</span>
be the greatest fix-point of the monotonic operator
<span class="math notranslate nohighlight">\(\Phi:\parties{\parties{\states\bh\targets}}\to \parties{\parties{\states\bh\targets}}\)</span> defined by:
\be
\label{eq:defphi}
\Phi(\LL)={L\in \LL \mid
\exists j_L\in J, \forall d\in\signauxdeux, (\action_2(d)=j_L)\implies (\beldeux(L,d)\in \LL \cup {\emptyset)}}\enspace,
\ee
in other words <span class="math notranslate nohighlight">\(\Phi(\LL)\)</span> is the set of supports
such that player <span class="math notranslate nohighlight">\(2\)</span> has an action which
ensure his next belief will be in <span class="math notranslate nohighlight">\(\LL\)</span>,
whatever signal <span class="math notranslate nohighlight">\(d\)</span> he might receive.
Let <span class="math notranslate nohighlight">\(\sigma_{\rand}\)</span> be the strategy for player <span class="math notranslate nohighlight">\(1\)</span> that plays randomly any action.</p>
<p>We are going to prove that:</p>
<ol class="simple">
<li><p>[(A)] every support in <span class="math notranslate nohighlight">\(\LL_\infty\)</span> is surely winning for player <span class="math notranslate nohighlight">\(2\)</span>,</p></li>
<li><p>[(B)] and <span class="math notranslate nohighlight">\(\sigma_{\rand}\)</span> is positively winning from any support <span class="math notranslate nohighlight">\(L\subseteq\states\)</span> which is not in <span class="math notranslate nohighlight">\(\LL_\infty\)</span>.</p></li>
</ol>
<p>We start with proving (A).
To win surely from any support <span class="math notranslate nohighlight">\(L\in\LL_\infty\)</span>, player <span class="math notranslate nohighlight">\(2\)</span> uses the following
belief strategy <span class="math notranslate nohighlight">\(\tau_B\)</span>: when the current belief of player <span class="math notranslate nohighlight">\(2\)</span> is <span class="math notranslate nohighlight">\(L\in\LL_\infty\)</span> then player <span class="math notranslate nohighlight">\(2\)</span>
plays an action <span class="math notranslate nohighlight">\(j_L\)</span> defined as in~\eqref{eq:defphi}.
By definition of <span class="math notranslate nohighlight">\(\Phi\)</span> and since <span class="math notranslate nohighlight">\(\LL_\infty\)</span> is a fix-point of <span class="math notranslate nohighlight">\(\Phi\)</span>,
there always exists such an action.
When playing with the belief strategy <span class="math notranslate nohighlight">\(\tau_B\)</span>,
starting from a support in <span class="math notranslate nohighlight">\(\LL_\infty\)</span>,
the beliefs of player <span class="math notranslate nohighlight">\(2\)</span> stay in <span class="math notranslate nohighlight">\(\LL_\infty\)</span>
and never intersect <span class="math notranslate nohighlight">\(\targets\)</span> because <span class="math notranslate nohighlight">\(\LL_\infty\subseteq \parties{\states\bh\targets}\)</span>.
{According to property~\eqref{eq:beln_lemma} of beliefs (Lemma~\ref{lem:beliefs})},
this guarantees the play never visits <span class="math notranslate nohighlight">\(\targets\)</span>,
whatever strategy is used by player <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>We now prove (B).
Let
<span class="math notranslate nohighlight">\(\LL_0=\parties{\states\bh\targets}\supseteq
\LL_1=\Phi(\LL_0)\supseteq \LL_2=\Phi(\LL_1)\ldots\)</span> and <span class="math notranslate nohighlight">\(\LL_\infty\)</span>
be the limit of this sequence, the greatest fix-point of <span class="math notranslate nohighlight">\(\Phi\)</span>.
We
prove that for any support <span class="math notranslate nohighlight">\(L\in\parties{\states}\)</span>, if
<span class="math notranslate nohighlight">\(L\not\in\LL_\infty\)</span> then: \be\label{eq:postoprove} \text{<span class="math notranslate nohighlight">\(\sigma_{\rand}\)</span> is
positively winning for player <span class="math notranslate nohighlight">\(1\)</span> from <span class="math notranslate nohighlight">\(L\)</span>}\enspace.  \end{equation}If <span class="math notranslate nohighlight">\(L\cap\targets
\not=\emptyset\)</span>,~\eqref{eq:postoprove} is obvious.  To deal with
the case where {<span class="math notranslate nohighlight">\(L\cap \targets =\emptyset\)</span>}, we define for every
<span class="math notranslate nohighlight">\(n\in\NN\)</span>, <span class="math notranslate nohighlight">\(\KK_n = \parties{\states\bh\targets} \bh \LL_n\)</span>, and we
prove by induction on <span class="math notranslate nohighlight">\(n\in\NN\)</span> that for every <span class="math notranslate nohighlight">\(L\in\KK_n\)</span>, for every
initial distribution <span class="math notranslate nohighlight">\(\delta_L\)</span> with support <span class="math notranslate nohighlight">\(L\)</span>, for every {behavioral} strategy
<span class="math notranslate nohighlight">\(\tau\)</span>, \be\label{eq:topo} \probimp{\sigma_{\rand},\tau}{\delta_L}{\exists m, 2\leq
m\leq n+1, V_m\in\targets }&gt;0 \enspace.  \end{equation}For
<span class="math notranslate nohighlight">\(n=0\)</span>,~\eqref{eq:topo} is obvious because <span class="math notranslate nohighlight">\(\KK_0=\emptyset\)</span>.  Suppose
that for some <span class="math notranslate nohighlight">\(n\in\NN\)</span>, \eqref{eq:topo} holds for every <span class="math notranslate nohighlight">\(L'\in\KK_n\)</span>,
and let <span class="math notranslate nohighlight">\(L\in\KK_{n+1}\bh \KK_n\)</span>.
Then by definition of <span class="math notranslate nohighlight">\(\KK_{n+1}\)</span>, \be\label{eq:LLLn}
L\in\LL_{n}\bh\Phi(\LL_n)\enspace.  \end{equation}Let <span class="math notranslate nohighlight">\(\delta_L\)</span> be an initial
distribution with support <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> any behavioral strategy for player <span class="math notranslate nohighlight">\(2\)</span>.
Let <span class="math notranslate nohighlight">\(J_0\subseteq J\)</span> be the support of <span class="math notranslate nohighlight">\(\tau(\delta_L)\)</span> and <span class="math notranslate nohighlight">\(j_L\in J_0\)</span>.  According
to~\eqref{eq:LLLn}, by definition of <span class="math notranslate nohighlight">\(\Phi\)</span>, there exists a signal
<span class="math notranslate nohighlight">\(d\in D\)</span> such that <span class="math notranslate nohighlight">\(\action_2(d)=j_L\)</span> and
<span class="math notranslate nohighlight">\(\beldeux(L,d)\not \in \LL_n\)</span> and <span class="math notranslate nohighlight">\(\beldeux(L,d)\neq \emptyset\)</span>.
{According to  property~\eqref{eq:belief_compute} of beliefs (Lemma~\ref{lem:beliefs}),}
<span class="math notranslate nohighlight">\(\forall k \in \beldeux(L,d),\probimp{\sigma_{\rand},\tau}{\delta_L}{V_2 =k\land D_1=d}  &gt; 0\)</span>.
If
<span class="math notranslate nohighlight">\(\beldeux(L,d)\cap\targets \not= \emptyset\)</span> then according to
the definition of beliefs,
<span class="math notranslate nohighlight">\(\probimp{\sigma_{\rand},\tau}{\delta_L}{V_2\in\targets}&gt;0\)</span>.  Otherwise
<span class="math notranslate nohighlight">\(\beldeux(L,d)\in\parties{\states\bh\targets}\bh\LL_n=\KK_n\)</span> hence
distribution <span class="math notranslate nohighlight">\(\delta_{d}:k\to \probimp{\sigma_{\rand},\tau}{\delta_L}{V_2 =k\mid D_1=d}\)</span>
has its support in <span class="math notranslate nohighlight">\(\KK_n\)</span>. By inductive hypothesis, for every
behavioral strategy <span class="math notranslate nohighlight">\(\tau'\)</span>,</p>
<div class="math notranslate nohighlight">
\[\probimp{\sigma_{\rand},\tau'}{\delta_{d}}{\exists m\in\NN, 2\leq
  m\leq n+1, V_m\in\targets}&gt;0\]</div>
<p>hence using the shifting lemma and the
definition of <span class="math notranslate nohighlight">\(\delta_{d}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\probimp{\sigma_{\rand},\tau}{\delta}{\exists m\in\NN,
  3\leq m\leq n+2, V_m\in\targets}&gt;0\enspace,\]</div>
<p>which completes the proof of the inductive
step.
{
Hence~\eqref{eq:topo} holds for every behavioral strategy
<span class="math notranslate nohighlight">\(\tau\)</span>. Thus, according to Lemma~\ref{actioneq3},~\eqref{eq:topo}
holds as well for every general strategy <span class="math notranslate nohighlight">\(\tau\)</span>.
}</p>
<p>To compute
the partition of supports between those positively winning for player <span class="math notranslate nohighlight">\(1\)</span>
and those surely winning for player <span class="math notranslate nohighlight">\(2\)</span>,
it is enough to compute
the largest fix-point of <span class="math notranslate nohighlight">\(\Phi\)</span>.
Since <span class="math notranslate nohighlight">\(\Phi\)</span> is monotonic, and each application of the operator
can be computed in time linear in the size of the game (<span class="math notranslate nohighlight">\(|G|\)</span>)
and the number of supports (<span class="math notranslate nohighlight">\(2^{|\states|}\)</span>)
the overall computation can be achieved in time <span class="math notranslate nohighlight">\(|G| \cdot 2^{|\states|}\)</span>.
To compute the strategy <span class="math notranslate nohighlight">\(\tau_B\)</span>, it is enough to compute
for each <span class="math notranslate nohighlight">\(L\in\LL_\infty\)</span> one action <span class="math notranslate nohighlight">\(j_L\)</span> such that
<span class="math notranslate nohighlight">\((\action_2(d)=j_L)\implies (\beldeux(L,d)\in\LL_\infty)\)</span>.</p>
</div>
<p>As a byproduct of the proof one obtains the following bounds on time
and probabilities before reaching a target state, when player <span class="math notranslate nohighlight">\(1\)</span> uses
the uniform memoryless strategy <span class="math notranslate nohighlight">\(\sigma_{\rand}\)</span>.  From an initial
distribution positively winning for the reachability objective, for
every strategy <span class="math notranslate nohighlight">\(\tau\)</span>, \be\label{eq:bounds}
\probimp{\sigma_{\rand},\tau}{\delta}{\exists n\leq 2^{\mid \states
\mid}, C_n = 1}\geq \left(
\frac{1}{p_{\min}\mid\actionsun\mid}\right)^{2^{\lvert\states\lvert}}\enspace,
\end{equation}
where <span class="math notranslate nohighlight">\(p_{\min}\)</span> is the smallest non-zero transition probability.</p>
<p>\subsubsection{A fix-point algorithm for BÃ¼chi games}</p>
<p>To decide whether player <span class="math notranslate nohighlight">\(1\)</span> wins almost-surely a BÃ¼chi game,
we provide an algorithm which runs in doubly-exponential time.
It uses the algorithm for reachability games as a sub-procedure.</p>
<div class="proof theorem admonition" id="Deciding almost-sure winning in B&amp;uuml;chi games">
<p class="admonition-title"><span class="caption-number">Theorem 258 </span> (NEEDS LABEL Deciding almost-sure winning in BÃ¼chi games)</p>
<div class="theorem-content section" id="proof-content">
<p>\label{theo:qdec2} In a BÃ¼chi game each initial distribution
<span class="math notranslate nohighlight">\(\delta\)</span> is either almost-surely winning for player <span class="math notranslate nohighlight">\(1\)</span> or
positively winning for player <span class="math notranslate nohighlight">\(2\)</span>, and this depends only on
<span class="math notranslate nohighlight">\(\supp(\delta)\subseteq \states\)</span>.
The corresponding partition of <span class="math notranslate nohighlight">\(\parties{\states}\)</span> is computable in
time <span class="math notranslate nohighlight">\(\mathcal{O}\left(2^{2^{|G|}}\right)\)</span>, where <span class="math notranslate nohighlight">\(|G|\)</span> denotes the size of the description of the game,
as a projection of the greatest
fix-point <span class="math notranslate nohighlight">\(\LL_\infty\)</span>
of a monotonic operator</p>
<div class="math notranslate nohighlight">
\[\Psi:
\parties{\parties{\states}\times\states}
\to
\parties{\parties{\states}\times\states}
\enspace.
\]</div>
<p>The operator <span class="math notranslate nohighlight">\(\Psi\)</span> is computable using as a nested fix-point the operator <span class="math notranslate nohighlight">\(\Phi\)</span> of Theorem~\ref{theo:qdec1}.
The almost-surely winning belief strategy of player <span class="math notranslate nohighlight">\(1\)</span> and the positively winning <span class="math notranslate nohighlight">\(2\)</span>-belief strategy of player <span class="math notranslate nohighlight">\(2\)</span>  can be extracted
from <span class="math notranslate nohighlight">\(\LL_\infty\)</span>.</p>
</div>
</div><p>\smallskip
We sketch the main ideas of the proof of Theorem~\ref{theo:qdec2}.</p>
<p>First, suppose that from <strong>every</strong> initial support, player <span class="math notranslate nohighlight">\(1\)</span> can
win positively the  reachability game.
{Then she can do so using a belief strategy and according to Lemma~\ref{lem:borelcantelli},}
this strategy guarantees
almost-surely the BÃ¼chi condition.</p>
<p>In general though player <span class="math notranslate nohighlight">\(1\)</span> is not in such an easy situation and
there exists a support <span class="math notranslate nohighlight">\(L\)</span> which is <strong>not</strong> positively winning
for her for the reachability objective.
Then by qualitative determinacy, player <span class="math notranslate nohighlight">\(2\)</span> has a strategy to achieve surely her safety objective
from <span class="math notranslate nohighlight">\(L\)</span>, which is <strong>a fortiori</strong>
surely winning for her co-BÃ¼chi objective as well.</p>
<p>We prove that in case player <span class="math notranslate nohighlight">\(2\)</span> can <strong>force with positive
probability the belief of player <span class="math notranslate nohighlight">\(1\)</span></strong> to be <span class="math notranslate nohighlight">\(L\)</span> eventually from another
support <span class="math notranslate nohighlight">\(L'\)</span>, then player <span class="math notranslate nohighlight">\(2\)</span>
{ has a general strategy to win positively from <span class="math notranslate nohighlight">\(L'\)</span>}.
This is not completely obvious because in general player <span class="math notranslate nohighlight">\(2\)</span> cannot
know exactly <strong>when</strong> the belief of player <span class="math notranslate nohighlight">\(1\)</span> is <span class="math notranslate nohighlight">\(L\)</span> (he can only
compute the 2-Belief, letting him know all the possible beliefs player
1 can have).  However player <span class="math notranslate nohighlight">\(2\)</span> can make blind guesses,
and be right with <span class="math notranslate nohighlight">\(&gt;0\)</span> probability.
For winning positively from <span class="math notranslate nohighlight">\(L'\)</span>, player <span class="math notranslate nohighlight">\(2\)</span> plays
totally randomly until he guesses randomly that the belief of player
<span class="math notranslate nohighlight">\(1\)</span> is <span class="math notranslate nohighlight">\(L\)</span>, at that moment he switches to a strategy surely winning
from <span class="math notranslate nohighlight">\(L\)</span>.  Such a strategy is far from being optimal, because player
<span class="math notranslate nohighlight">\(2\)</span> plays randomly and in most cases he makes a wrong guess about the
belief of player <span class="math notranslate nohighlight">\(1\)</span>.  However
there is a non zero probability for his guess to be right.</p>
<p>Hence, player <span class="math notranslate nohighlight">\(1\)</span> should surely avoid her belief to be <span class="math notranslate nohighlight">\(L\)</span>
or <span class="math notranslate nohighlight">\(L'\)</span> if she wants to win almost-surely.
However, doing so player <span class="math notranslate nohighlight">\(1\)</span> may prevent the play from
reaching target states, which may create another positively winning
support for player <span class="math notranslate nohighlight">\(2\)</span>, and so on. This is the basis of our fix-point algorithm.</p>
<p>Using these ideas, we prove that the set
<span class="math notranslate nohighlight">\(\LL_\infty\subseteq \parties{\states}\)</span> of supports almost-surely
winning for player <span class="math notranslate nohighlight">\(1\)</span> for the BÃ¼chi objective is the largest set of
initial supports from which:
\begin{multline}
\label{eq-dag}
\tag{<span class="math notranslate nohighlight">\(\dag\)</span>}
\textrm{player <span class="math notranslate nohighlight">\(1\)</span> has a strategy
which win positively the reachability game}\
\textrm{and also ensures at the same time
her belief to stay in } \LL_\infty .
\end{multline}</p>
<p>Property \eqref{eq-dag} can be reformulated as a reachability
condition in a new game whose states are states of the original game
augmented with beliefs of player <span class="math notranslate nohighlight">\(1\)</span>, kept hidden to player <span class="math notranslate nohighlight">\(2\)</span>.</p>
<p>The fix-point characterisation suggests the following algorithm for
computing the set of supports positively winning for player <span class="math notranslate nohighlight">\(2\)</span>:
<span class="math notranslate nohighlight">\(\parties{\states}\bh\LL_\infty\)</span> is the limit of the sequence
<span class="math notranslate nohighlight">\(\emptyset=\LL_0'\subsetneq \LL_0'\cup \LL_1''\subsetneq\LL_0'\cup
\LL_1'\subsetneq \LL_0'\cup \LL_1'\cup \LL_2''\subsetneq\ldots
\subsetneq \LL_0'\cup \cdots \cup \LL'_m
=\parties{\states}\bh\LL_\infty\)</span>, where</p>
<ul class="simple">
<li><p>[(a)]
from supports in <span class="math notranslate nohighlight">\(\LL''_{i+1}\)</span> player <span class="math notranslate nohighlight">\(2\)</span> can surely guarantee the safety objective,
under the hypothesis that player <span class="math notranslate nohighlight">\(1\)</span>
{guarantees for sure} her beliefs to stay outside <span class="math notranslate nohighlight">\(\LL'_i\)</span>,</p></li>
<li><p>[(b)]
from supports in <span class="math notranslate nohighlight">\(\LL'_{i+1}\)</span> player <span class="math notranslate nohighlight">\(2\)</span> can ensure with positive probability the belief of player
<span class="math notranslate nohighlight">\(1\)</span> to be in <span class="math notranslate nohighlight">\(\LL''_{i+1}\)</span> eventually,
under the same hypothesis.</p></li>
</ul>
<p>The overall strategy of player <span class="math notranslate nohighlight">\(2\)</span> positively winning for the co-BÃ¼chi objective
consists in playing randomly for some time until he decides to pick
up randomly a belief <span class="math notranslate nohighlight">\(L\)</span> of player <span class="math notranslate nohighlight">\(1\)</span> in some <span class="math notranslate nohighlight">\(\LL''_i\)</span>,
bets that the current belief of player <span class="math notranslate nohighlight">\(1\)</span> is <span class="math notranslate nohighlight">\(L\)</span> and that player <span class="math notranslate nohighlight">\(1\)</span>
guarantees for sure
her future beliefs
will stay outside <span class="math notranslate nohighlight">\(\LL'_i\)</span>.
He forgets
the signals he has received up to that moment and switches
definitively to a strategy which guarantees (a).  With positive
probability, player <span class="math notranslate nohighlight">\(2\)</span> guesses correctly the belief of player <span class="math notranslate nohighlight">\(1\)</span> at the right moment, and
future beliefs of player <span class="math notranslate nohighlight">\(1\)</span> will stay in <span class="math notranslate nohighlight">\(\LL'_i\)</span>, in which case the
co-BÃ¼chi condition holds and player <span class="math notranslate nohighlight">\(2\)</span> wins.</p>
<p>{In order to ensure (a), player <span class="math notranslate nohighlight">\(2\)</span> makes use of the hypothesis
about player <span class="math notranslate nohighlight">\(1\)</span> beliefs staying outside <span class="math notranslate nohighlight">\(\LL_i'\)</span>. For that player <span class="math notranslate nohighlight">\(2\)</span> needs to keep track of all the possible beliefs of player <span class="math notranslate nohighlight">\(1\)</span>, hence the doubly-exponential memory.
The reason is player <span class="math notranslate nohighlight">\(2\)</span> can infer
from this data structure some information about the possible actions played by player <span class="math notranslate nohighlight">\(1\)</span>: in case
for every possible belief of player <span class="math notranslate nohighlight">\(1\)</span> an action <span class="math notranslate nohighlight">\(i\in I\)</span> creates a risk to reach <span class="math notranslate nohighlight">\(\LL'_i\)</span>
then player <span class="math notranslate nohighlight">\(2\)</span> knows for sure this action is not played by player <span class="math notranslate nohighlight">\(1\)</span>.
This in turn helps player <span class="math notranslate nohighlight">\(2\)</span> to know which are the possible states of the game.
Finally, when player <span class="math notranslate nohighlight">\(2\)</span> estimates the state of the game using his <span class="math notranslate nohighlight">\(2\)</span>-beliefs,
this gives a potentially more accurate estimation of the possible states than simply computing his <span class="math notranslate nohighlight">\(1\)</span>-beliefs.}</p>
<p>{The positively winning <span class="math notranslate nohighlight">\(2\)</span>-belief strategy of player <span class="math notranslate nohighlight">\(2\)</span> has a particular structure.
All memory updates are deterministic except for one: from
the initial memory state <span class="math notranslate nohighlight">\(\emptyset\)</span>,
whatever signal is received there is non-zero chance that the memory state stays <span class="math notranslate nohighlight">\(\emptyset\)</span> but it may as well
be updated to several other memory states.}
\smallskip</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./8_Imperfect"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="finite_duration.html" title="previous page">Finite duration</a>
    <a class='right-next' id="next-link" href="references.html" title="next page">Bibliographic references</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>