
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mean-payoff optimality in strongly connected MDPs &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="End components" href="end_components.html" />
    <link rel="prev" title="Mean-payoff in MDPs: General properties and linear programming" href="mean_payoff_properties.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     Büchi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Markov Decision Processes
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Infinite
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../9_Timed/index.html">
   Timed Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/state_space_representation.html">
     State-Space Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/controllable_predecessor_operator.html">
     Controllable-Predecessor Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/backward_algorithm.html">
     Backward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/forward_algorithm.html">
     Forward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10_Pushdown/index.html">
   Pushdown Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/profiles.html">
     Profiles and regularity of the winning regions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/parity.html">
     Parity pushdown games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11_Counters/index.html">
   Games with Counters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/counters.html">
     Vector games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/dim1.html">
     Games in dimension one
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/avag.html">
     Asymmetric games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/resource.html">
     Resource-conscious games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/complexity.html">
     The complexity of asymmetric monotone games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multi
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12_Multiobjectives/index.html">
   Games with multiple objectives
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/mean_payoff_energy.html">
     Mean-payoff and energy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/total_payoff_shortest_path.html">
     Total-payoff and shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/beyond_worst_case.html">
     Beyond worst-case synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/percentile.html">
     Percentile queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13_Multiplayer/index.html">
   Multiplayer Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/nash_equilibria_normal_form.html">
     Nash Equilibria for games in normal form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/admissible_strategies.html">
     Admissible strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deterministic-optimality-in-strongly-connected-mdps">
   Deterministic optimality in strongly connected MDPs
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="mean-payoff-optimality-in-strongly-connected-mdps">
<span id="sec-mean-payoff-strongly-connected"></span><h1>Mean-payoff optimality in strongly connected MDPs<a class="headerlink" href="#mean-payoff-optimality-in-strongly-connected-mdps" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[\renewcommand{\Game}{\game}
\]</div>
<p>As shown in the previous section, the optimal solution of any of the programs <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}^{\mathit{dual}}\)</span> gives us an upper bound on the optimal value. In this sub-section we show that in strongly connected MDPs: a) a value of every vertex is the same; b) from a solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> one can extract a memoryless deterministic strategy <span class="math notranslate nohighlight">\(\sigma\)</span> whose expected mean-payoff is well defined (i.e., the preconditions of <a class="reference internal" href="mean_payoff_properties.html#5-lem:limit-defined">Lemma 167</a> are satisfied)) and equal to the objective value of the solution. Moreover, if the solution in question is optimal, then <span class="math notranslate nohighlight">\( \sigma \)</span> is optimal for both <span class="math notranslate nohighlight">\(\textsf{p-Payoff}\)</span>- and <span class="math notranslate nohighlight">\(\textsf{s-Payoff}\)</span>-semantics.</p>
<div class="proof definition admonition" id="5-def:scc-mdp">
<p class="admonition-title"><span class="caption-number">Definition 172 </span> (NEEDS TITLE 5-def:scc-mdp)</p>
<div class="definition-content section" id="proof-content">
<p>An MDP is <strong>strongly connected</strong> if for each pair of vertices <span class="math notranslate nohighlight">\(u,v\)</span> there exists a strategy which, when starting in <span class="math notranslate nohighlight">\(u\)</span>, reaches <span class="math notranslate nohighlight">\(v\)</span> with a positive probability.</p>
</div>
</div><p>For the rest of this section we fix an optimal solution <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{v,a}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>. We denote by <span class="math notranslate nohighlight">\(S\)</span> the set of all vertices for which there exists action <span class="math notranslate nohighlight">\(a\)</span> s.t. <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{v,a}&gt;0.\)</span> From the shape of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> it follows that <span class="math notranslate nohighlight">\(S\)</span> is non-empty and closed, and hence we can consider a sub-MDP <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}\)</span> induced by <span class="math notranslate nohighlight">\(S\)</span>. In <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}\)</span> we then define a memoryless randomized strategy <span class="math notranslate nohighlight">\(\sigma\)</span> by putting</p>
<div class="math notranslate nohighlight">
\[\sigma(a\mid v)=\frac{ \bar{\vec{x}}_{(v,a)}}{\sum_{b\in  A} \bar{\vec{x}}_{(v,b)}}.\]</div>
<p>Fixing a strategy <span class="math notranslate nohighlight">\(\sigma\)</span> yields a <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(\mathcal{M}_S^{\sigma}\)</span>. Markov chain can be viewed as an MDP with a single action (and hence, with no non-determinism). <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^\sigma\)</span> in particular can be viewed an MDP with the same vertices, edges, and colouring as <span class="math notranslate nohighlight">\(\mathcal{M}_S\)</span>, but with a single action (as non-determinism was already resolved by <span class="math notranslate nohighlight">\(\sigma\)</span>). The probability of transitioning from a vertex <span class="math notranslate nohighlight">\(u\)</span> to a vertex <span class="math notranslate nohighlight">\(v\)</span> in a Markov chain is denoted by <span class="math notranslate nohighlight">\(P_{u,v}\)</span>. In <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span> we have <span class="math notranslate nohighlight">\(P_{u,v}=\sum_{a\in  A}  \Delta(v\mid u,a)\cdot\sigma(a\mid u)\)</span>, the right-hand side being computed in the original MDP <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. Both <span class="math notranslate nohighlight">\(\mathcal{M}_S\)</span> and <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span> have the same sets of plays and for each initial vertex, the probability measure induced by <span class="math notranslate nohighlight">\(\sigma\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> equals the probability measure arising (under the unique policy) in <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>. Hence, to prove anything about <span class="math notranslate nohighlight">\(\sigma\)</span> it suffices to analyse <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>.</p>
<blockquote>
<div><p><strong>A refresher on Markov chains.</strong></p>
</div></blockquote>
<p>We review some fundamental notions of Markov chain theory <span id="id1">[<a class="reference internal" href="references.html#id121"><span>Nor98</span></a>]</span>. A Markov chain that is strongly connected is called <strong>irreducible</strong>. The one-step transition probabilities in a Markov chain can be arranged into a square matrix <span class="math notranslate nohighlight">\(P\)</span>, which has one row and one column for each vertex. The cell in the row corresponding to a vertex <span class="math notranslate nohighlight">\(u\)</span> and in the column corresponding to a vertex <span class="math notranslate nohighlight">\(v\)</span> bears the value <span class="math notranslate nohighlight">\(P_{u,v}\)</span> defined above. An easy induction shows that the matrix <span class="math notranslate nohighlight">\(P^k\)</span> contains <span class="math notranslate nohighlight">\(k\)</span>-step transition probabilities. That is, the probability of being in <span class="math notranslate nohighlight">\(v\)</span> after <span class="math notranslate nohighlight">\(k\)</span> steps from vertex <span class="math notranslate nohighlight">\(u\)</span> is equal to the <span class="math notranslate nohighlight">\((u,v)\)</span>-cell of <span class="math notranslate nohighlight">\(P^k\)</span>, which we denote by <span class="math notranslate nohighlight">\(P^{(k)}_{u,v}\)</span>.</p>
<p>A vertex <span class="math notranslate nohighlight">\(u\)</span> of a Markov chain is <strong>recurrent</strong> if, when starting from <span class="math notranslate nohighlight">\(u\)</span>, it is revisited infinitely often with probability <span class="math notranslate nohighlight">\(1\)</span>. On the other hand, if the probability that <span class="math notranslate nohighlight">\(u\)</span> is re-visited only finitely often is one, then the vertex is <strong>transient</strong>. It is known (Theorem 1.5.3 in <span id="id2">[<a class="reference internal" href="references.html#id121"><span>Nor98</span></a>]</span>) that each vertex of a finite Markov chain is either recurrent or transient, and that these two properties can be equivalently characterized as follows: vertex <span class="math notranslate nohighlight">\(u\)</span> is recurrent if and only if  <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty} P^{(k)}_{u,u}=\infty\)</span>, otherwise it is transient.</p>
<p>An <strong>invariant distribution</strong> in a Markov chain with a vertex set <span class="math notranslate nohighlight">\(V\)</span> is a <span class="math notranslate nohighlight">\(| V|\)</span>-dimensional non-negative row vector <span class="math notranslate nohighlight">\(\vec{z}\)</span> which adds up to <span class="math notranslate nohighlight">\(1\)</span> and satisfies <span class="math notranslate nohighlight">\(  \vec{z}\cdot  P =  \vec{z}\)</span>.</p>
<p>The following lemma holds for arbitrary finite Markov chains.</p>
<div class="proof lemma admonition" id="5-lem:MC-inv-rec">
<p class="admonition-title"><span class="caption-number">Lemma 173 </span> (NEEDS TITLE 5-lem:MC-inv-rec)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\vec{z}\)</span> be an invariant distribution and <span class="math notranslate nohighlight">\(v\)</span> a vertex such that <span class="math notranslate nohighlight">\(\vec{z}_v &gt; 0\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(n\)</span> be the number of vertices in the chain and <span class="math notranslate nohighlight">\(p_{\min}\)</span> the minimum non-zero entry of <span class="math notranslate nohighlight">\(P\)</span>.
Assume, for the sake of contradiction, that <span class="math notranslate nohighlight">\(v\)</span> is transient. We show that in such a case, for each vertex <span class="math notranslate nohighlight">\(u\)</span> it holds <span class="math notranslate nohighlight">\(\lim_{k\rightarrow\infty}  P^{(k)}_{u,v} = 0\)</span>. For <span class="math notranslate nohighlight">\(u=v\)</span> this is immediate, since the sum <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty} P^{(k)}_{v,v}\)</span> converges for  transient <span class="math notranslate nohighlight">\(v\)</span>. Otherwise, let <span class="math notranslate nohighlight">\(f_{u,v,i}\)</span> be the probability that a play starting in <span class="math notranslate nohighlight">\(u\)</span> visits <span class="math notranslate nohighlight">\(v\)</span> for the <strong>first time</strong> in exactly <span class="math notranslate nohighlight">\(i\)</span> steps. Then <span class="math notranslate nohighlight">\(P^{(k)}_{u,v}=\sum_{i=0}^k f_{u,v,i}\cdot  P^{(k-i)}_{v,v}\)</span>. Now when starting in a vertex from which <span class="math notranslate nohighlight">\(v\)</span> is reachable with a positive probability, at least one of the following events happens with probability <span class="math notranslate nohighlight">\(\geq p_{\min}^n\)</span> in the first <span class="math notranslate nohighlight">\(n\)</span> steps: either we reach a vertex from which <span class="math notranslate nohighlight">\(v\)</span> is not reachable with positive probability, or we reach <span class="math notranslate nohighlight">\(v\)</span>. If neither of the events happens, we are, after <span class="math notranslate nohighlight">\(n\)</span> steps, still in a vertex from which <span class="math notranslate nohighlight">\(v\)</span> can be reached with a positive probability. In such a case, the argument can be inductively repeated (analogously to the proof of <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 148</a>) to show that <span class="math notranslate nohighlight">\(f_{u,v,i}\leq (1-p_{\min}^n)^{\lfloor\frac{i}{n}\rfloor}\leq (1-p_{\min}^n)^{\frac{i-n}{n}}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty} P^{(k)}_{v,v}\)</span> converges, for each <span class="math notranslate nohighlight">\(\varepsilon&gt;0\)</span> there exists <span class="math notranslate nohighlight">\(j_\varepsilon\)</span> such that <span class="math notranslate nohighlight">\(\sum_{i=j_{ \varepsilon}}^{\infty} P^{(i)}_{v,v} &lt; \frac{ \varepsilon}{2}\)</span>. Similarly, there exists <span class="math notranslate nohighlight">\(\ell_\varepsilon\)</span> such that</p>
<div class="math notranslate nohighlight">
\[\sum_{i=\ell_{ \varepsilon}}^{\infty}{(1-p_{\min}^n)^{\frac{i-n}{n}}} = \frac{(1-p_{\min}^n)^{\frac{\ell_\varepsilon}{n}}}{\left(1-(1-p_{\min}^n)^{\frac{1}{n}}\right)\cdot(1-p_{\min}^n)}&lt; \frac{ \varepsilon}{2},\]</div>
<p>and hence <span class="math notranslate nohighlight">\(\sum_{i=\ell_{ \varepsilon}}^{\infty} f_{u,v,i}&lt; \frac{ \varepsilon}{2}.\)</span></p>
<p>Now we put <span class="math notranslate nohighlight">\(m_{ \varepsilon}=\max\{j_\varepsilon,\ell_\varepsilon\}\)</span>. For any <span class="math notranslate nohighlight">\(k\geq 2m_{ \varepsilon}\)</span> we have <span class="math notranslate nohighlight">\(P^{(k)}_{u,v}=\sum_{i=0}^k f_{u,v,i}\cdot  P^{(k-i)}_{v,v} \leq \sum_{i=m_{ \varepsilon}}^{k}f_{u,v,i} + \sum_{i=0}^{m_{ \varepsilon}} P^{(k-i)}_{v,v}\leq\sum_{i=m_{ \varepsilon}}^{k}f_{u,v,i} + \sum_{i=m_{ \varepsilon}}^{k} P^{(i)}_{v,v}&lt; \varepsilon\)</span> (note that all the series involved are non-negative). This proves that <span class="math notranslate nohighlight">\(P^{(k)}_{u,v}\)</span> vanishes in the limit.</p>
<p>Finally, we derive the contradiction. Since <span class="math notranslate nohighlight">\(\vec{z}\)</span> satisfies <span class="math notranslate nohighlight">\(\vec{z}\cdot  P =  \vec{z}\)</span>, we also have <span class="math notranslate nohighlight">\(\vec{z}\cdot  P^k =  \vec{z}\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>. Hence, the <span class="math notranslate nohighlight">\(v\)</span>-component of <span class="math notranslate nohighlight">\(\vec{z}\cdot  P^k\)</span> is equal to <span class="math notranslate nohighlight">\(\vec{z}_v&gt;0\)</span>. But as shown above, the <span class="math notranslate nohighlight">\(v\)</span>-column of <span class="math notranslate nohighlight">\(P^k\)</span> converges to the all-zero vector as <span class="math notranslate nohighlight">\(k\rightarrow \infty\)</span>, so also <span class="math notranslate nohighlight">\(( \vec{z}\cdot  P^k)_v\)</span> vanishes in the limit, a contradiction.</p>
</div>
<blockquote>
<div><p><strong>Towards the optimality of <span class="math notranslate nohighlight">\( \sigma \)</span>.</strong></p>
</div></blockquote>
<p>We now turn back to the chain <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>, where the memoryless strategy <span class="math notranslate nohighlight">\( \sigma \)</span> is obtained from the optimal solution of <span class="math notranslate nohighlight">\(   \mathcal{L}_{\mathit{mp}} \)</span>. In general, <span class="math notranslate nohighlight">\(  \mathcal{M}_{ S}^{\sigma} \)</span> does not have to be irreducible. Hence, we use the following lemma and its corollary to extract an irreducible sub-chain, to which we can apply known results of Markov chain theory.</p>
<div class="proof lemma admonition" id="5-lem:mc-rec">
<p class="admonition-title"><span class="caption-number">Lemma 174 </span> (NEEDS TITLE 5-lem:mc-rec)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bar{ \vec{z}}\)</span> be a vector such that for each <span class="math notranslate nohighlight">\(v\in  S\)</span> it holds <span class="math notranslate nohighlight">\(\bar{ \vec{z}}_v=\sum_{a\in  A}  \bar{\vec{x}}_{v,a}\)</span>. Then <span class="math notranslate nohighlight">\(\bar{ \vec{z}}\)</span> is an invariant distribution of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>. Consequently, all vertices of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span> are recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The first part follows directly from the fact that <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{v,a}\)</span> is a feasible solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>. The second part follows from <a class="reference internal" href="#5-lem:MC-inv-rec">Lemma 173</a> and from the fact that <span class="math notranslate nohighlight">\(\bar \vec{z}\)</span> is positive (by the definition of <span class="math notranslate nohighlight">\(S\)</span>).</p>
</div>
<div class="proof corollary admonition" id="5-cor:mp-scc-extraction">
<p class="admonition-title"><span class="caption-number">Corollary 175 </span> (NEEDS TITLE 5-cor:mp-scc-extraction)</p>
<div class="corollary-content section" id="proof-content">
<p>The set <span class="math notranslate nohighlight">\(S\)</span> can be partitioned into subsets <span class="math notranslate nohighlight">\(S_1, S_2,\dots, S_m\)</span> such that each <span class="math notranslate nohighlight">\(S_i\)</span> induces a strongly connected sub-chain of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(v\in S\)</span> be arbitrary and let <span class="math notranslate nohighlight">\(U_v\subseteq  S\)</span> be the set of all vertices reachable with positive probability from <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is reachable (in <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>) with positive probability from each <span class="math notranslate nohighlight">\(u\in U_v\)</span>: otherwise, there would be a positive probability of never revisiting <span class="math notranslate nohighlight">\(v\)</span>, a contradiction with each vertex being recurrent in <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span> (<a class="reference internal" href="#5-lem:mc-rec">Lemma 174</a>). Hence, <span class="math notranslate nohighlight">\(U_v\)</span> induces a strongly connected sub-MDP (or sub-chain) of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>. It is easy to show that if <span class="math notranslate nohighlight">\(U_v \neq U_w\)</span> for some <span class="math notranslate nohighlight">\(v\neq w \)</span>, then the two sets must be disjoint.</p>
</div>
<p>Hence, we can extract from <span class="math notranslate nohighlight">\(S\)</span> a set <span class="math notranslate nohighlight">\(Q\)</span> inducing a strongly-connected sub-chain of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>, which we denote <span class="math notranslate nohighlight">\(\mathcal{M}^{\sigma}_{Q}\)</span>. The set <span class="math notranslate nohighlight">\(Q\)</span> also induces a strongly connected sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> denoted by <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span>. The chain <span class="math notranslate nohighlight">\(\mathcal{M}^{\sigma}_{Q}\)</span> arises by fixing, in <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span>, a strategy formed by a restriction of <span class="math notranslate nohighlight">\(\sigma\)</span> to <span class="math notranslate nohighlight">\(Q\)</span>. We use the following powerful theorem to analyse <span class="math notranslate nohighlight">\(\mathcal{M}^{\sigma}_{Q}\)</span>.</p>
<p>````{prf:theorem} Ergodic theorem; see Theorem 1.10.2 in <span id="id3">[<a class="reference internal" href="references.html#id121"><span>Nor98</span></a>]</span>
:label: 5-thm:ergodic
In a strongly connected Markov chain (with a finite set of vertices <span class="math notranslate nohighlight">\(V\)</span>) there exists a unique invariant distribution <span class="math notranslate nohighlight">\(\vec{z}\)</span>. Moreover, for every vector <span class="math notranslate nohighlight">\(\vec{h}\in  \mathbb{R}^{ V}\)</span> the following equation holds with probability 1:</p>
<div class="math notranslate nohighlight">
\[
\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{ \textrm{In}(\pi_i)} = \sum_{v\in V}  \vec{z}_v\cdot \vec{h}_v.
\]</div>
<p>(In particular, the limit is well-defined with probability 1).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
We can use the Ergodic theorem to shows that the expected mean-payoff achieved by $\sigma$ in $\mathcal{M}_{Q}$ matches the optimal value of $   \mathcal{L}_{\mathit{mp}} $, in a very strong sense: the probability of a play having a mean-payoff equal to this optimal value is 1 under $ \sigma $.

````{prf:theorem} NEEDS TITLE 5-cor:mp-scc-optimality
:label: 5-cor:mp-scc-optimality

Let $\sigma_Q$ be the restriction of $\sigma$ to $Q$. Then for every $v\in Q$ it holds that $\mathbb{P}^{\sigma_Q}_{ \mathcal{M}_Q,v}(  \mathtt{MeanPayoff}^{\;-} = r^*)=1$, where $r^*$ is the is the optimal value of $\mathcal{L}_{\mathit{mp}}$.

</pre></div>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\( \vec{w}\in \mathbb{R}^{ V \times A} \)</span> be a vector sych that <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}= \bar{\vec{x}}_{(v,a)}/\sum_{(q,a)\in Q\times A}  \bar{\vec{x}}_{(q,a)}\)</span> for every <span class="math notranslate nohighlight">\((v,a)\in Q\times  A\)</span>, and <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=0\)</span> for all other <span class="math notranslate nohighlight">\((v,a)\)</span>. We claim that <span class="math notranslate nohighlight">\( \vec{w} \)</span> is also an optimal solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>.</p>
<p>To prove feasibility, note that setting <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=0\)</span> for each <span class="math notranslate nohighlight">\(v\in  V\setminus Q\)</span> does not break the constraints <code class="xref eq docutils literal notranslate"><span class="pre">5-eq:mdp-flow</span></code>. This is because <span class="math notranslate nohighlight">\(Q\)</span> induces a strongly connected sub-chain of <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>, and hence there are no <span class="math notranslate nohighlight">\(v\in  V\)</span>, <span class="math notranslate nohighlight">\(u\in  V\setminus Q\)</span> such that <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{(u,a)}\cdot  \Delta(v\mid u,a)&gt;0\)</span>. Next, <code class="xref eq docutils literal notranslate"><span class="pre">5-eq:mdp-flow</span></code> is invariant w.r.t. multiplication of variables by a constant, so normalizing the remaining values preserves <code class="xref eq docutils literal notranslate"><span class="pre">5-eq:mdp-flow</span></code> and ensures that <code class="xref eq docutils literal notranslate"><span class="pre">5-eq:mdp-freq-1</span></code> holds.</p>
<p>To prove optimality, assume that the objective value of <span class="math notranslate nohighlight">\(\vec{w}\)</span> is smaller than <span class="math notranslate nohighlight">\(r^*\)</span>. Then we can mirror the construction from the previous paragraph and produce a feasible solution <span class="math notranslate nohighlight">\({\hat{\vec{w}}_{(v,a)}}\)</span> whose <span class="math notranslate nohighlight">\((Q\times A)\)</span>-indexed components are zero and the rest are normalized components of <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span>. Then <span class="math notranslate nohighlight">\(r^*\)</span> is a convex combination of the objective values of <span class="math notranslate nohighlight">\(\vec{w}\)</span> and <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span>, so <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span> must have a strictly larger value than <span class="math notranslate nohighlight">\(r^*\)</span>, a contradiction with the latter’s optimality.</p>
<p>We now plug <span class="math notranslate nohighlight">\( \vec{w} \)</span> into the ergodic theorem as follows: As in <a class="reference internal" href="#5-lem:mc-rec">Lemma 174</a>, it easy to prove that setting <span class="math notranslate nohighlight">\(\vec{z}_v=\sum_{a\in A}\vec{w}_{(v,a)}\)</span> yields an invariant distribution. Now put <span class="math notranslate nohighlight">\(\vec{h}_v=\sum_{a\in A}\sigma(a\mid v)\cdot  c(v,a)\)</span> (<span class="math notranslate nohighlight">\( =  \sum_{w \in  V}  P_{v,w}\cdot  c(v,w)\)</span>). From the Ergodic theorem we get that <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{ \textrm{In}(\pi_i)}\)</span> almost-surely exists and equals</p>
<div class="math notranslate nohighlight" id="equation-5-eq-mc-opt-limit">
<span class="eqno">(11)<a class="headerlink" href="#equation-5-eq-mc-opt-limit" title="Permalink to this equation">¶</a></span>\[\begin{split}\sum_{v\in Q}  \vec{z}_v\cdot \vec{h}_v &amp;= \sum_{v\in  V} \left(\big(\sum_{d\in A}\vec{w}_{(v,d)}\big)\cdot \big(\sum_{a\in A}\sigma(a\mid v)\cdot  c(v,a) \big)\right) \nonumber\\
&amp;= \sum_{v\in Q} \left(\Bigg( \frac{\sum_{d\in A} \bar{\vec{x}}_{(v,d)}}{\sum\limits_{\substack{q\in Q\\ b\in  A}}  \bar{\vec{x}}_{(q,b)}} \Bigg)\cdot \Bigg( \frac{\sum_{a\in A} \bar{\vec{x}}_{(v,a)}\cdot c(v,a)}{\sum\limits_{d\in   A}  \bar{\vec{x}}_{(v,d)}} \Bigg) \right) \nonumber\\
&amp;= \frac{1}{\sum\limits_{\substack{q\in Q\\ b\in  A}}  \bar{\vec{x}}_{(q,b)}}\cdot\sum\limits_{\substack{v\in Q\\ a\in A}}  \bar{\vec{x}}_{(v,a)}\cdot  c(v,a) = \sum\limits_{\substack{v\in Q\\ a\in A}} \vec{w}_{(v,a)}\cdot c(v,a) =r^*.\end{split}\]</div>
<p>It remains to take a step from the left-hand side of <code class="xref eq docutils literal notranslate"><span class="pre">5-eq:ergodic-use</span></code> towards the mean payoff. To this end, we construct a new Markov chain <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span> from <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> by splitting every edge <span class="math notranslate nohighlight">\((u,v)\)</span> with a new dummy vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> (i.e., <span class="math notranslate nohighlight">\(d_{u,v}\)</span> has one edge incoming from <span class="math notranslate nohighlight">\(u\)</span> with probability <span class="math notranslate nohighlight">\(P_{u,v}\)</span> and one edge outgoing to <span class="math notranslate nohighlight">\(v\)</span> with probability <span class="math notranslate nohighlight">\(1\)</span>). In <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span> we define a vector <span class="math notranslate nohighlight">\(\vec{h}'\)</span> s.t. for each vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> the vector <span class="math notranslate nohighlight">\( \vec{h}' \)</span> has the <span class="math notranslate nohighlight">\( d_{u,v} \)</span>-component equal to <span class="math notranslate nohighlight">\(c(u,v)\)</span>, while the components corresponding to the original vertices are zero. It is easy to check that <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span>  is strongly connected and that it has an invariant distribution <span class="math notranslate nohighlight">\(\vec{z}'\)</span> defined by <span class="math notranslate nohighlight">\(\vec{z}'_v= \vec{z}_v/2\)</span> for <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(\vec{z}'_{d_{u,v}}=\frac{ \vec{z}_u\cdot P_{u,v}}{2}\)</span> for <span class="math notranslate nohighlight">\((u,v)\)</span> an edge of <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span>.
Also, by easy induction, for each play <span class="math notranslate nohighlight">\(\pi\)</span> of length <span class="math notranslate nohighlight">\(n\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> it holds <span class="math notranslate nohighlight">\(\frac{1}{n}\sum_{i=0}^{n-1} c( \pi_i) = \frac{1}{n}\sum_{i=0}^{2n-1}\vec{h}'_{ \textrm{In}( \pi_i')}\)</span>, where <span class="math notranslate nohighlight">\(\pi'\)</span> is the unique play in <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span> obtained from <span class="math notranslate nohighlight">\(\pi\)</span> by splitting edges with appropriate dummy vertices. Hence,</p>
<div class="math notranslate nohighlight" id="equation-5-eq-mc-opt-limit">
<span class="eqno">(11)<a class="headerlink" href="#equation-5-eq-mc-opt-limit" title="Permalink to this equation">¶</a></span>\[\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1} c( \pi_i) = 2\cdot \lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}'_{ \textrm{In}( \pi_i')},
\]</div>
<p>provided that both limits exist. By the ergodic theorem  applied to <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span>, we have that the RHS  limit in <a class="reference internal" href="#equation-5-eq-mc-opt-limit">(11)</a> is defined with probability 1 and equal to</p>
<div class="math notranslate nohighlight">
\[\begin{split}\underbrace{\sum_{v\in Q}  \vec{z}'_v \cdot \vec{h}'_{v}}_{=0} + \sum_{u,v\in Q}  \vec{z}'_{d_{u,v}}\cdot \vec{h}'_{d_{u,v}} = \frac{1}{2}\sum_{u\in Q} \vec{z}_u\cdot\left( \sum_{v\in Q} P_{u,v}\cdot  c(u,v)\right)\\ =\frac{1}{2}\sum_{u\in Q}  \vec{z}_u\cdot \vec{h}_u=\frac{r^*}{2},\end{split}\]</div>
<p>the last equality being shown above. Plugging this into <a class="reference internal" href="#equation-5-eq-mc-opt-limit">(11)</a> yields that if a limit on the LHS (i.e., the mean payoff of a play) is well-defined with probability 1, then it is equal to <span class="math notranslate nohighlight">\(r^*\)</span> also with probability 1. But if there was a set <span class="math notranslate nohighlight">\(L\)</span> of positive probability in <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> with <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1} c( \pi_i)\)</span> undefined for each <span class="math notranslate nohighlight">\(\pi\in L\)</span>, by splitting the plays in <span class="math notranslate nohighlight">\(L\)</span> we would obtain a positive-probability set of plays in <span class="math notranslate nohighlight">\(\mathcal{M}_Q'\)</span> in which <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}'_{ \textrm{In}( \pi_i')}\)</span> is also undefined, a contradiction with the ergodic theorem.</p>
</div>
<p>So far, we have constructed an optimal strategy <span class="math notranslate nohighlight">\(\sigma_Q\)</span> but only on the part <span class="math notranslate nohighlight">\(Q\)</span> of the original MDP <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. To conclude the construction, we define a memoryless strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> as follows: we fix a memoryless deterministic strategy <span class="math notranslate nohighlight">\(\sigma_{=1}\)</span> that is winning, from each vertex of <span class="math notranslate nohighlight">\(\mathcal{M},\)</span> for the objective of almost-sure reaching of <span class="math notranslate nohighlight">\(Q\)</span> (such a strategy exists since <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> is strongly connected, see also <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 148</a>. Then we put <span class="math notranslate nohighlight">\(\sigma^*(v)=\sigma_{=1}(v)\)</span> if <span class="math notranslate nohighlight">\(v\not\in Q\)</span> and <span class="math notranslate nohighlight">\(\sigma^*(v)=\sigma_Q(v)\)</span> otherwise. Hence, starting in any vertex, <span class="math notranslate nohighlight">\(\sigma^*\)</span> eventually reaches <span class="math notranslate nohighlight">\(Q\)</span> with probability 1 and then it starts behaving as <span class="math notranslate nohighlight">\(\sigma_Q\)</span>. The optimality of such a strategy follows from the prefix independence of mean payoff, as argued in the next theorem.</p>
<div class="proof theorem admonition" id="5-thm:mp-valcomp">
<p class="admonition-title"><span class="caption-number">Theorem 176 </span> (NEEDS TITLE 5-thm:mp-valcomp)</p>
<div class="theorem-content section" id="proof-content">
<p>For any sequence of numbers <span class="math notranslate nohighlight">\(c_0,c_1,\dots\)</span> and any <span class="math notranslate nohighlight">\(k\in \mathbb{N}\)</span> it holds <span class="math notranslate nohighlight">\(\liminf_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}c_i = \liminf_{m\rightarrow \infty}\frac{1}{m}\sum_{i=0}^{m-1}c_{k+i}\)</span>. As a consequence,
for every vertex <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> it holds <span class="math notranslate nohighlight">\(\mathbb{P}^{\sigma_Q}_{ \mathcal{M}_Q,v}(  \mathtt{MeanPayoff}^{\;-}=r^*)=1,\)</span> where <span class="math notranslate nohighlight">\(r^*\)</span> is the optimal value of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>. Hence, <span class="math notranslate nohighlight">\(\mathbb{E}^{\sigma^*}_v[  \mathtt{MeanPayoff}^{\;-}]= r^*\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\liminf_{n\rightarrow \infty}\frac{c_0 + \cdots c_{n-1}}{n} &amp;= \liminf_{n\rightarrow \infty}\left(\underbrace{\frac{k}{n}}_{\mathrlap{\text{vanishes for } n\rightarrow \infty}}\cdot\frac{c_0 + \cdots + c_{k-1}}{k} + \underbrace{\frac{n-k}{n}}_{\mathrlap{\rightarrow 1 \text{ for } n\rightarrow \infty}}\cdot\frac{c_k+\cdot+c_{n-1}}{n-k} \right)\\
&amp;=\liminf_{m\rightarrow\infty} \frac{c_k+\dots+c_{k+m-1}}{m}.\end{split}\]</div>
<p>A similar argument holds for <span class="math notranslate nohighlight">\(\limsup.\)</span></p>
<p>With probability 1, a play has an infinite suffix consisting of plays from <span class="math notranslate nohighlight">\(\mathcal{M}_Q^{\sigma}\)</span>, and thus also <span class="math notranslate nohighlight">\(\mathtt{MeanPayoff}^{\;-}\)</span> and <span class="math notranslate nohighlight">\(\mathtt{MeanPayoff}^{\;+}\)</span> determined by this suffix. By <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">5-cor:mp-scc-optimality</span></code>, these quantities are equal to <span class="math notranslate nohighlight">\(r^*\)</span> with probability 1.</p>
</div>
<p>The following theorem summarizes the computational aspects.</p>
<div class="proof theorem admonition" id="5-thm:mp-rand-opt-main">
<p class="admonition-title"><span class="caption-number">Theorem 177 </span> (NEEDS TITLE 5-thm:mp-rand-opt-main)</p>
<div class="theorem-content section" id="proof-content">
<p>In a strongly connected mean-payoff MDP, one can compute, in polynomial time, a memoryless randomized strategy which is optimal from every vertex, as well as the (single) optimal value of every vertex.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We obtain, in polynomial time, an optimal solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>, with the optimal objective value being the optimal value of every vertex (<a class="reference internal" href="#5-thm:mp-valcomp">Theorem 176</a>). We then use this optimal solution <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> to construct the strategy <span class="math notranslate nohighlight">\(\sigma\)</span> and the  Markov chain <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}^{\sigma}\)</span>. From this chain we extract a strongly connected subset of vertices <span class="math notranslate nohighlight">\(Q\)</span> (in polynomial time, by a simple graph reachability analysis). With the subset in hand, we can construct strategies <span class="math notranslate nohighlight">\(\sigma_Q\)</span> and <span class="math notranslate nohighlight">\(\sigma_{=1}\)</span>, all polynomial-time computations (see <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 148</a>). These two strategies are then combined to produce the optimal strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span>.</p>
</div>
<div class="section" id="deterministic-optimality-in-strongly-connected-mdps">
<h2>Deterministic optimality in strongly connected MDPs<a class="headerlink" href="#deterministic-optimality-in-strongly-connected-mdps" title="Permalink to this headline">¶</a></h2>
<p>It remains to prove that we can actually compute a memoryless <strong>deterministic</strong> strategy that is optimal in every vertex. Looking back at the construction that resulted in <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 177</a>, we see that the optimal strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> might be randomized because the computed optimal solution <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> can contain two components <span class="math notranslate nohighlight">\((v,a)\)</span>, <span class="math notranslate nohighlight">\((v,b)\)</span> with <span class="math notranslate nohighlight">\(a\neq b\)</span> and both <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{(v,a)}\)</span> and <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{(v,b)}\)</span> being positive. To prove memoryless deterministic optimality, we will show that there is always an optimal solution which yields a deterministic strategy, and that such a solution can be obtained in polynomial time.</p>
<p>The previous section implicitly defined two mappings: First, a mapping <span class="math notranslate nohighlight">\(\Psi\)</span>, which maps every solution <span class="math notranslate nohighlight">\( \vec{x} \)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> to a memoryless strategy in some sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>, by putting <span class="math notranslate nohighlight">\(\Psi(\vec{x}) = \sigma\)</span> where <span class="math notranslate nohighlight">\(\sigma(a\mid v) = \vec{x}_{(v,a)}/\sum_{b\in  A}\vec{x}_{(v,b)}\)</span>. Second, mapping <span class="math notranslate nohighlight">\(\Xi\)</span>, which maps each memoryless strategy <span class="math notranslate nohighlight">\(\sigma\)</span> that induces a strongly connected Markov chain to a solution <span class="math notranslate nohighlight">\(\Xi(\sigma)\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> such that <span class="math notranslate nohighlight">\(\Xi(\sigma)_{(v,a)}= \vec{z}_v\cdot \sigma(a\mid v)\)</span>, where <span class="math notranslate nohighlight">\(\vec{z}\)</span> is the unique invariant distribution of the chain induced by <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<div class="proof lemma admonition" id="5-lem:sol-strat-correspondence">
<p class="admonition-title"><span class="caption-number">Lemma 178 </span> (NEEDS TITLE 5-lem:sol-strat-correspondence)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be the set containing exactly those solutions <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> for which the strategy  <span class="math notranslate nohighlight">\(\Psi(\vec{x})\)</span> induces a strongly connected Markov chain. Then the mappings <span class="math notranslate nohighlight">\(\Psi\)</span> and <span class="math notranslate nohighlight">\(\Xi\)</span> are bijections between <span class="math notranslate nohighlight">\(X\)</span> and the set of all memoryless strategies in some sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> that induce a strongly connected Markov chain.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>A straightforward computation shows that <span class="math notranslate nohighlight">\(\Xi\circ\Psi\)</span> and <span class="math notranslate nohighlight">\(\Psi\circ\Xi\)</span> are identity functions on the respective sets.</p>
</div>
<div class="proof definition admonition" id="5-def:pure-lp">
<p class="admonition-title"><span class="caption-number">Definition 179 </span> (NEEDS TITLE 5-def:pure-lp)</p>
<div class="definition-content section" id="proof-content">
<p>A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>is <strong>pure</strong> if for every vertex <span class="math notranslate nohighlight">\(v\)</span> there is at most one action <span class="math notranslate nohighlight">\(a\)</span> such that <span class="math notranslate nohighlight">\(\vec{x}_{(v,a)}&gt;0\)</span>.</p>
</div>
</div><p>The following lemma follows from the way in which strategies <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\sigma^*\)</span> were constructed in the previous sub-section.</p>
<div class="proof lemma admonition" id="5-lem:pure-lpsol">
<p class="admonition-title"><span class="caption-number">Lemma 180 </span> (NEEDS TITLE 5-lem:pure-lpsol)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> and denote <span class="math notranslate nohighlight">\( S = \{v \in  V\mid \exists a \text{ s.t. } \bar{\vec{x}}_{(v,a)}&gt;0\} \)</span>. Then the strategy <span class="math notranslate nohighlight">\(\sigma=\Psi( \bar{\vec{x}})\)</span> is an MD strategy in <span class="math notranslate nohighlight">\(\mathcal{M}_{ S}\)</span>. Hence, in such a case, the strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> constructed from <span class="math notranslate nohighlight">\( \sigma \)</span> as in <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 177</a> is an optimal MD strategy in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>.</p>
</div>
</div><p>It remains to show how to find a pure optimal solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>. To this end we exploit some fundamental properties of linear programs.</p>
<p>A linear program is in the <strong>standard</strong> (or equational) form if its set of constraints can be expressed as <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span>, <span class="math notranslate nohighlight">\(\vec{x}\geq 0\)</span>, where <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a vector of variables, <span class="math notranslate nohighlight">\(\vec{b}\)</span> is a non-negative vector, and <span class="math notranslate nohighlight">\(A\)</span> is a matrix of an appropriate dimension. In this notation, all the vectors are column vectors, i.e. <span class="math notranslate nohighlight">\(A\)</span> has one column per each variable. Note that <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> is a program in the standard form. A feasible solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of such a program is <strong>basic</strong> if the columns of <span class="math notranslate nohighlight">\(A\)</span> corresponding to variables whose value is positive in <span class="math notranslate nohighlight">\(\vec{x}\)</span> form a linearly independent set of vectors. Since the maximal number of linearly independent columns equals the maximal number of linearly independent rows (a number called a <strong>rank</strong> of <span class="math notranslate nohighlight">\(A\)</span>), we know that each basic feasible solution has at most as many positive entries as there are rows of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>The next two lemmas prove some fundamental properties of basic feasible solutions.</p>
<div class="proof lemma admonition" id="5-lem:basic-cond-unique">
<p class="admonition-title"><span class="caption-number">Lemma 181 </span> (NEEDS TITLE 5-lem:basic-cond-unique)</p>
<div class="lemma-content section" id="proof-content">
<p>Assume that a linear program in a standard form has two basic feasible solutions <span class="math notranslate nohighlight">\(\vec{x},\vec{x}'\)</span> such that both solutions have the same set of non-zero components, and the cardinality of this set equals the number of equality constraints in the program. Then <span class="math notranslate nohighlight">\(\vec{x}=\vec{x}'\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Write <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span> the equational constraints of the LP.
If <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic feasible solution, then it solves the equation <span class="math notranslate nohighlight">\(A_{N} \cdot \vec{x}_N = \vec{b}\)</span>, where <span class="math notranslate nohighlight">\(A_N\)</span> (<span class="math notranslate nohighlight">\(  N\)</span> stands for non-zero) is obtained from <span class="math notranslate nohighlight">\(A\)</span> by removing all columns corresponding to zero components of <span class="math notranslate nohighlight">\(\vec{x}\)</span>, and   <span class="math notranslate nohighlight">\(\vec{x}_N\)</span> is obtained from <span class="math notranslate nohighlight">\(\vec{x}\)</span> by removing all zero components.</p>
<p>Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> has as many non-zero components as there are rows of <span class="math notranslate nohighlight">\(A\)</span>, it follows that <span class="math notranslate nohighlight">\(A_N\)</span> is a square matrix. Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic solution, <span class="math notranslate nohighlight">\(A_N\)</span> is regular (its columns are linearly independent) and <span class="math notranslate nohighlight">\(\vec{x}=A_{N}^{-1}\cdot \vec{b}\)</span> is uniquely determined by <span class="math notranslate nohighlight">\(A_N\)</span>. Repeating the same argument for <span class="math notranslate nohighlight">\(\vec{x}'\)</span> yields <span class="math notranslate nohighlight">\(\vec{x}'=A_{N}^{-1}\cdot \vec{b}= \vec{x}\)</span>.</p>
</div>
<div class="proof lemma admonition" id="5-lem:basic-sol">
<p class="admonition-title"><span class="caption-number">Lemma 182 </span> (NEEDS TITLE 5-lem:basic-sol)</p>
<div class="lemma-content section" id="proof-content">
<p>If a linear program in a standard form has an optimal solution, then it has also a basic optimal solution. Moreover, a basic optimal solution can be found in polynomial time.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The existence of a basic optimal solution is a well-known linear programming fact, e.g. the standard simplex algorithm works by traversing the set of basic feasible solutions until it finds an optimal one <span id="id4">[<a class="reference internal" href="references.html#id120"><span>Matouvsek07</span></a>]</span>. For computing an optimal basic solution, we can use one of the polynomial-time interior-point methods for linear programming, such as the path-following method <span id="id5">[<a class="reference internal" href="references.html#id117"><span>Kar84</span></a>,<a class="reference internal" href="references.html#id114"><span>Gon92</span></a>]</span>. While these methods work by traversing the interior of the polyhedron of feasible solutions, they converge, in polynomial time, to a point that is closer to the optimal basic solution than to all the other basic solutions. By a process called <strong>purification,</strong> such a point can be then converted to the closest basic solution, i.e. to the optimal one <span id="id6">[<a class="reference internal" href="references.html#id114"><span>Gon92</span></a>]</span>.</p>
</div>
<div class="proof theorem admonition" id="5-thm:lpmp-basic-dim">
<p class="admonition-title"><span class="caption-number">Theorem 183 </span> (NEEDS TITLE 5-thm:lpmp-basic-dim)</p>
<div class="theorem-content section" id="proof-content">
<p>One can find, in polynomial time, an optimal deterministic strategy in a given strongly connected  mean-payoff MDP.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>First, we use <a class="reference internal" href="#5-lem:basic-sol">Lemma 182</a> to find a basic optimal solution <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>.
We check if it is pure. If yes, we are done. Otherwise,</p>
<p>there is <span class="math notranslate nohighlight">\(v\in  V\)</span> and two distinct actions <span class="math notranslate nohighlight">\(a,b\)</span> such that <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{(v,a)}&gt;0\)</span> and <span class="math notranslate nohighlight">\(\bar{\vec{x}}_{(v,b)}&gt;0.\)</span> Let <span class="math notranslate nohighlight">\( S = \{v \in  V\mid \exists a \text{ s.t. } \bar{\vec{x}}_{(v,a)}&gt;0\} \)</span>. By <a class="reference internal" href="#5-cor:mp-scc-extraction">Corollary 175</a>, we can partition <span class="math notranslate nohighlight">\(S\)</span> into several subsets, each of which induces a strongly connected sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. Let <span class="math notranslate nohighlight">\(Q\)</span> be a class of this partition containing <span class="math notranslate nohighlight">\(v\)</span>. We have that the optimal mean-payoff value of every vertex in <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> is the same as in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. This is because,
as in the beginning of the proof of <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">5-cor:mp-scc-optimality</span></code>, we can transform <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> into another optimal solution of the same value as <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> which has non-zero entries only for components indexed by <span class="math notranslate nohighlight">\((q,a)\)</span> with <span class="math notranslate nohighlight">\(q\in Q\)</span>. All these computations can be easily implemented in polynomial time.</p>
<p>We argue that <span class="math notranslate nohighlight">\(Q\)</span> is a strict subset of <span class="math notranslate nohighlight">\(V\)</span>. Indeed, assume that <span class="math notranslate nohighlight">\(Q= V\)</span>. Then <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> induces a randomized strategy <span class="math notranslate nohighlight">\(\sigma\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. Moreover, since <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span> is a basic solution, it has at most <span class="math notranslate nohighlight">\(| V|+1\)</span> positive entries, and since it is non-pure, it must have exactly <span class="math notranslate nohighlight">\(n+1\)</span> positive entries, i.e. <a class="reference internal" href="#5-lem:basic-cond-unique">Lemma 181</a> is applicable to <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span>, since <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> has exactly <span class="math notranslate nohighlight">\(| V|+1\)</span> constraints. Now we define a new strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> in <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> by slightly changing the behaviour in <span class="math notranslate nohighlight">\(v\)</span>. To this end, choose some <span class="math notranslate nohighlight">\(\varepsilon&gt;0\)</span> and put <span class="math notranslate nohighlight">\(\sigma'(a\mid v)=\sigma(a\mid v)- \varepsilon\)</span> and <span class="math notranslate nohighlight">\(\sigma'(b\mid v)=\sigma(b\mid v)+ \varepsilon\)</span>; we choose <span class="math notranslate nohighlight">\(\varepsilon\)</span> small enough so that both quantities are still non-zero. The chain <span class="math notranslate nohighlight">\(\mathcal{M}^{\sigma'}\)</span> is still strongly connected. Now let <span class="math notranslate nohighlight">\(\vec{x}' = \Xi(\sigma')\)</span>. Then <span class="math notranslate nohighlight">\(\vec{x}'\)</span> is a solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span> which is still basic, with a set of non-zero components being the same as in <span class="math notranslate nohighlight">\(\bar{\vec{x}}\)</span>. At the same time, <span class="math notranslate nohighlight">\(\vec{x}'\neq  \bar{\vec{x}}\)</span>, since <span class="math notranslate nohighlight">\(\sigma\neq {\sigma'}\)</span> and <span class="math notranslate nohighlight">\(\Xi\)</span> is a bijection (<a class="reference internal" href="#5-lem:sol-strat-correspondence">Lemma 178</a>). But this is a contradiction with <a class="reference internal" href="#5-lem:basic-cond-unique">Lemma 181</a>.</p>
<p>Hence, <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> is a strict sub-MDP of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> in which the value of every vertex is the same as in the original MDP. We can perform a recursive call of the aforementioned computation on <span class="math notranslate nohighlight">\(\mathcal{M}_Q\)</span> (compute basic optimal solution of <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathit{mp}}\)</span>, check purity, possibly extract and recurse on a sub-MDP).
The depth of recursion is bounded by <span class="math notranslate nohighlight">\(| V|\)</span>, so the running time is polynomial. Since each sub-MDP obtained during the recursion is non-empty, and the size of the MDPs decreases, the recursion must eventually terminate with a basic optimal solution (in some sub-MDP <span class="math notranslate nohighlight">\(\mathcal{M}'\)</span>) that is pure. This yields a memoryless deterministic strategy in <span class="math notranslate nohighlight">\(\mathcal{M}'\)</span> whose value is equal to the optimal value in <span class="math notranslate nohighlight">\(\mathcal{M}.\)</span> Such a strategy can be extended to whole <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> by solving almost sure reachability to <span class="math notranslate nohighlight">\(  \mathcal{M}' \)</span>, as described in the previous sub-section.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5_MDP"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="mean_payoff_properties.html" title="previous page">Mean-payoff in MDPs: General properties and linear programming</a>
    <a class='right-next' id="next-link" href="end_components.html" title="next page">End components</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>