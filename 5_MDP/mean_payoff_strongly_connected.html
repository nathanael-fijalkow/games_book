
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mean-payoff optimality in strongly connected MDPs &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="End components" href="end_components.html" />
    <link rel="prev" title="Mean-payoff in MDPs: General properties and linear programming" href="mean_payoff_properties.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     Büchi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../4_Payoffs/index.html">
   Games with Payoffs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/discounted_payoff.html">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_Payoffs/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Markov Decision Processes
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html#min-left-1-x-3-1-y-3-1-x-9-1-y-right-right-frac-1-4-max-x-y-in-0-1-2-min-left-4-6y-6-2x-6y-br-right">
     \min\left(
{(1-x) +  3 (1-y)},
{3(1-x) - 9(1-y)}
\right)\right)\
=&amp;
\frac{1}{4}\max_{(x,y)\in[0,1]^2}
\min\left(
4 - 6y,
-6 -2x + 6y
     <br/>
     \right)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deterministic-optimality-in-strongly-connected-mdps">
   Deterministic optimality in strongly connected MDPs
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="mean-payoff-optimality-in-strongly-connected-mdps">
<span id="sec-mean-payoff-strongly-connected"></span><h1>Mean-payoff optimality in strongly connected MDPs<a class="headerlink" href="#mean-payoff-optimality-in-strongly-connected-mdps" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\newcommand{\expv}{\mathbb{E}} \newcommand{\discProbDist}{f} \newcommand{\sampleSpace}{S} \newcommand{\sigmaAlg}{\mathcal{F}} \newcommand{\probm}{\mathbb{P}} \newcommand{\rvar}{X} \\\newcommand{\actions}{A} \newcommand{\colouring}{c} \newcommand{\probTranFunc}{\Delta} \newcommand{\edges}{E} \newcommand{\colours}{C} \newcommand{\mdp}{\mathcal{M}} \newcommand{\vinit}{v_0} \newcommand{\cylProb}{p} \newcommand{\emptyPlay}{\epsilon} \newcommand{\objective}{\Omega} \newcommand{\genColour}{\textsc{c}} \newcommand{\quantObj}{f} \newcommand{\quantObjExt}{\bar{\quantObj}} \newcommand{\indicator}[1]{\mathbf{1}_{#1}} \newcommand{\eps}{\varepsilon} \newcommand{\maxc}{\max_{\colouring}} 
\newcommand{\winPos}{W_{&gt;0}}
\newcommand{\winAS}{W_{=1}}
\newcommand{\cylinder}{\mathit{Cyl}}
\newcommand{\PrePos}{\text{Pre}_{&gt;0}}
\newcommand{\PreAS}{\text{Pre}_{=1}}
\newcommand{\PreOPPos}{\mathcal{P}_{&gt;0}}
\newcommand{\OPAS}{\mathcal{P}_{=1}}
\newcommand{\safeOP}{\mathit{Safe_{=1}}}
\newcommand{\closed}{\mathit{Cl}}\\\newcommand{\reachOP}{\mathcal{V}}
\newcommand{\discOP}{\mathcal{D}}
\newcommand{\valsigma}{\vec{x}^{\sigma}}
\newcommand{\lp}{\mathcal{L}}
\newcommand{\lpdisc}{\lp_{\mathit{disc}}}
\newcommand{\lpreach}{\lp_{\mathit{reach}}}
\newcommand{\lpmp}{\lp_{\mathit{mp}}}
\newcommand{\lpsol}[1]{\bar{\vec{#1}}}
\newcommand{\lpsolg}[1]{\bar{#1}}
\newcommand{\lpmpdual}{\lpmp^{\mathit{dual}}}
\newcommand{\actevent}[3]{\actions^{#1}_{#2,#3}} 
\newcommand{\MeanPayoffSup}{\MeanPayoff^{\;+}}
\newcommand{\MeanPayoffInf}{\MeanPayoff^{\;-}}
\newcommand{\mcprob}{P}
\newcommand{\invdist}{\vec{z}}
\newcommand{\hittime}{T}
\newcommand{\playPay}{\textsf{p-Payoff}}
\newcommand{\stepPay}{\textsf{s-Payoff}}
\newcommand{\Pay}{\textsf{Payoff}}
\newcommand{\mec}{M}
\newcommand{\OPS}{\mathcal{S}_{=1}}
\newcommand{\smallmp}{\mathit{mp}}
\newcommand{\vgood}{v_{\mathit{good}}}
\newcommand{\vbad}{v_{\mathit{bad}}}
\newcommand{\finact}{fin}
\newcommand{\mecs}{\mathit{MEC}}
\newcommand{\slice}[2]{#1_{#2-}}
\newcommand{\ReachOp}{\mathcal{R}}
\newcommand{\dPayoffStep}[1]{\DiscountedPayoff^{\;(#1)}}
\newcommand{\solvset}{S}
\newcommand{\Eve}{\textrm{Eve}}
\newcommand{\Adam}{\textrm{Adam}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Zinfty}{\Z \cup \set{\pm \infty}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rinfty}{\R \cup \set{\pm \infty}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Qinfty}{\Q \cup \set{\pm \infty}}
\newcommand{\argmax}{\textrm{argmax}}
\newcommand{\argmin}{\textrm{argmin}}
\newcommand{\Op}{\mathbb{O}}
\newcommand{\Prob}{\mathbb{P}} \newcommand{\dist}{\mathcal{D}} \newcommand{\Dist}{\dist} \newcommand{\supp}{\textrm{supp}} 
\newcommand{\game}{\mathcal{G}} \renewcommand{\Game}{\game} \newcommand{\arena}{\mathcal{A}} \newcommand{\Arena}{\arena} 
\newcommand{\col}{\textsf{col}} \newcommand{\Col}{\col} 
\newcommand{\mEve}{\mathrm{Eve}}
\newcommand{\mAdam}{\mathrm{Adam}}
\newcommand{\mRandom}{\mathrm{Random}}
\newcommand{\vertices}{V} \newcommand{\VE}{V_\mEve} \newcommand{\VA}{V_\mAdam} \newcommand{\VR}{V_\mRandom} 
\newcommand{\ing}{\textrm{In}}
\newcommand{\Ing}{\ing}
\newcommand{\out}{\textrm{Out}}
\newcommand{\Out}{\out}
\newcommand{\dest}{\Delta} 
\newcommand{\WE}{W_\mEve} \newcommand{\WA}{W_\mAdam} 
\newcommand{\Paths}{\textrm{Paths}} \newcommand{\play}{\pi} \newcommand{\first}{\textrm{first}} \newcommand{\last}{\textrm{last}} 
\newcommand{\mem}{\mathcal{M}} \newcommand{\Mem}{\mem} 
\newcommand{\Pre}{\textrm{Pre}} \newcommand{\PreE}{\textrm{Pre}_\mEve} \newcommand{\PreA}{\textrm{Pre}_\mAdam} \newcommand{\Attr}{\textrm{Attr}} \newcommand{\AttrE}{\textrm{Attr}_\mEve} \newcommand{\AttrA}{\textrm{Attr}_\mAdam} \newcommand{\rank}{\textrm{rank}}
\newcommand{\Win}{\textrm{Win}} 
\newcommand{\Lose}{\textrm{Lose}} 
\newcommand{\Value}{\textrm{val}} 
\newcommand{\ValueE}{\textrm{val}_\mEve} 
\newcommand{\ValueA}{\textrm{val}_\mAdam}
\newcommand{\val}{\Value} 
\newcommand{\Automaton}{\mathbf{A}} 
\newcommand{\Safe}{\mathtt{Safe}}
\newcommand{\Reach}{\mathtt{Reach}} 
\newcommand{\Buchi}{\mathtt{Buchi}} 
\newcommand{\CoBuchi}{\mathtt{CoBuchi}} 
\newcommand{\Parity}{\mathtt{Parity}} 
\newcommand{\Muller}{\mathtt{Muller}} 
\newcommand{\Rabin}{\mathtt{Rabin}} 
\newcommand{\Streett}{\mathtt{Streett}} 
\newcommand{\MeanPayoff}{\mathtt{MeanPayoff}} 
\newcommand{\DiscountedPayoff}{\mathtt{DiscountedPayoff}}
\newcommand{\Energy}{\mathtt{Energy}}
\newcommand{\TotalPayoff}{\mathtt{TotalPayoff}}
\newcommand{\ShortestPath}{\mathtt{ShortestPath}}
\newcommand{\Sup}{\mathtt{Sup}}
\newcommand{\Inf}{\mathtt{Inf}}
\newcommand{\LimSup}{\mathtt{LimSup}}
\newcommand{\LimInf}{\mathtt{LimInf}}
\newcommand{\NL}{\textrm{NL}}
\newcommand{\PTIME}{\textrm{PTIME}}
\newcommand{\NP}{\textrm{NP}}
\newcommand{\UP}{\textrm{UP}}
\newcommand{\coNP}{\textrm{coNP}}
\newcommand{\coUP}{\textrm{coUP}}
\newcommand{\PSPACE}{\textrm{PSPACE}}\end{aligned}\end{align} \]</div>
<p>As shown in the previous section, the optimal solution of any of the programs <span class="math notranslate nohighlight">\(\lpmp\)</span>, <span class="math notranslate nohighlight">\(\lpmpdual\)</span> gives us an upper bound on the optimal value. In this sub-section we show that in strongly connected MDPs: a) a value of every vertex is the same; b) from a solution of <span class="math notranslate nohighlight">\(\lpmp\)</span> one can extract a memoryless deterministic strategy <span class="math notranslate nohighlight">\(\sigma\)</span> whose expected mean-payoff is well defined (i.e., the preconditions of  <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">5-lem:limit-defined</span></code> are satisfied)) and equal to the objective value of the solution. Moreover, if the solution in question is optimal, then <span class="math notranslate nohighlight">\( \sigma \)</span> is optimal for both <span class="math notranslate nohighlight">\(\playPay\)</span>- and <span class="math notranslate nohighlight">\(\stepPay\)</span>-semantics.</p>
<div class="proof definition admonition" id="5-def:scc-mdp">
<p class="admonition-title"><span class="caption-number">Definition 162 </span> (NEEDS TITLE 5-def:scc-mdp)</p>
<div class="definition-content section" id="proof-content">
<p>An MDP is <strong>strongly connected</strong> if for each pair of vertices <span class="math notranslate nohighlight">\(u,v\)</span> there exists a strategy which, when starting in <span class="math notranslate nohighlight">\(u\)</span>, reaches <span class="math notranslate nohighlight">\(v\)</span> with a positive probability.</p>
</div>
</div><p>For the rest of this section we fix an optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span>. We denote by <span class="math notranslate nohighlight">\(\solvset\)</span> the set of all vertices for which there exists action <span class="math notranslate nohighlight">\(a\)</span> s.t. <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}&gt;0.\)</span> From the shape of <span class="math notranslate nohighlight">\(\lpmp\)</span> it follows that <span class="math notranslate nohighlight">\(\solvset\)</span> is non-empty and closed, and hence we can consider a sub-MDP <span class="math notranslate nohighlight">\(\mdp_{\solvset}\)</span> induced by <span class="math notranslate nohighlight">\(\solvset\)</span>. In <span class="math notranslate nohighlight">\(\mdp_{\solvset}\)</span> we then define a memoryless randomized strategy <span class="math notranslate nohighlight">\(\sigma\)</span> by putting
$<span class="math notranslate nohighlight">\(
\sigma(a\mid v)=\frac{\lpsol{x}_{(v,a)}}{\sum_{b\in \actions}\lpsol{x}_{(v,b)}}.
\)</span>$</p>
<p>Fixing a strategy <span class="math notranslate nohighlight">\(\sigma\)</span> yields a <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(\mdp_\solvset^{\sigma}\)</span>. Markov chain can be viewed as an MDP with a single action (and hence, with no non-determinism). <span class="math notranslate nohighlight">\(\mdp_{\solvset}^\sigma\)</span> in particular can be viewed an MDP with the same vertices, edges, and colouring as <span class="math notranslate nohighlight">\(\mdp_\solvset\)</span>, but with a single action (as non-determinism was already resolved by <span class="math notranslate nohighlight">\(\sigma\)</span>). The probability of transitioning from a vertex <span class="math notranslate nohighlight">\(u\)</span> to a vertex <span class="math notranslate nohighlight">\(v\)</span> in a Markov chain is denoted by <span class="math notranslate nohighlight">\(\mcprob_{u,v}\)</span>. In <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span> we have <span class="math notranslate nohighlight">\(\mcprob_{u,v}=\sum_{a\in \actions} \probTranFunc(v\mid u,a)\cdot\sigma(a\mid u)\)</span>, the right-hand side being computed in the original MDP <span class="math notranslate nohighlight">\(\mdp\)</span>. Both <span class="math notranslate nohighlight">\(\mdp_\solvset\)</span> and <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span> have the same sets of plays and for each initial vertex, the probability measure induced by <span class="math notranslate nohighlight">\(\sigma\)</span> in <span class="math notranslate nohighlight">\(\mdp\)</span> equals the probability measure arising (under the unique policy) in <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>. Hence, to prove anything about <span class="math notranslate nohighlight">\(\sigma\)</span> it suffices to analyse <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>.</p>
<blockquote>
<div><p><strong>A refresher on Markov chains.</strong></p>
</div></blockquote>
<p>We review some fundamental notions of Markov chain theory <span id="id1">[<a class="reference internal" href="references.html#id120"><span>Nor98</span></a>]</span>. A Markov chain that is strongly connected is called <strong>irreducible</strong>. The one-step transition probabilities in a Markov chain can be arranged into a square matrix <span class="math notranslate nohighlight">\(\mcprob\)</span>, which has one row and one column for each vertex. The cell in the row corresponding to a vertex <span class="math notranslate nohighlight">\(u\)</span> and in the column corresponding to a vertex <span class="math notranslate nohighlight">\(v\)</span> bears the value <span class="math notranslate nohighlight">\(\mcprob_{u,v}\)</span> defined above. An easy induction shows that the matrix <span class="math notranslate nohighlight">\(\mcprob^k\)</span> contains <span class="math notranslate nohighlight">\(k\)</span>-step transition probabilities. That is, the probability of being in <span class="math notranslate nohighlight">\(v\)</span> after <span class="math notranslate nohighlight">\(k\)</span> steps from vertex <span class="math notranslate nohighlight">\(u\)</span> is equal to the <span class="math notranslate nohighlight">\((u,v)\)</span>-cell of <span class="math notranslate nohighlight">\(\mcprob^k\)</span>, which we denote by <span class="math notranslate nohighlight">\(\mcprob^{(k)}_{u,v}\)</span>.</p>
<p>A vertex <span class="math notranslate nohighlight">\(u\)</span> of a Markov chain is <strong>recurrent</strong> if, when starting from <span class="math notranslate nohighlight">\(u\)</span>, it is revisited infinitely often with probability <span class="math notranslate nohighlight">\(1\)</span>. On the other hand, if the probability that <span class="math notranslate nohighlight">\(u\)</span> is re-visited only finitely often is one, then the vertex is <strong>transient</strong>. It is known~\cite[Theorem 1.5.3]{Norris:1998} that each vertex of a finite Markov chain is either recurrent or transient, and that these two properties can be equivalently characterized as follows: vertex <span class="math notranslate nohighlight">\(u\)</span> is recurrent if and only if  <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty}\mcprob^{(k)}_{u,u}=\infty\)</span>, otherwise it is transient.</p>
<p>An <strong>invariant distribution</strong> in a Markov chain with a vertex set <span class="math notranslate nohighlight">\(\vertices\)</span> is a <span class="math notranslate nohighlight">\(|\vertices|\)</span>-dimensional non-negative row vector <span class="math notranslate nohighlight">\(\invdist\)</span> which adds up to <span class="math notranslate nohighlight">\(1\)</span> and satisfies <span class="math notranslate nohighlight">\( \invdist\cdot \mcprob = \invdist\)</span>.</p>
<p>The following lemma holds for arbitrary finite Markov chains.</p>
<div class="proof lemma admonition" id="lemma-1">
<p class="admonition-title"><span class="caption-number">Lemma 163 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>\label{5-lem:MC-inv-rec}
Let <span class="math notranslate nohighlight">\(\invdist\)</span> be an invariant distribution and <span class="math notranslate nohighlight">\(v\)</span> a vertex such that <span class="math notranslate nohighlight">\(\invdist_v &gt; 0\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is recurrent.</p>
<p>:label:
\label{5-lem:MC-inv-rec}
Let <span class="math notranslate nohighlight">\(\invdist\)</span> be an invariant distribution and <span class="math notranslate nohighlight">\(v\)</span> a vertex such that <span class="math notranslate nohighlight">\(\invdist_v &gt; 0\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is recurrent.</p>
<p>\label{5-lem:MC-inv-rec}
Let <span class="math notranslate nohighlight">\(\invdist\)</span> be an invariant distribution and <span class="math notranslate nohighlight">\(v\)</span> a vertex such that <span class="math notranslate nohighlight">\(\invdist_v &gt; 0\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(n\)</span> be the number of vertices in the chain and <span class="math notranslate nohighlight">\(p_{\min}\)</span> the minimum non-zero entry of <span class="math notranslate nohighlight">\(\mcprob\)</span>.
Assume, for the sake of contradiction, that <span class="math notranslate nohighlight">\(v\)</span> is transient. We show that in such a case, for each vertex <span class="math notranslate nohighlight">\(u\)</span> it holds <span class="math notranslate nohighlight">\(\lim_{k\rightarrow\infty} \mcprob^{(k)}_{u,v} = 0\)</span>. For <span class="math notranslate nohighlight">\(u=v\)</span> this is immediate, since the sum <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty}\mcprob^{(k)}_{v,v}\)</span> converges for  transient <span class="math notranslate nohighlight">\(v\)</span>. Otherwise, let <span class="math notranslate nohighlight">\(f_{u,v,i}\)</span> be the probability that a play starting in <span class="math notranslate nohighlight">\(u\)</span> visits <span class="math notranslate nohighlight">\(v\)</span> for the <strong>first time</strong> in exactly <span class="math notranslate nohighlight">\(i\)</span> steps. Then <span class="math notranslate nohighlight">\(\mcprob^{(k)}_{u,v}=\sum_{i=0}^k f_{u,v,i}\cdot \mcprob^{(k-i)}_{v,v}\)</span>. Now when starting in a vertex from which <span class="math notranslate nohighlight">\(v\)</span> is reachable with a positive probability, at least one of the following events happens with probability <span class="math notranslate nohighlight">\(\geq p_{\min}^n\)</span> in the first <span class="math notranslate nohighlight">\(n\)</span> steps: either we reach a vertex from which <span class="math notranslate nohighlight">\(v\)</span> is not reachable with positive probability, or we reach <span class="math notranslate nohighlight">\(v\)</span>. If neither of the events happens, we are, after <span class="math notranslate nohighlight">\(n\)</span> steps, still in a vertex from which <span class="math notranslate nohighlight">\(v\)</span> can be reached with a positive probability. In such a case, the argument can be inductively repeated (analogously to the proof of  <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 139</a>) to show that <span class="math notranslate nohighlight">\(f_{u,v,i}\leq (1-p_{\min}^n)^{\lfloor\frac{i}{n}\rfloor}\leq (1-p_{\min}^n)^{\frac{i-n}{n}}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\sum_{k=0}^{\infty}\mcprob^{(k)}_{v,v}\)</span> converges, for each <span class="math notranslate nohighlight">\(\eps&gt;0\)</span> there exists <span class="math notranslate nohighlight">\(j_\eps\)</span> such that <span class="math notranslate nohighlight">\(\sum_{i=j_{\eps}}^{\infty}\mcprob^{(i)}_{v,v} &lt; \frac{\eps}{2}\)</span>. Similarly, there exists <span class="math notranslate nohighlight">\(\ell_\eps\)</span> such that
$<span class="math notranslate nohighlight">\(
\sum_{i=\ell_{\eps}}^{\infty}{(1-p_{\min}^n)^{\frac{i-n}{n}}} = \frac{(1-p_{\min}^n)^{\frac{\ell_\eps}{n}}}{\left(1-(1-p_{\min}^n)^{\frac{1}{n}}\right)\cdot(1-p_{\min}^n)}&lt; \frac{\eps}{2},
\)</span><span class="math notranslate nohighlight">\(
 and hence \)</span>\sum_{i=\ell_{\eps}}^{\infty} f_{u,v,i}&lt; \frac{\eps}{2}.$</p>
<p>Now we put <span class="math notranslate nohighlight">\(m_{\eps}=\max\{j_\eps,\ell_\eps\}\)</span>. For any <span class="math notranslate nohighlight">\(k\geq 2m_{\eps}\)</span> we have <span class="math notranslate nohighlight">\(\mcprob^{(k)}_{u,v}=\sum_{i=0}^k f_{u,v,i}\cdot \mcprob^{(k-i)}_{v,v} \leq \sum_{i=m_{\eps}}^{k}f_{u,v,i} + \sum_{i=0}^{m_{\eps}}\mcprob^{(k-i)}_{v,v}\leq\sum_{i=m_{\eps}}^{k}f_{u,v,i} + \sum_{i=m_{\eps}}^{k}\mcprob^{(i)}_{v,v}&lt;\eps\)</span> (note that all the series involved are non-negative). This proves that <span class="math notranslate nohighlight">\(\mcprob^{(k)}_{u,v}\)</span> vanishes in the limit.</p>
<p>Finally, we derive the contradiction. Since <span class="math notranslate nohighlight">\(\invdist\)</span> satisfies <span class="math notranslate nohighlight">\(\invdist\cdot \mcprob = \invdist\)</span>, we also have <span class="math notranslate nohighlight">\(\invdist\cdot \mcprob^k = \invdist\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>. Hence, the <span class="math notranslate nohighlight">\(v\)</span>-component of <span class="math notranslate nohighlight">\(\invdist\cdot \mcprob^k\)</span> is equal to <span class="math notranslate nohighlight">\(\invdist_v&gt;0\)</span>. But as shown above, the <span class="math notranslate nohighlight">\(v\)</span>-column of <span class="math notranslate nohighlight">\(\mcprob^k\)</span> converges to the all-zero vector as <span class="math notranslate nohighlight">\(k\rightarrow \infty\)</span>, so also <span class="math notranslate nohighlight">\((\invdist\cdot \mcprob^k)_v\)</span> vanishes in the limit, a contradiction.</p>
</div>
<blockquote>
<div><p><strong>Towards the optimality of <span class="math notranslate nohighlight">\( \sigma \)</span>.</strong></p>
</div></blockquote>
<p>We now turn back to the chain <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>, where the memoryless strategy <span class="math notranslate nohighlight">\( \sigma \)</span> is obtained from the optimal solution of <span class="math notranslate nohighlight">\( \lpmp \)</span>. In general, <span class="math notranslate nohighlight">\( \mdp_{\solvset}^{\sigma} \)</span> does not have to be irreducible. Hence, we use the following lemma and its corollary to extract an irreducible sub-chain, to which we can apply known results of Markov chain theory.</p>
<div class="proof lemma admonition" id="5-lem:mc-rec">
<p class="admonition-title"><span class="caption-number">Lemma 164 </span> (NEEDS TITLE 5-lem:mc-rec)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bar{\invdist}\)</span> be a vector such that for each <span class="math notranslate nohighlight">\(v\in \solvset\)</span> it holds <span class="math notranslate nohighlight">\(\bar{\invdist}_v=\sum_{a\in \actions} \lpsol{x}_{v,a}\)</span>. Then <span class="math notranslate nohighlight">\(\bar{\invdist}\)</span> is an invariant distribution of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>. Consequently, all vertices of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span> are recurrent.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The first part follows directly from the fact that <span class="math notranslate nohighlight">\(\lpsol{x}_{v,a}\)</span> is a feasible solution of <span class="math notranslate nohighlight">\(\lpmp\)</span>. The second part follows from <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">5-lem:MC-inv-rec</span></code> and from the fact that <span class="math notranslate nohighlight">\(\bar\invdist\)</span> is positive (by the definition of <span class="math notranslate nohighlight">\(\solvset\)</span>).</p>
</div>
<div class="proof corollary admonition" id="5-cor:mp-scc-extraction">
<p class="admonition-title"><span class="caption-number">Corollary 165 </span> (NEEDS TITLE 5-cor:mp-scc-extraction)</p>
<div class="corollary-content section" id="proof-content">
<p>The set <span class="math notranslate nohighlight">\(\solvset\)</span> can be partitioned into subsets <span class="math notranslate nohighlight">\(\solvset_1,\solvset_2,\dots,\solvset_m\)</span> such that each <span class="math notranslate nohighlight">\(\solvset_i\)</span> induces a strongly connected sub-chain of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(v\in\solvset\)</span> be arbitrary and let <span class="math notranslate nohighlight">\(U_v\subseteq \solvset\)</span> be the set of all vertices reachable with positive probability from <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>. Then <span class="math notranslate nohighlight">\(v\)</span> is reachable (in <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>) with positive probability from each <span class="math notranslate nohighlight">\(u\in U_v\)</span>: otherwise, there would be a positive probability of never revisiting <span class="math notranslate nohighlight">\(v\)</span>, a contradiction with each vertex being recurrent in <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span> ( <a class="reference internal" href="#5-lem:mc-rec">Lemma 164</a>). Hence, <span class="math notranslate nohighlight">\(U_v\)</span> induces a strongly connected sub-MDP (or sub-chain) of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>. It is easy to show that if <span class="math notranslate nohighlight">\(U_v \neq U_w\)</span> for some <span class="math notranslate nohighlight">\(v\neq w \)</span>, then the two sets must be disjoint.</p>
</div>
<p>Hence, we can extract from <span class="math notranslate nohighlight">\(\solvset\)</span> a set <span class="math notranslate nohighlight">\(Q\)</span> inducing a strongly-connected sub-chain of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>, which we denote <span class="math notranslate nohighlight">\(\mdp^{\sigma}_{Q}\)</span>. The set <span class="math notranslate nohighlight">\(Q\)</span> also induces a strongly connected sub-MDP of <span class="math notranslate nohighlight">\(\mdp\)</span> denoted by <span class="math notranslate nohighlight">\(\mdp_Q\)</span>. The chain <span class="math notranslate nohighlight">\(\mdp^{\sigma}_{Q}\)</span> arises by fixing, in <span class="math notranslate nohighlight">\(\mdp_Q\)</span>, a strategy formed by a restriction of <span class="math notranslate nohighlight">\(\sigma\)</span> to <span class="math notranslate nohighlight">\(Q\)</span>. We use the following powerful theorem to analyse <span class="math notranslate nohighlight">\(\mdp^{\sigma}_{Q}\)</span>.</p>
<p>```{prf:theorem} Ergodic theorem; see Theorem~1.10.2 in <span id="id2">[<a class="reference internal" href="references.html#id120"><span>Nor98</span></a>]</span>
:label: 5-thm:ergodic
In a strongly connected Markov chain (with a finite set of vertices <span class="math notranslate nohighlight">\(\vertices\)</span>) there exists a unique invariant distribution <span class="math notranslate nohighlight">\(\invdist\)</span>. Moreover, for every vector <span class="math notranslate nohighlight">\(\vec{h}\in \R^{\vertices}\)</span> the following equation holds with probability 1:</p>
<div class="math notranslate nohighlight">
\[
\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{\ing(\pi_i)} = \sum_{v\in\vertices} \invdist_v\cdot \vec{h}_v.
\]</div>
<p>(In particular, the limit is well-defined with probability 1).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>

We can use the Ergodic theorem to shows that the expected mean-payoff achieved by $\sigma$ in $\mdp_{Q}$ matches the optimal value of $ \lpmp $, in a very strong sense: the probability of a play having a mean-payoff equal to this optimal value is 1 under $ \sigma $.

```{prf:theorem} NEEDS TITLE 5-cor:mp-scc-optimality
:label: 5-cor:mp-scc-optimality

Let $\sigma_Q$ be the restriction of $\sigma$ to $Q$. Then for every $v\in Q$ it holds that $\probm^{\sigma_Q}_{\mdp_Q,v}(\MeanPayoffInf = r^*)=1$, where $r^*$ is the is the optimal value of $\lpmp$. 

</pre></div>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\( \vec{w}\in\R^{\vertices \times\actions} \)</span> be a vector sych that <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=\lpsol{x}_{(v,a)}/\sum_{(q,a)\in Q\times\actions} \lpsol{x}_{(q,a)}\)</span> for every <span class="math notranslate nohighlight">\((v,a)\in Q\times \actions\)</span>, and <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=0\)</span> for all other <span class="math notranslate nohighlight">\((v,a)\)</span>. We claim that <span class="math notranslate nohighlight">\( \vec{w} \)</span> is also an optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span>.</p>
<p>To prove feasibility, note that setting <span class="math notranslate nohighlight">\(\vec{w}_{(v,a)}=0\)</span> for each <span class="math notranslate nohighlight">\(v\in \vertices\setminus Q\)</span> does not break the constraints~\eqref{5-eq:mdp-flow}. This is because <span class="math notranslate nohighlight">\(Q\)</span> induces a strongly connected sub-chain of <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>, and hence there are no <span class="math notranslate nohighlight">\(v\in \vertices\)</span>, <span class="math notranslate nohighlight">\(u\in \vertices\setminus Q\)</span> such that <span class="math notranslate nohighlight">\(\lpsol{x}_{(u,a)}\cdot \probTranFunc(v\mid u,a)&gt;0\)</span>. Next,~\eqref{5-eq:mdp-flow} is invariant w.r.t. multiplication of variables by a constant, so normalizing the remaining values preserves~\eqref{5-eq:mdp-flow} and ensures that~\eqref{5-eq:mdp-freq-1} holds.</p>
<p>To prove optimality, assume that the objective value of <span class="math notranslate nohighlight">\(\vec{w}\)</span> is smaller than <span class="math notranslate nohighlight">\(r^*\)</span>. Then we can mirror the construction from the previous paragraph and produce a feasible solution <span class="math notranslate nohighlight">\({\hat{\vec{w}}_{(v,a)}}\)</span> whose <span class="math notranslate nohighlight">\((Q\times\actions)\)</span>-indexed components are zero and the rest are normalized components of <span class="math notranslate nohighlight">\(\lpsol{x}\)</span>. Then <span class="math notranslate nohighlight">\(r^*\)</span> is a convex combination of the objective values of <span class="math notranslate nohighlight">\(\vec{w}\)</span> and <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span>, so <span class="math notranslate nohighlight">\(\hat{\vec{w}}\)</span> must have a strictly larger value than <span class="math notranslate nohighlight">\(r^*\)</span>, a contradiction with the latter’s optimality.</p>
<p>We now plug <span class="math notranslate nohighlight">\( \vec{w} \)</span> into the ergodic theorem as follows: As in <a class="reference internal" href="#5-lem:mc-rec">Lemma 164</a>, it easy to prove that setting <span class="math notranslate nohighlight">\(\invdist_v=\sum_{a\in\actions}\vec{w}_{(v,a)}\)</span> yields an invariant distribution. Now put <span class="math notranslate nohighlight">\(\vec{h}_v=\sum_{a\in\actions}\sigma(a\mid v)\cdot \colouring(v,a)\)</span> (<span class="math notranslate nohighlight">\( =  \sum_{w \in \vertices} \mcprob_{v,w}\cdot \colouring(v,w)\)</span>). From the Ergodic theorem we get that <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=0}^{n-1}\vec{h}_{\ing(\pi_i)}\)</span> almost-surely exists and equals
\begin{align}
\sum_{v\in Q} \invdist_v\cdot \vec{h}<em>v &amp;= \sum</em>{v\in \vertices} \left(\big(\sum_{d\in\actions}\vec{w}<em>{(v,d)}\big)\cdot \big(\sum</em>{a\in\actions}\sigma(a\mid v)\cdot \colouring(v,a) \big)\right) \nonumber\
&amp;= \sum_{v\in Q} \left(\Bigg( \frac{\sum_{d\in\actions}\lpsol{x}<em>{(v,d)}}{\sum\limits</em>{\substack{q\in Q\ b\in \actions}} \lpsol{x}<em>{(q,b)}} \Bigg)\cdot \Bigg( \frac{\sum</em>{a\in\actions}\lpsol{x}<em>{(v,a)}\cdot\colouring(v,a)}{\sum\limits</em>{d\in  \actions} \lpsol{x}<em>{(v,d)}} \Bigg) \right) \nonumber\
&amp;= \frac{1}{\sum\limits</em>{\substack{q\in Q\ b\in \actions}} \lpsol{x}<em>{(q,b)}}\cdot\sum\limits</em>{\substack{v\in Q\ a\in\actions}} \lpsol{x}<em>{(v,a)}\cdot \colouring(v,a) = \sum\limits</em>{\substack{v\in Q\ a\in\actions}} \vec{w}_{(v,a)}\cdot\colouring(v,a) =r^*.\label{5-eq:ergodic-use}
\end{align}</p>
<p>It remains to take a step from the left-hand side of~\eqref{5-eq:ergodic-use} towards the mean payoff. To this end, we construct a new Markov chain <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> from <span class="math notranslate nohighlight">\(\mdp_Q\)</span> by splitting every edge <span class="math notranslate nohighlight">\((u,v)\)</span> with a new dummy vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> (i.e., <span class="math notranslate nohighlight">\(d_{u,v}\)</span> has one edge incoming from <span class="math notranslate nohighlight">\(u\)</span> with probability <span class="math notranslate nohighlight">\(\mcprob_{u,v}\)</span> and one edge outgoing to <span class="math notranslate nohighlight">\(v\)</span> with probability <span class="math notranslate nohighlight">\(1\)</span>). In <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> we define a vector <span class="math notranslate nohighlight">\(\vec{h}'\)</span> s.t. for each vertex <span class="math notranslate nohighlight">\(d_{u,v}\)</span> the vector <span class="math notranslate nohighlight">\( \vec{h}' \)</span> has the <span class="math notranslate nohighlight">\( d_{u,v} \)</span>-component equal to <span class="math notranslate nohighlight">\(\colouring(u,v)\)</span>, while the components corresponding to the original vertices are zero. It is easy to check that <span class="math notranslate nohighlight">\(\mdp_Q'\)</span>  is strongly connected and that it has an invariant distribution <span class="math notranslate nohighlight">\(\invdist'\)</span> defined by <span class="math notranslate nohighlight">\(\invdist'_v=\invdist_v/2\)</span> for <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(\invdist'_{d_{u,v}}=\frac{\invdist_u\cdot\mcprob_{u,v}}{2}\)</span> for <span class="math notranslate nohighlight">\((u,v)\)</span> an edge of <span class="math notranslate nohighlight">\(\mdp_Q\)</span>.
Also, by easy induction, for each play <span class="math notranslate nohighlight">\(\play\)</span> of length <span class="math notranslate nohighlight">\(n\)</span> in <span class="math notranslate nohighlight">\(\mdp_Q\)</span> it holds <span class="math notranslate nohighlight">\(\frac{1}{n}\sum_{i=0}^{n-1}\colouring(\play_i) = \frac{1}{n}\sum_{i=0}^{2n-1}\vec{h}'_{\ing(\play_i')}\)</span>, where <span class="math notranslate nohighlight">\(\play'\)</span> is the unique play in <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> obtained from <span class="math notranslate nohighlight">\(\play\)</span> by splitting edges with appropriate dummy vertices. Hence,
\begin{equation}
\label{5-eq:mc-opt-limit}
\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\colouring(\play_i) = 2\cdot \lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}’<em>{\ing(\play_i’)},\end{equation} provided that both limits exist. By the ergodic theorem  applied to <span class="math notranslate nohighlight">\(\mdp_Q'\)</span>, we have that the RHS  limit in~\eqref{5-eq:mc-opt-limit} is defined with probability 1 and equal to
\begin{align*}
\underbrace{\sum</em>{v\in Q} \invdist’<em>v \cdot \vec{h}’</em>{v}}<em>{=0} + \sum</em>{u,v\in Q} \invdist’<em>{d</em>{u,v}}\cdot \vec{h}’<em>{d</em>{u,v}} = \frac{1}{2}\sum_{u\in Q}\invdist_u\cdot\left( \sum_{v\in Q}\mcprob_{u,v}\cdot \colouring(u,v)\right)\ =\frac{1}{2}\sum_{u\in Q} \invdist_u\cdot \vec{h}_u=\frac{r^<em>}{2},
\end{align</em>}</p>
<p>the last equality being shown above. Plugging this into~\eqref{5-eq:mc-opt-limit} yields that if a limit on the LHS (i.e., the mean payoff of a play) is well-defined with probability 1, then it is equal to <span class="math notranslate nohighlight">\(r^*\)</span> also with probability 1. But if there was a set <span class="math notranslate nohighlight">\(L\)</span> of positive probability in <span class="math notranslate nohighlight">\(\mdp_Q\)</span> with <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\colouring(\play_i)\)</span> undefined for each <span class="math notranslate nohighlight">\(\play\in L\)</span>, by splitting the plays in <span class="math notranslate nohighlight">\(L\)</span> we would obtain a positive-probability set of plays in <span class="math notranslate nohighlight">\(\mdp_Q'\)</span> in which <span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}\vec{h}'_{\ing(\play_i')}\)</span> is also undefined, a contradiction with the ergodic theorem.</p>
</div>
<p>So far, we have constructed an optimal strategy <span class="math notranslate nohighlight">\(\sigma_Q\)</span> but only on the part <span class="math notranslate nohighlight">\(Q\)</span> of the original MDP <span class="math notranslate nohighlight">\(\mdp\)</span>. To conclude the construction, we define a memoryless strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> in <span class="math notranslate nohighlight">\(\mdp\)</span> as follows: we fix a memoryless deterministic strategy <span class="math notranslate nohighlight">\(\sigma_{=1}\)</span> that is winning, from each vertex of <span class="math notranslate nohighlight">\(\mdp,\)</span> for the objective of almost-sure reaching of <span class="math notranslate nohighlight">\(Q\)</span> (such a strategy exists since <span class="math notranslate nohighlight">\(\mdp\)</span> is strongly connected, see also  <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 139</a>. Then we put <span class="math notranslate nohighlight">\(\sigma^*(v)=\sigma_{=1}(v)\)</span> if <span class="math notranslate nohighlight">\(v\not\in Q\)</span> and <span class="math notranslate nohighlight">\(\sigma^*(v)=\sigma_Q(v)\)</span> otherwise. Hence, starting in any vertex, <span class="math notranslate nohighlight">\(\sigma^*\)</span> eventually reaches <span class="math notranslate nohighlight">\(Q\)</span> with probability 1 and then it starts behaving as <span class="math notranslate nohighlight">\(\sigma_Q\)</span>. The optimality of such a strategy follows from the prefix independence of mean payoff, as argued in the next theorem.</p>
<div class="proof theorem admonition" id="5-thm:mp-valcomp">
<p class="admonition-title"><span class="caption-number">Theorem 166 </span> (NEEDS TITLE 5-thm:mp-valcomp)</p>
<div class="theorem-content section" id="proof-content">
<p>For any sequence of numbers <span class="math notranslate nohighlight">\(c_0,c_1,\dots\)</span> and any <span class="math notranslate nohighlight">\(k\in\N\)</span> it holds <span class="math notranslate nohighlight">\(\liminf_{n\rightarrow \infty}\frac{1}{n}\sum_{i=0}^{n-1}c_i = \liminf_{m\rightarrow \infty}\frac{1}{m}\sum_{i=0}^{m-1}c_{k+i}\)</span>. As a consequence,
for every vertex <span class="math notranslate nohighlight">\(v\)</span> in <span class="math notranslate nohighlight">\(\mdp\)</span> it holds <span class="math notranslate nohighlight">\(\probm^{\sigma_Q}_{\mdp_Q,v}(\MeanPayoffInf=r^*)=1,\)</span> where <span class="math notranslate nohighlight">\(r^*\)</span> is the optimal value of <span class="math notranslate nohighlight">\(\lpmp\)</span>. Hence, <span class="math notranslate nohighlight">\(\expv^{\sigma^*}_v[\MeanPayoffInf]= r^*\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We have
\begin{align*}
\liminf_{n\rightarrow \infty}\frac{c_0 + \cdots c_{n-1}}{n} &amp;= \liminf_{n\rightarrow \infty}\left(\underbrace{\frac{k}{n}}<em>{\mathrlap{\text{vanishes for } n\rightarrow \infty}}\cdot\frac{c_0 + \cdots + c</em>{k-1}}{k} + \underbrace{\frac{n-k}{n}}<em>{\mathrlap{\rightarrow 1 \text{ for } n\rightarrow \infty}}\cdot\frac{c_k+\cdot+c</em>{n-1}}{n-k} \right)\
&amp;=\liminf_{m\rightarrow\infty} \frac{c_k+\dots+c_{k+m-1}}{m}.
\end{align*} A similar argument holds for <span class="math notranslate nohighlight">\(\limsup.\)</span></p>
<p>With probability 1, a play has an infinite suffix consisting of plays from <span class="math notranslate nohighlight">\(\mdp_Q^{\sigma}\)</span>, and thus also <span class="math notranslate nohighlight">\(\MeanPayoffInf\)</span> and <span class="math notranslate nohighlight">\(\MeanPayoffSup\)</span> determined by this suffix. By \Cref{5-cor:mp-scc-optimality}, these quantities are equal to <span class="math notranslate nohighlight">\(r^*\)</span> with probability 1.</p>
</div>
<p>The following theorem summarizes the computational aspects.</p>
<div class="proof theorem admonition" id="5-thm:mp-rand-opt-main">
<p class="admonition-title"><span class="caption-number">Theorem 167 </span> (NEEDS TITLE 5-thm:mp-rand-opt-main)</p>
<div class="theorem-content section" id="proof-content">
<p>In a strongly connected mean-payoff MDP, one can compute, in polynomial time, a memoryless randomized strategy which is optimal from every vertex, as well as the (single) optimal value of every vertex.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We obtain, in polynomial time, an optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span>, with the optimal objective value being the optimal value of every vertex ( <a class="reference internal" href="#5-thm:mp-valcomp">Theorem 166</a>). We then use this optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> to construct the strategy <span class="math notranslate nohighlight">\(\sigma\)</span> and the  Markov chain <span class="math notranslate nohighlight">\(\mdp_{\solvset}^{\sigma}\)</span>. From this chain we extract a strongly connected subset of vertices <span class="math notranslate nohighlight">\(Q\)</span> (in polynomial time, by a simple graph reachability analysis). With the subset in hand, we can construct strategies <span class="math notranslate nohighlight">\(\sigma_Q\)</span> and <span class="math notranslate nohighlight">\(\sigma_{=1}\)</span>, all polynomial-time computations (see  <a class="reference internal" href="reachability.html#5-thm:as-char">Theorem 139</a>). These two strategies are then combined to produce the optimal strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span>.</p>
</div>
<div class="section" id="deterministic-optimality-in-strongly-connected-mdps">
<h2>Deterministic optimality in strongly connected MDPs<a class="headerlink" href="#deterministic-optimality-in-strongly-connected-mdps" title="Permalink to this headline">¶</a></h2>
<p>It remains to prove that we can actually compute a memoryless~<strong>deterministic</strong> strategy that is optimal in every vertex. Looking back at the construction that resulted in  <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 167</a>, we see that the optimal strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> might be randomized because the computed optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span> can contain two components <span class="math notranslate nohighlight">\((v,a)\)</span>, <span class="math notranslate nohighlight">\((v,b)\)</span> with <span class="math notranslate nohighlight">\(a\neq b\)</span> and both <span class="math notranslate nohighlight">\(\lpsol{x}_{(v,a)}\)</span> and <span class="math notranslate nohighlight">\(\lpsol{x}_{(v,b)}\)</span> being positive. To prove memoryless deterministic optimality, we will show that there is always an optimal solution which yields a deterministic strategy, and that such a solution can be obtained in polynomial time.</p>
<p>The previous section implicitly defined two mappings: First, a mapping <span class="math notranslate nohighlight">\(\Psi\)</span>, which maps every solution <span class="math notranslate nohighlight">\( \vec{x} \)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span> to a memoryless strategy in some sub-MDP of <span class="math notranslate nohighlight">\(\mdp\)</span>, by putting <span class="math notranslate nohighlight">\(\Psi(\vec{x}) = \sigma\)</span> where <span class="math notranslate nohighlight">\(\sigma(a\mid v) = \vec{x}_{(v,a)}/\sum_{b\in \actions}\vec{x}_{(v,b)}\)</span>. Second, mapping <span class="math notranslate nohighlight">\(\Xi\)</span>, which maps each memoryless strategy <span class="math notranslate nohighlight">\(\sigma\)</span> that induces a strongly connected Markov chain to a solution <span class="math notranslate nohighlight">\(\Xi(\sigma)\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span> such that <span class="math notranslate nohighlight">\(\Xi(\sigma)_{(v,a)}=\invdist_v\cdot \sigma(a\mid v)\)</span>, where <span class="math notranslate nohighlight">\(\invdist\)</span> is the unique invariant distribution of the chain induced by <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<div class="proof lemma admonition" id="5-lem:sol-strat-correspondence">
<p class="admonition-title"><span class="caption-number">Lemma 168 </span> (NEEDS TITLE 5-lem:sol-strat-correspondence)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be the set containing exactly those solutions <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span> for which the strategy  <span class="math notranslate nohighlight">\(\Psi(\vec{x})\)</span> induces a strongly connected Markov chain. Then the mappings <span class="math notranslate nohighlight">\(\Psi\)</span> and <span class="math notranslate nohighlight">\(\Xi\)</span> are bijections between <span class="math notranslate nohighlight">\(X\)</span> and the set of all memoryless strategies in some sub-MDP of <span class="math notranslate nohighlight">\(\mdp\)</span> that induce a strongly connected Markov chain.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>A straightforward computation shows that <span class="math notranslate nohighlight">\(\Xi\circ\Psi\)</span> and <span class="math notranslate nohighlight">\(\Psi\circ\Xi\)</span> are identity functions on the respective sets.</p>
</div>
<div class="proof definition admonition" id="definition-7">
<p class="admonition-title"><span class="caption-number">Definition 169 </span> (NEEDS TITLE AND LABEL)</p>
<div class="definition-content section" id="proof-content">
<p>\label{5-def:pure-lp}
A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span>is <strong>pure</strong> if for every vertex <span class="math notranslate nohighlight">\(v\)</span> there is at most one action <span class="math notranslate nohighlight">\(a\)</span> such that <span class="math notranslate nohighlight">\(\vec{x}_{(v,a)}&gt;0\)</span>.</p>
<p>:label:
\label{5-def:pure-lp}
A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span>is <strong>pure</strong> if for every vertex <span class="math notranslate nohighlight">\(v\)</span> there is at most one action <span class="math notranslate nohighlight">\(a\)</span> such that <span class="math notranslate nohighlight">\(\vec{x}_{(v,a)}&gt;0\)</span>.</p>
<p>\label{5-def:pure-lp}
A solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span>is <strong>pure</strong> if for every vertex <span class="math notranslate nohighlight">\(v\)</span> there is at most one action <span class="math notranslate nohighlight">\(a\)</span> such that <span class="math notranslate nohighlight">\(\vec{x}_{(v,a)}&gt;0\)</span>.</p>
</div>
</div><p>The following lemma follows from the way in which strategies <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\sigma^*\)</span> were constructed in the previous sub-section.</p>
<div class="proof lemma admonition" id="lemma-8">
<p class="admonition-title"><span class="caption-number">Lemma 170 </span> (NEEDS TITLE AND LABEL)</p>
<div class="lemma-content section" id="proof-content">
<p>\label{5-lem:pure-lpsol}
Let <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span> and denote <span class="math notranslate nohighlight">\( S = \{v \in \vertices\mid \exists a \text{ s.t. }\lpsol{x}_{(v,a)}&gt;0\} \)</span>. Then the strategy <span class="math notranslate nohighlight">\(\sigma=\Psi(\lpsol{x})\)</span> is an MD strategy in <span class="math notranslate nohighlight">\(\mdp_{\solvset}\)</span>. Hence, in such a case, the strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> constructed from <span class="math notranslate nohighlight">\( \sigma \)</span> as in  <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 167</a> is an optimal MD strategy in <span class="math notranslate nohighlight">\(\mdp\)</span>.</p>
<p>:label:
\label{5-lem:pure-lpsol}
Let <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span> and denote <span class="math notranslate nohighlight">\( S = \{v \in \vertices\mid \exists a \text{ s.t. }\lpsol{x}_{(v,a)}&gt;0\} \)</span>. Then the strategy <span class="math notranslate nohighlight">\(\sigma=\Psi(\lpsol{x})\)</span> is an MD strategy in <span class="math notranslate nohighlight">\(\mdp_{\solvset}\)</span>. Hence, in such a case, the strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> constructed from <span class="math notranslate nohighlight">\( \sigma \)</span> as in  <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 167</a> is an optimal MD strategy in <span class="math notranslate nohighlight">\(\mdp\)</span>.</p>
<p>\label{5-lem:pure-lpsol}
Let <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> be a pure optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span> and denote <span class="math notranslate nohighlight">\( S = \{v \in \vertices\mid \exists a \text{ s.t. }\lpsol{x}_{(v,a)}&gt;0\} \)</span>. Then the strategy <span class="math notranslate nohighlight">\(\sigma=\Psi(\lpsol{x})\)</span> is an MD strategy in <span class="math notranslate nohighlight">\(\mdp_{\solvset}\)</span>. Hence, in such a case, the strategy <span class="math notranslate nohighlight">\(\sigma^*\)</span> constructed from <span class="math notranslate nohighlight">\( \sigma \)</span> as in  <a class="reference internal" href="#5-thm:mp-rand-opt-main">Theorem 167</a> is an optimal MD strategy in <span class="math notranslate nohighlight">\(\mdp\)</span>.</p>
</div>
</div><p>It remains to show how to find a pure optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span>. To this end we exploit some fundamental properties of linear programs.</p>
<p>A linear program is in the <strong>standard</strong> (or equational) form if its set of constraints can be expressed as <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span>, <span class="math notranslate nohighlight">\(\vec{x}\geq 0\)</span>, where <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a vector of variables, <span class="math notranslate nohighlight">\(\vec{b}\)</span> is a non-negative vector, and <span class="math notranslate nohighlight">\(A\)</span> is a matrix of an appropriate dimension. In this notation, all the vectors are column vectors, i.e. <span class="math notranslate nohighlight">\(A\)</span> has one column per each variable. Note that <span class="math notranslate nohighlight">\(\lpmp\)</span> is a program in the standard form. A feasible solution <span class="math notranslate nohighlight">\(\vec{x}\)</span> of such a program is <strong>basic</strong> if the columns of <span class="math notranslate nohighlight">\(A\)</span> corresponding to variables whose value is positive in <span class="math notranslate nohighlight">\(\vec{x}\)</span> form a linearly independent set of vectors. Since the maximal number of linearly independent columns equals the maximal number of linearly independent rows (a number called a <strong>rank</strong> of <span class="math notranslate nohighlight">\(A\)</span>), we know that each basic feasible solution has at most as many positive entries as there are rows of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>The next two lemmas prove some fundamental properties of basic feasible solutions.</p>
<div class="proof lemma admonition" id="5-lem:basic-cond-unique">
<p class="admonition-title"><span class="caption-number">Lemma 171 </span> (NEEDS TITLE 5-lem:basic-cond-unique)</p>
<div class="lemma-content section" id="proof-content">
<p>Assume that a linear program in a standard form has two basic feasible solutions <span class="math notranslate nohighlight">\(\vec{x},\vec{x}'\)</span> such that both solutions have the same set of non-zero components, and the cardinality of this set equals the number of equality constraints in the program. Then <span class="math notranslate nohighlight">\(\vec{x}=\vec{x}'\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Write <span class="math notranslate nohighlight">\(A\cdot \vec{x} = \vec{b}\)</span> the equational constraints of the LP.
If <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic feasible solution, then it solves the equation <span class="math notranslate nohighlight">\(A_{N} \cdot \vec{x}_N = \vec{b}\)</span>, where <span class="math notranslate nohighlight">\(A_N\)</span> (<span class="math notranslate nohighlight">\(  N\)</span> stands for non-zero) is obtained from <span class="math notranslate nohighlight">\(A\)</span> by removing all columns corresponding to zero components of <span class="math notranslate nohighlight">\(\vec{x}\)</span>, and   <span class="math notranslate nohighlight">\(\vec{x}_N\)</span> is obtained from <span class="math notranslate nohighlight">\(\vec{x}\)</span> by removing all zero components.</p>
<p>Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> has as many non-zero components as there are rows of <span class="math notranslate nohighlight">\(A\)</span>, it follows that <span class="math notranslate nohighlight">\(A_N\)</span> is a square matrix. Since <span class="math notranslate nohighlight">\(\vec{x}\)</span> is a basic solution, <span class="math notranslate nohighlight">\(A_N\)</span> is regular (its columns are linearly independent) and <span class="math notranslate nohighlight">\(\vec{x}=A_{N}^{-1}\cdot \vec{b}\)</span> is uniquely determined by <span class="math notranslate nohighlight">\(A_N\)</span>. Repeating the same argument for <span class="math notranslate nohighlight">\(\vec{x}'\)</span> yields <span class="math notranslate nohighlight">\(\vec{x}'=A_{N}^{-1}\cdot \vec{b}= \vec{x}\)</span>.</p>
</div>
<div class="proof lemma admonition" id="5-lem:basic-sol">
<p class="admonition-title"><span class="caption-number">Lemma 172 </span> (NEEDS TITLE 5-lem:basic-sol)</p>
<div class="lemma-content section" id="proof-content">
<p>If a linear program in a standard form has an optimal solution, then it has also a basic optimal solution. Moreover, a basic optimal solution can be found in polynomial time.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>[Sketch]
The existence of a basic optimal solution is a well-known linear programming fact, e.g. the standard simplex algorithm works by traversing the set of basic feasible solutions until it finds an optimal one <span id="id3">[<a class="reference internal" href="references.html#id119"><span>Matouvsek07</span></a>]</span>. For computing an optimal basic solution, we can use one of the polynomial-time interior-point methods for linear programming, such as the path-following method <span id="id4">[<a class="reference internal" href="references.html#id116"><span>Kar84</span></a>,<a class="reference internal" href="references.html#id113"><span>Gon92</span></a>]</span>. While these methods work by traversing the interior of the polyhedron of feasible solutions, they converge, in polynomial time, to a point that is closer to the optimal basic solution than to all the other basic solutions. By a process called <strong>purification,</strong> such a point can be then converted to the closest basic solution, i.e. to the optimal one <span id="id5">[<a class="reference internal" href="references.html#id113"><span>Gon92</span></a>]</span>.</p>
</div>
<div class="proof theorem admonition" id="5-thm:lpmp-basic-dim">
<p class="admonition-title"><span class="caption-number">Theorem 173 </span> (NEEDS TITLE 5-thm:lpmp-basic-dim)</p>
<div class="theorem-content section" id="proof-content">
<p>One can find, in polynomial time, an optimal deterministic strategy in a given strongly connected  mean-payoff MDP.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>First, we use <a class="reference internal" href="#5-lem:basic-sol">Lemma 172</a> to find a basic optimal solution <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> of <span class="math notranslate nohighlight">\(\lpmp\)</span>.
We check if it is pure. If yes, we are done. Otherwise,
there is <span class="math notranslate nohighlight">\(v\in \vertices\)</span> and two distinct actions <span class="math notranslate nohighlight">\(a,b\)</span> such that <span class="math notranslate nohighlight">\(\lpsol{x}_{(v,a)}&gt;0\)</span> and <span class="math notranslate nohighlight">\(\lpsol{x}_{(v,b)}&gt;0.\)</span> Let <span class="math notranslate nohighlight">\( S = \{v \in \vertices\mid \exists a \text{ s.t. }\lpsol{x}_{(v,a)}&gt;0\} \)</span>. By~\Cref{5-cor:mp-scc-extraction}, we can partition <span class="math notranslate nohighlight">\(\solvset\)</span> into several subsets, each of which induces a strongly connected sub-MDP of <span class="math notranslate nohighlight">\(\mdp\)</span>. Let <span class="math notranslate nohighlight">\(Q\)</span> be a class of this partition containing <span class="math notranslate nohighlight">\(v\)</span>. We have that the optimal mean-payoff value of every vertex in <span class="math notranslate nohighlight">\(\mdp_Q\)</span> is the same as in <span class="math notranslate nohighlight">\(\mdp\)</span>. This is because,
as in the beginning of the proof of~\Cref{5-cor:mp-scc-optimality}, we can transform <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> into another optimal solution of the same value as <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> which has non-zero entries only for components indexed by <span class="math notranslate nohighlight">\((q,a)\)</span> with <span class="math notranslate nohighlight">\(q\in Q\)</span>. All these computations can be easily implemented in polynomial time.</p>
<p>We argue that <span class="math notranslate nohighlight">\(Q\)</span> is a strict subset of <span class="math notranslate nohighlight">\(\vertices\)</span>. Indeed, assume that <span class="math notranslate nohighlight">\(Q=\vertices\)</span>. Then <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> induces a randomized strategy <span class="math notranslate nohighlight">\(\sigma\)</span> in <span class="math notranslate nohighlight">\(\mdp\)</span>. Moreover, since <span class="math notranslate nohighlight">\(\lpsol{x}\)</span> is a basic solution, it has at most <span class="math notranslate nohighlight">\(|\vertices|+1\)</span> positive entries, and since it is non-pure, it must have exactly <span class="math notranslate nohighlight">\(n+1\)</span> positive entries, i.e.  <a class="reference internal" href="#5-lem:basic-cond-unique">Lemma 171</a> is applicable to <span class="math notranslate nohighlight">\(\lpsol{x}\)</span>, since <span class="math notranslate nohighlight">\(\lpmp\)</span> has exactly <span class="math notranslate nohighlight">\(|\vertices|+1\)</span> constraints. Now we define a new strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> in <span class="math notranslate nohighlight">\(\mdp\)</span> by slightly changing the behaviour in <span class="math notranslate nohighlight">\(v\)</span>. To this end, choose some <span class="math notranslate nohighlight">\(\eps&gt;0\)</span> and put <span class="math notranslate nohighlight">\(\sigma'(a\mid v)=\sigma(a\mid v)-\eps\)</span> and <span class="math notranslate nohighlight">\(\sigma'(b\mid v)=\sigma(b\mid v)+\eps\)</span>; we choose <span class="math notranslate nohighlight">\(\eps\)</span> small enough so that both quantities are still non-zero. The chain <span class="math notranslate nohighlight">\(\mdp^{\sigma'}\)</span> is still strongly connected. Now let <span class="math notranslate nohighlight">\(\vec{x}' = \Xi(\sigma')\)</span>. Then <span class="math notranslate nohighlight">\(\vec{x}'\)</span> is a solution of <span class="math notranslate nohighlight">\(\lpmp\)</span> which is still basic, with a set of non-zero components being the same as in <span class="math notranslate nohighlight">\(\lpsol{x}\)</span>. At the same time, <span class="math notranslate nohighlight">\(\vec{x}'\neq \lpsol{x}\)</span>, since <span class="math notranslate nohighlight">\(\sigma\neq {\sigma'}\)</span> and <span class="math notranslate nohighlight">\(\Xi\)</span> is a bijection ( <a class="reference internal" href="#5-lem:sol-strat-correspondence">Lemma 168</a>). But this is a contradiction with  <a class="reference internal" href="#5-lem:basic-cond-unique">Lemma 171</a>.</p>
<p>Hence, <span class="math notranslate nohighlight">\(\mdp_Q\)</span> is a strict sub-MDP of <span class="math notranslate nohighlight">\(\mdp\)</span> in which the value of every vertex is the same as in the original MDP. We can perform a recursive call of the aforementioned computation on <span class="math notranslate nohighlight">\(\mdp_Q\)</span> (compute basic optimal solution of <span class="math notranslate nohighlight">\(\lpmp\)</span>, check purity, possibly extract and recurse on a sub-MDP).
The depth of recursion is bounded by <span class="math notranslate nohighlight">\(|\vertices|\)</span>, so the running time is polynomial. Since each sub-MDP obtained during the recursion is non-empty, and the size of the MDPs decreases, the recursion must eventually terminate with a basic optimal solution (in some sub-MDP <span class="math notranslate nohighlight">\(\mdp'\)</span>) that is pure. This yields a memoryless deterministic strategy in <span class="math notranslate nohighlight">\(\mdp'\)</span> whose value is equal to the optimal value in <span class="math notranslate nohighlight">\(\mdp.\)</span> Such a strategy can be extended to whole <span class="math notranslate nohighlight">\(\mdp\)</span> by solving almost sure reachability to <span class="math notranslate nohighlight">\( \mdp' \)</span>, as described in the previous sub-section.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5_MDP"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="mean_payoff_properties.html" title="previous page">Mean-payoff in MDPs: General properties and linear programming</a>
    <a class='right-next' id="next-link" href="end_components.html" title="next page">End components</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>