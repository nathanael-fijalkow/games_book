
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Discounted payoff games &#8212; Games on graphs</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Shortest path games" href="shortest_path.html" />
    <link rel="prev" title="Mean payoff games" href="mean_payoff.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Games on graphs</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1_Introduction/index.html">
   Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/intro.html">
     What is this book about?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/simple.html">
     A first model of games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/objectives.html">
     Objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/computation.html">
     Computational models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/automata.html">
     Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/memory.html">
     Memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/reductions.html">
     Reductions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/subgames.html">
     Traps and subgames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/fixed_points.html">
     Generic fixed point algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/value_iteration.html">
     Value iteration algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/strategy_improvement.html">
     Strategy improvement algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_Introduction/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classic
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../2_Regular/index.html">
   Regular Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/attractors.html">
     Reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/buchi.html">
     BÃ¼chi games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/parity.html">
     Parity games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/muller.html">
     Rabin, Streett, and Muller games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/zielonka.html">
     Zielonka tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_Regular/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../3_Parity/index.html">
   Parity Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/strategy_improvement.html">
     An exponential time strategy improvement algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/zielonka.html">
     A quasipolynomial time attractor decomposition algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/separation.html">
     A quasipolynomial time separating automata algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/value_iteration.html">
     A quasipolynomial time value iteration algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/relationships.html">
     Comparing the three families of algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_Parity/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index.html">
   Games with Payoffs
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="qualitative.html">
     Refining qualitative objectives with quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mean_payoff.html">
     Mean payoff games
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Discounted payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="shortest_path.html">
     Shortest path games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="total_payoff.html">
     Total payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Stochastic
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../5_MDP/index.html">
   Markov Decision Processes
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reachability.html">
     Positive and almost-sure reachability and safety in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/discounted.html">
     Discounted payoff in MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_properties.html">
     Mean-payoff in MDPs: General properties and linear programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/mean_payoff_strongly_connected.html">
     Mean-payoff optimality in strongly connected MDPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/end_components.html">
     End components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/reductions.html">
     Reductions to optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/optimal_reachability.html">
     Optimal reachability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_MDP/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../6_Stochastic/index.html">
   Stochastic Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/determinacy.html">
     Positional determinacy of stochastic reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/relations.html">
     Relations between all games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/algos.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_Stochastic/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../7_Concurrent/index.html">
   Concurrent Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/matrix_games.html">
     Matrix games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/reachability.html">
     Concurrent reachability games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/mean_payoff.html">
     Concurrent mean-payoff games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/discounted.html">
     Concurrent discounted games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_Concurrent/references.html">
     Bibilographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../8_Imperfect/index.html">
   Games with Signals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/finite_duration.html">
     Finite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/infinite_duration.html">
     Infinite duration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_Imperfect/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Infinite
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../9_Timed/index.html">
   Timed Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/state_space_representation.html">
     State-Space Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/controllable_predecessor_operator.html">
     Controllable-Predecessor Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/backward_algorithm.html">
     Backward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/forward_algorithm.html">
     Forward Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../9_Timed/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10_Pushdown/index.html">
   Pushdown Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/profiles.html">
     Profiles and regularity of the winning regions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/parity.html">
     Parity pushdown games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_Pushdown/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11_Counters/index.html">
   Games with Counters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/counters.html">
     Vector games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/dim1.html">
     Games in dimension one
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/avag.html">
     Asymmetric games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/resource.html">
     Resource-conscious games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/complexity.html">
     The complexity of asymmetric monotone games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11_Counters/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multi
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12_Multiobjectives/index.html">
   Games with multiple objectives
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/mean_payoff_energy.html">
     Mean-payoff and energy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/total_payoff_shortest_path.html">
     Total-payoff and shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/beyond_worst_case.html">
     Beyond worst-case synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/percentile.html">
     Percentile queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12_Multiobjectives/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13_Multiplayer/index.html">
   Multiplayer Games
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/nash_equilibria_normal_form.html">
     Nash Equilibria for games in normal form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/admissible_strategies.html">
     Admissible strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13_Multiplayer/references.html">
     Bibliographic references
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#positional-determinacy-via-a-contraction-mapping">
   Positional determinacy via a contraction mapping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strategy-improvement-algorithm">
   Strategy improvement algorithm
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration-algorithm">
   Value iteration algorithm
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#polynomial-reduction-from-mean-payoff-games-to-discounted-payoff-games">
   Polynomial reduction from mean payoff games to discounted payoff games
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="discounted-payoff-games">
<span id="sec-discounted-payoff"></span><h1>Discounted payoff games<a class="headerlink" href="#discounted-payoff-games" title="Permalink to this headline">Â¶</a></h1>
<div class="math notranslate nohighlight">
\[\renewcommand{\Game}{\game}
\]</div>
<p>From a practical point of view, the modelling of a real-world
situation via mean payoff games requires that only the long-term
behaviour is important. Since mean payoff only depends on the limit of
the play, it cannot be used to model the beginning of the execution:
the mean payoff is said to be <strong>prefix independent</strong>. In economical
studies, there is a tendency to make the prefixes count more, since
they represent short-term implications of the actions taken, even if
long-term behaviours also matter. The common payoff used to model this
preference to prefixes is the discounted payoff that associates to a
play <span class="math notranslate nohighlight">\(\pi\)</span> the weight</p>
<div class="math notranslate nohighlight">
\[\mathtt{DiscountedPayoff}_\lambda( \pi) = (1-\lambda)\sum_{i=0}^{\infty} \lambda^i
  \, c( \pi_i)\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda\)</span> is a parameter in the interval
<span class="math notranslate nohighlight">\((0,1)\)</span>, ensuring the convergence of the infinite series (since
weights <span class="math notranslate nohighlight">\(c( \pi_i)\)</span> are bounded). The coefficient <span class="math notranslate nohighlight">\(1-\lambda\)</span> before
the series is just to counterbalance the fact that if all weights in
the game are <span class="math notranslate nohighlight">\(1\)</span>, we would like the payoff to be 1 too, which then
holds since <span class="math notranslate nohighlight">\(\sum_{i=0}^\infty \lambda^i = \frac 1{1-\lambda}\)</span>. When
<span class="math notranslate nohighlight">\(\lambda\)</span> tends to <span class="math notranslate nohighlight">\(0\)</span>, only the prefixes (and even the first weight)
matters. On the contrary, when <span class="math notranslate nohighlight">\(\lambda\)</span> tends to <span class="math notranslate nohighlight">\(1\)</span>, the
discounted payoff looks more and more like the mean payoff. To grasp
an intuition why this holds, consider a play that results from
positional strategies in a mean payoff game. The weights encountered
during the play then ultimately follow a periodic sequence
<span class="math notranslate nohighlight">\(w_0,w_1,\ldots,w_{r-1},w_0,w_1,\ldots,w_{r-1},w_0,\ldots\)</span> with
average-payoff <span class="math notranslate nohighlight">\(\frac 1 r\sum_{i=0}^{r-1}w_i\)</span>. Grouping the terms of
the series <span class="math notranslate nohighlight">\((1-\lambda)\sum_{i=0}^{\infty} \lambda^i \, w_i\)</span> by
batches of <span class="math notranslate nohighlight">\(r\)</span> terms, we then obtain</p>
<div class="math notranslate nohighlight">
\[(1-\lambda)\sum_{i=0}^{\infty} \lambda^{ri} \sum_{j=0}^{r-1}
  \lambda^jw_j=\frac{1-\lambda}{1-\lambda^r}\sum_{j=0}^{r-1}
  \lambda^jw_j= \frac
  1{1+\lambda+\cdots+\lambda^{r-1}}\sum_{j=0}^{r-1} \lambda^jw_j\]</div>
<p>that tends towards the average-payoff <span class="math notranslate nohighlight">\(\frac 1 r\sum_{j=0}^{r-1} w_j\)</span>
when <span class="math notranslate nohighlight">\(\lambda\)</span> tends to <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>The weighted game of <a class="reference internal" href="mean_payoff.html#fig-mp"><span class="std std-numref">Fig. 34</span></a> can also be equipped with a
discounted payoff. If <span class="math notranslate nohighlight">\(\lambda\)</span> is close to <span class="math notranslate nohighlight">\(1\)</span>, for instance
<span class="math notranslate nohighlight">\(\lambda=0.9\)</span>, then optimal strategies are the same as for the
mean payoff objective: <span class="math notranslate nohighlight">\(\sigma^*(0)=1\)</span>, <span class="math notranslate nohighlight">\(\sigma^*(2)=3\)</span>,
<span class="math notranslate nohighlight">\(\tau^*(1)=2\)</span>, <span class="math notranslate nohighlight">\(\tau^*(3)=1\)</span>, and <span class="math notranslate nohighlight">\(\tau^*(4)=0\)</span>. In that case, the
discounted payoff of the unique lasso play
<span class="math notranslate nohighlight">\((0,1)\big((1,2)(2,3)(3,1)\big)^\omega\)</span> starting in <span class="math notranslate nohighlight">\(0\)</span> and following
this profile of strategies is
<span class="math notranslate nohighlight">\((1-\lambda)\left(4+
  \frac{2\lambda+4\lambda^2-\lambda^3}{1-\lambda^3}\right)\)</span>, which is
around <span class="math notranslate nohighlight">\(1.7\)</span> when <span class="math notranslate nohighlight">\(\lambda=0.99\)</span>, while the mean payoff optimal value
of vertex 0 was <span class="math notranslate nohighlight">\(5/3\approx 1.67\)</span>. However, the situation completely
changes when <span class="math notranslate nohighlight">\(\lambda\)</span> decreases. When <span class="math notranslate nohighlight">\(\lambda=0.5\)</span> for instance,
Adam changes his decision in vertex <span class="math notranslate nohighlight">\(1\)</span> and decides to go to vertex
<span class="math notranslate nohighlight">\(0\)</span>: this is because the cycle <span class="math notranslate nohighlight">\((1,0)\)</span> has now a discounted payoff
that becomes low enough, the first weight <span class="math notranslate nohighlight">\(0\)</span> being much lower than
<span class="math notranslate nohighlight">\(2\)</span> (if he decides to go to vertex <span class="math notranslate nohighlight">\(2\)</span>). For a really low value of
<span class="math notranslate nohighlight">\(\lambda\)</span>, for instance <span class="math notranslate nohighlight">\(\lambda=0.1\)</span>, the decisions again change
drastically for both players: now the optimal (positional) strategy
become <span class="math notranslate nohighlight">\(\sigma^*(0)=4\)</span>, <span class="math notranslate nohighlight">\(\sigma^*(2)=3\)</span>, <span class="math notranslate nohighlight">\(\tau^*(1)=0\)</span>, <span class="math notranslate nohighlight">\(\tau^*(3)=0\)</span>,
and <span class="math notranslate nohighlight">\(\tau^*(4)=0\)</span>, i.e. Adam changed his decision in vertex <span class="math notranslate nohighlight">\(3\)</span>, and
Eve in vertex <span class="math notranslate nohighlight">\(0\)</span>. However, we note that for each value of <span class="math notranslate nohighlight">\(\lambda\)</span>
considered so far, positional optimal strategies are described. This
is no accident, as we will see in the remainder of the chapter.</p>
<p>We now study how to solve this class of games, and how it is used to
obtain a theoretically more efficient solution to mean payoff
games. Indeed, we will obtain a pseudopolynomial time complexity for
both objectives.</p>
<div class="section" id="positional-determinacy-via-a-contraction-mapping">
<h2>Positional determinacy via a contraction mapping<a class="headerlink" href="#positional-determinacy-via-a-contraction-mapping" title="Permalink to this headline">Â¶</a></h2>
<p>First, it is easier (than for mean payoff games) to prove that
discounted payoff games are positionally determined, by using a
description of the values as a fixed point of a contracting operator
<span class="math notranslate nohighlight">\(F\colon  \mathbb{R}^V\to  \mathbb{R}^V\)</span> that maps every vector <span class="math notranslate nohighlight">\(\vec x=(x_v)_{v\in V}\)</span>
to a new vector <span class="math notranslate nohighlight">\((y_v)_{v\in V}\)</span> corresponding to the best that both
players can hope for in one transition if they are rewarded by vector
<span class="math notranslate nohighlight">\(\vec x\)</span> afterwards: for all <span class="math notranslate nohighlight">\(v\in V\)</span>, we thus let</p>
<div class="math notranslate nohighlight" id="equation-4-eq-f-contraction">
<span class="eqno">(3)<a class="headerlink" href="#equation-4-eq-f-contraction" title="Permalink to this equation">Â¶</a></span>\[\begin{split}y_v =
  \begin{cases}
    \max_{(v,v')\in E} [(1-\lambda) c(v,v') + \lambda x_{v'}] &amp;
    \text{ if } v\in  V_\mathrm{Eve}\\
    \min_{(v,v')\in E} [(1-\lambda) c(v,v') + \lambda x_{v'}] &amp;
    \text{ if } v\in  V_\mathrm{Adam}\\
  \end{cases}\end{split}\]</div>
<div class="proof theorem admonition" id="4-thm:discounted">
<p class="admonition-title"><span class="caption-number">Theorem 109 </span> (Positional determinacy)</p>
<div class="theorem-content section" id="proof-content">
<p>Discounted payoff games are positionally determined.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We prove that <span class="math notranslate nohighlight">\(F\)</span> is indeed a contracting operator.
For all vectors <span class="math notranslate nohighlight">\(\vec x=(x_v)_{v\in V}\)</span> and
<span class="math notranslate nohighlight">\(\vec y = (y_v)_{v\in V}\)</span>, we have, by definition,
<span class="math notranslate nohighlight">\(\|F(\vec x)-F(\vec y)\|_\infty = \max_{v\in V}|F(\vec x)_v-F(\vec
  y)_v|\)</span>. Let <span class="math notranslate nohighlight">\(v\in  V_\mathrm{Eve}\)</span>. Consider a vertex <span class="math notranslate nohighlight">\(v'\)</span> such that
<span class="math notranslate nohighlight">\(F(\vec x)_v = (1-\lambda) c(v,v') + \lambda x_{v'}\)</span>. Then,
<span class="math notranslate nohighlight">\(F(\vec y)_v\geq (1-\lambda) c(v,v') + \lambda y_{v'}\)</span> so that
<span class="math notranslate nohighlight">\(F(\vec x)_v-F(\vec y)_v\leq \lambda(x_{v'}-y_{v'})\)</span>. By now
considering <span class="math notranslate nohighlight">\(v''\)</span> such that
<span class="math notranslate nohighlight">\(F(\vec y)_v = (1-\lambda) c(v,v'') + \lambda y_{v''}\)</span>, we obtain
also that <span class="math notranslate nohighlight">\(F(\vec x)_v-F(\vec y)_v\geq \lambda(x_{v''}-y_{v''})\)</span>. In
the overall, we thus have
<span class="math notranslate nohighlight">\(|F(\vec x)_v-F(\vec y)_v|\leq \lambda\|\vec x-\vec y\|_\infty\)</span>. The
same reasoning also applies to a vertex <span class="math notranslate nohighlight">\(v\)</span> of <span class="math notranslate nohighlight">\(V_\mathrm{Adam}\)</span>. Therefore, we
obtain
<span class="math notranslate nohighlight">\(\|F(\vec x)-F(\vec y)\|_\infty\leq \lambda\|\vec x-\vec y\|_\infty\)</span>
which means that <span class="math notranslate nohighlight">\(F\)</span> is a contraction mapping (since <span class="math notranslate nohighlight">\(0&lt;\lambda&lt;1\)</span>).</p>
<p>By Banach fixed-point theorem, <span class="math notranslate nohighlight">\(F\)</span> admits a unique fixed-point
vector <span class="math notranslate nohighlight">\(\vec{x^*}\)</span>, such that <span class="math notranslate nohighlight">\(F(\vec{x^*})=\vec {x^*}\)</span>. This
fixed-point is moreover the limit of the sequence of vectors
<span class="math notranslate nohighlight">\((F^n(\vec 0))_{n\in  \mathbb{N}}\)</span> with <span class="math notranslate nohighlight">\(\vec 0\)</span> being the null vector, by
Kleene fixed-point theorem (since <span class="math notranslate nohighlight">\(F\)</span> is continuous, by composition
of continuous functions). Imagine that Eve plays a positional
strategy dictated by the equality <span class="math notranslate nohighlight">\(F(\vec{x^*})=\vec {x^*}\)</span>,
i.e. when in vertex <span class="math notranslate nohighlight">\(v\in  V_\mathrm{Eve}\)</span>, she chooses to go to some vertex
<span class="math notranslate nohighlight">\(v'\)</span> such that <span class="math notranslate nohighlight">\(x^*_v = (1-\lambda) c(v,v') + \lambda
  x^*_{v'}\)</span>. Then, she guarantees, by an easy induction proof, a value
at least <span class="math notranslate nohighlight">\(x^*_v\)</span> when starting in vertex <span class="math notranslate nohighlight">\(v\)</span> (for all <span class="math notranslate nohighlight">\(v\in V\)</span>). A
symmetrical argument for Adam allows one to obtain that, for all
<span class="math notranslate nohighlight">\(v\in V\)</span>,</p>
<div class="math notranslate nohighlight">
\[\textrm{val}_\mathrm{Adam}(v)\leq x^*_v \leq  \textrm{val}_\mathrm{Eve}(v)\,.\]</div>
<p>Since we
always have <span class="math notranslate nohighlight">\(\textrm{val}_\mathrm{Eve}(v)\leq  \textrm{val}_\mathrm{Adam}(v)\)</span>, we finally obtain that the
game is determined, and that <span class="math notranslate nohighlight">\(x^*\)</span> is equal to the optimal value
vector. Moreover, the two above positional strategies for Eve and
Adam are optimal.</p>
</div>
<p>As for mean payoff (or parity) games, the existence of positional
optimal (or winning) strategies for both players, and the ability to
solve in polynomial time the one-player version of these games, allows
us to obtain easily an <span class="math notranslate nohighlight">\(\textrm{NP}\cap \textrm{coNP}\)</span> complexity to solve
discounted payoff games in the case of integer costs and a rational
discount factor. The use of the above contracting operator even
ensures that the Turing machines guessing and checking the optimal
strategies may indeed be designed as unambiguous (instead of just
non-deterministic). Calling <span class="math notranslate nohighlight">\(\textrm{UP}\)</span> the class of problems that can be
solved by an unambiguous Turing machine running in polynomial time,
and <span class="math notranslate nohighlight">\(\textrm{coUP}\)</span> the class of problems whose complement are in <span class="math notranslate nohighlight">\(\textrm{UP}\)</span>, we
then obtain the theorem:</p>
<div class="proof theorem admonition" id="4-thm:disc-up">
<p class="admonition-title"><span class="caption-number">Theorem 110 </span> (Complexity)</p>
<div class="theorem-content section" id="proof-content">
<p>Discounted payoff games with integer costs and rational discount
factor <span class="math notranslate nohighlight">\(\lambda\)</span> can be solved in <span class="math notranslate nohighlight">\(\textrm{UP}\cap \textrm{coUP}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Using the previous result, we know that the value of a discounted
payoff game is the <strong>unique</strong> solution of the fixed point
equation <span class="math notranslate nohighlight">\(\vec x = F(\vec x)\)</span>, with <span class="math notranslate nohighlight">\(F\)</span> a contraction
mapping. Therefore, guessing vector <span class="math notranslate nohighlight">\(\vec x\)</span> and checking it is
indeed a fixed point of <span class="math notranslate nohighlight">\(F\)</span> can be performed in an unambiguous
Turing machine. To conclude, it only remains to show that this check
can be done in polynomial time, in particular we must show that the
values <span class="math notranslate nohighlight">\(\vec x\)</span> are <strong>short</strong> in terms of their binary
representation. The equality <span class="math notranslate nohighlight">\(\vec x = F(\vec x)\)</span> induces optimal
decisions in each vertex, thus leading to a profile of strategies
for both players. We summarise this profile
in:  *  a square Boolean matrix
<span class="math notranslate nohighlight">\(Q\in \{0,1\}^{V\times V}\)</span>, whose entry <span class="math notranslate nohighlight">\(Q_{v,v'}\)</span> is <span class="math notranslate nohighlight">\(1\)</span> if
<span class="math notranslate nohighlight">\((v,v')\)</span> is the chosen edge in <span class="math notranslate nohighlight">\(v\)</span> by the profile, and <span class="math notranslate nohighlight">\(0\)</span>
otherwise; *  a vector <span class="math notranslate nohighlight">\(\vec c\in  \mathbb{Z}^{V}\)</span>, whose entry <span class="math notranslate nohighlight">\(c_v\)</span> is
the weight of the edge <span class="math notranslate nohighlight">\((v,v')\)</span> chosen in <span class="math notranslate nohighlight">\(v\)</span> by the
profile.   We can then write the fixed point equation
as</p>
<div class="math notranslate nohighlight">
\[\vec x = (1-\lambda) \vec c + \lambda Q \vec x\,.\]</div>
<p>Letting
<span class="math notranslate nohighlight">\(\lambda = a/b\)</span> the rational discount factor, the above equation
rewrites into ```{math}
:label: 4-eq:1
A\vec x = (b-a)\vec
c</p>
<div class="highlight-with notranslate"><div class="highlight"><pre><span></span>  identity matrix). Therefore, $A$ is a matrix that has at most two
  non-zero elements in each row: each of these non-zero elements can
  be written using at most $N=\max(\log_2 a,\log_2 b)$ bits (therefore
  polynomial in the representation of the game), and are therefore
  bounded in absolute value by $2^N$. By induction on the size of the
  matrix, we can then show that the determinant of $A$ is at most
  $4^{Nn}$. {eq}`4-eq:1`\todo{Ne s&#39;affiche pas dans la version html} then resolves, using Cramer&#39;s formula, by
  $x_v = \det (A_v) / \det (A)$, with $A_v$ the matrix obtained from
  $A$ by replacing the $v$-th column with vector $(b-a)\vec
  c$. Therefore, all components of $\vec x$ can be written with only a
  polynomial of bits with respect to the size of the costs in the
  arena and $N$.

  The $\textrm{coUP}$ membership follows, as in  {prf:ref}`4-thm:MP-NPcoNP`, from a
  dual reasoning for Adam, using the above determinacy result for
  discounted payoff games. 
</pre></div>
</div>
</div>
<p>For the discounted payoff game of <a class="reference internal" href="mean_payoff.html#fig-mp"><span class="std std-numref">Fig. 34</span></a>, the contracting
operator is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}F\left(
  \begin{array}{c}
    x_{v_0}\\x_{v_1}\\x_{v_2}\\x_{v_3}\\x_{v_4}
  \end{array}\right) =
  \left(
    \begin{array}{c}
      \max\big(4(1-\lambda)+\lambda x_{v_1}, (1-\lambda)5+\lambda x_{v_4}\big)\\
      \min\big(\lambda x_{v_0}, 2(1-\lambda)+\lambda x_{v_2}\big)\\
      \max\big((1-\lambda)+\lambda x_{v_2}, 4(1-\lambda)+\lambda x_{v_3}\big)\\
      \min\big(-2(1-\lambda)+\lambda x_{v_0}, -(1-\lambda)+\lambda x_{v_1}\big)\\
      \min\big(-2(1-\lambda)+\lambda x_{v_0}, 2(1-\lambda)+\lambda x_{v_4}\big)
    \end{array}
  \right)\,.\end{split}\]</div>
<p>A careful analysis gives the fixed points for all values of
<span class="math notranslate nohighlight">\(\lambda\in (0,1)\)</span>, which in turn allows us to find the associated
positional optimal strategies <span class="math notranslate nohighlight">\(\sigma^*\)</span> and <span class="math notranslate nohighlight">\(\tau^*\)</span> on the various
intervals of values for <span class="math notranslate nohighlight">\(\lambda\)</span>, summarised in the following table:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{array}{|c|c|c|c|c|}\hline
    \lambda &amp; (0, \lambda_1]
    &amp; (\lambda_1,\lambda_2] &amp; (\lambda_2,\lambda_3]
    &amp; (\lambda_3,1) \\\hline
    \sigma^*(v_0) &amp; v_4 &amp; v_4 &amp;  v_1   &amp; v_1  \\\hline
    \tau^*(v_1) &amp; v_0 &amp;  v_0 &amp;   v_0 &amp;   v_2  \\\hline
    \sigma^*(v_2) &amp; v_3  &amp; v_3   &amp; v_3 &amp;   v_3 \\\hline
    \tau^*(v_3) &amp;v_0 &amp;  v_1  &amp; v_1 &amp;   v_1  \\\hline
    \tau^*(v_4) &amp; v_0 &amp;  v_0  &amp; v_0 &amp;  v_0\\\hline
  \end{array}\end{split}\]</div>
<p>where frontiers are at <span class="math notranslate nohighlight">\(\lambda_1 = 1-\sqrt 2/2 \approx 0.293\)</span>,
<span class="math notranslate nohighlight">\(\lambda_2 = 1/2\)</span>, and <span class="math notranslate nohighlight">\(\lambda_3 \approx 0.841\)</span>. For instance, on
interval <span class="math notranslate nohighlight">\((0,\lambda_1]\)</span>, Adam gets discounted payoff
<span class="math notranslate nohighlight">\(\frac{5\lambda-2}{1+\lambda}\)</span> when starting
in vertex <span class="math notranslate nohighlight">\(v_3\)</span>, while switching his decision in interval
<span class="math notranslate nohighlight">\((\lambda_1,\lambda_2]\)</span> allows him to secure
<span class="math notranslate nohighlight">\(\frac{-2\lambda^3+6\lambda^2-1}{1+\lambda}\)</span>: this gives the
explanation for the value of <span class="math notranslate nohighlight">\(\lambda_1\)</span> which allows one to equal the
two values. A similar reasoning provides the values of
<span class="math notranslate nohighlight">\(\lambda_2\)</span> and <span class="math notranslate nohighlight">\(\lambda_3\)</span>.</p>
</div>
<div class="section" id="strategy-improvement-algorithm">
<h2>Strategy improvement algorithm<a class="headerlink" href="#strategy-improvement-algorithm" title="Permalink to this headline">Â¶</a></h2>
<p>We apply the strategy improvement paradigm already used for
mean payoff games. However, in the context of discounted payoff games,
this algorithm will directly run on the game itself to compute optimal
values and an optimal strategy for Eve (instead of only deciding if
Eve can guarantee a positive mean payoff).</p>
<p>The principle is identical though: it relies on an amelioration of a
strategy based on a local switching policy. Starting from an arbitrary
positional strategy of Eve, we apply local improvements by switching
some decisions to obtain a strictly better positional strategy. Since
there are only a finite (but exponential) number of positional
strategies, this strategy improvement algorithm will terminate (with
at most exponential time worst-case complexity). Moreover, it is
correct, as we will see, meaning that the local optimum we find when
no more switching is applicable is indeed a global optimum for Eve,
meaning that we have computed a (positional) optimal strategy for her.</p>
<p>To describe the switching policy used to solve discounted payoff
games, consider a strategy <span class="math notranslate nohighlight">\(\sigma\)</span> of Eve, and let <span class="math notranslate nohighlight">\(\textrm{val}^\sigma(v)\)</span>
be the best possible value Adam can get against <span class="math notranslate nohighlight">\(\sigma\)</span>, when the
play starts from vertex <span class="math notranslate nohighlight">\(v\)</span>:</p>
<div class="math notranslate nohighlight">
\[\textrm{val}^\sigma(v) = \inf_\tau
   \mathtt{DiscountedPayoff}_\lambda(v,\sigma,\tau).\]</div>
<p>Two strategies <span class="math notranslate nohighlight">\(\sigma\)</span>
and <span class="math notranslate nohighlight">\(\sigma'\)</span> are compared with respect to the vectors
<span class="math notranslate nohighlight">\(\vec x= \textrm{val}^\sigma\)</span> and <span class="math notranslate nohighlight">\(\vec{x'}= \textrm{val}^{\sigma'}\)</span>: we denote by
<span class="math notranslate nohighlight">\(\vec x\leq \vec{x'}\)</span> the fact that <span class="math notranslate nohighlight">\(x_v\leq x'_v\)</span> for all vertices
<span class="math notranslate nohighlight">\(v\in V\)</span>. Computing the vector <span class="math notranslate nohighlight">\(\textrm{val}^\sigma\)</span> amounts to solving a
one-player discounted payoff game where Eveâs vertices are now
constrained to follow <span class="math notranslate nohighlight">\(\sigma\)</span>, and thus can be replaced by Adamâs
vertices. By  <a class="reference internal" href="#4-thm:discounted">Theorem 109</a>, the solution of such a
one-player game is still the unique fixed point of the contraction
mapping <span class="math notranslate nohighlight">\(F_\sigma\)</span> defined for all <span class="math notranslate nohighlight">\(\vec x\in  \mathbb{R}^V\)</span> and <span class="math notranslate nohighlight">\(v\in V\)</span> by</p>
<div class="math notranslate nohighlight">
\[F_\sigma(\vec x)_v = \min_{(v,v')\in E}[(1-\lambda)c(v,v')+\lambda x_{v'}].\]</div>
<div class="proof proposition admonition" id="4-lem:one-player-DP">
<p class="admonition-title"><span class="caption-number">Proposition 111 </span> (One player)</p>
<div class="proposition-content section" id="proof-content">
<p>We can compute in polynomial time the optimal value of a one-player
discounted payoff game, by finding the unique fixed point
<span class="math notranslate nohighlight">\(\vec{x^*}\)</span> of the previous contraction mapping <span class="math notranslate nohighlight">\(F_\sigma\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>We first show that if a vector <span class="math notranslate nohighlight">\(\vec x\)</span> satisfies
<span class="math notranslate nohighlight">\(\vec x\leq F_\sigma(\vec x)\)</span>, then <span class="math notranslate nohighlight">\(\vec x\leq \vec{x^*}\)</span>. Indeed,
consider any positional strategy <span class="math notranslate nohighlight">\(\tau\)</span> of the unique player Adam,
and a vertex <span class="math notranslate nohighlight">\(v\in V\)</span>. Then,
<span class="math notranslate nohighlight">\(x_v\leq F_\sigma(\vec x)_v\leq (1-\lambda)c(v,v')+\lambda x_{v'}\)</span> with
<span class="math notranslate nohighlight">\((v,v')=\tau(v)\)</span>. We let <span class="math notranslate nohighlight">\(\pi\)</span> be the play starting in <span class="math notranslate nohighlight">\(v\)</span>, following
<span class="math notranslate nohighlight">\(\tau\)</span>, and denote by <span class="math notranslate nohighlight">\(v=v_0,v_1,\ldots\)</span> the sequence of vertices
visited by <span class="math notranslate nohighlight">\(\pi\)</span>. By induction,
<span class="math notranslate nohighlight">\(x_v \leq (1-\lambda)\sum_{i=0}^{n-1}\lambda^i c( \pi_i) +
  \lambda^nx_{v_n}\)</span>. Letting <span class="math notranslate nohighlight">\(n\)</span> go to <span class="math notranslate nohighlight">\(+\infty\)</span>, we get that
<span class="math notranslate nohighlight">\(x_v\leq  \mathtt{DiscountedPayoff}_\lambda( \pi)\)</span>. Since this holds for all
strategies of Adam, and <span class="math notranslate nohighlight">\(\vec{x^*}\)</span> is the optimal value vector of the
game by  <a class="reference internal" href="#4-thm:discounted">Theorem 109</a>, we obtain <span class="math notranslate nohighlight">\(x_v\leq x^*_v\)</span>.</p>
<p>Therefore, it follows that <span class="math notranslate nohighlight">\(x^*\)</span> is the unique solution of the
linear program</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{cases}
      \max\sum_{v\in V}x_v \\
      \text{under the constraints }\quad x_v\leq
      (1-\lambda)c(v,v')+\lambda x_{v'}\qquad \forall (v,v')\in E
    \end{cases}\end{split}\]</div>
<p>Such a linear program can be solved in polynomial time.</p>
</div>
<p>On top of computing the value <span class="math notranslate nohighlight">\(\textrm{val}^\sigma\)</span> of a strategy <span class="math notranslate nohighlight">\(\sigma\)</span>
of Eve, we also compute the best response of Adam, that is the best
(positional) strategy <span class="math notranslate nohighlight">\(\tau\)</span> he must play to achieve the lowest payoff
possible for Eve.</p>
<p>For the discounted payoff game of <a class="reference internal" href="mean_payoff.html#fig-mp"><span class="std std-numref">Fig. 34</span></a> with <span class="math notranslate nohighlight">\(\lambda=0.5\)</span>,
if we start from Eveâs strategy <span class="math notranslate nohighlight">\(\sigma(0)=4\)</span> and <span class="math notranslate nohighlight">\(\sigma(2)=2\)</span>, the
simplified contraction mapping in the one-player remaining game is
given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}F_\sigma\left(
  \begin{array}{c}
    x_0\\x_1\\x_2\\x_3\\x_4
  \end{array}\right) =
  \left(
    \begin{array}{c}
      (1-\lambda)5+\lambda x_4\\
      \min\big(\lambda x_0, 2(1-\lambda)+\lambda x_2\big)\\
      (1-\lambda)+\lambda x_2\\
      \min\big(-2(1-\lambda)+\lambda x_0, -(1-\lambda)+\lambda x_1\big)\\
      \min\big(-2(1-\lambda)+\lambda x_0, 2(1-\lambda)+\lambda x_4\big)
    \end{array}
  \right)\,.\end{split}\]</div>
<p>We compute the best response of Adam by solving the
linear program:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}
    \max x_0+x_1+x_2+x_3+x_4 \\
    \text{under the constraints } &amp; x_0=(1-\lambda)5+\lambda
    x_4 \\
    &amp; x_1\leq \lambda x_0 \\
    &amp; x_1\leq 2(1-\lambda)+\lambda x_2\\
    &amp; x_2 = (1-\lambda)+\lambda x_2 \qquad (\text{thus } x_2=1) \\
    &amp; x_3\leq -2(1-\lambda)+\lambda x_0\\
    &amp; x_3 \leq -(1-\lambda)+\lambda x_1 \\
    &amp; x_4\leq -2(1-\lambda)+\lambda x_0\\
    &amp; x_4\leq 2(1-\lambda)+\lambda x_4
  \end{cases}\end{split}\]</div>
<p>Feeding this linear program to a solver gives back the
solution <span class="math notranslate nohighlight">\(\vec x=(8/3,4/3,1,1/6,\allowbreak 1/3)\)</span>, which is associated
with the best response of Adam defined as <span class="math notranslate nohighlight">\(\tau(1)=0\)</span>, <span class="math notranslate nohighlight">\(\tau(3)=1\)</span>,
and <span class="math notranslate nohighlight">\(\tau(4)=0\)</span>. We can check if this vector <span class="math notranslate nohighlight">\(\vec x\)</span> is a fixed point
of <span class="math notranslate nohighlight">\(F\)</span> (and not only <span class="math notranslate nohighlight">\(F_\sigma\)</span>): we indeed have
<span class="math notranslate nohighlight">\(F(\vec x)_0=\max\big(4(1-\lambda)+\lambda x_1, (1-\lambda)5+\lambda
x_4\big)= \max(8/3,8/3)= 8/3\)</span>, but
<span class="math notranslate nohighlight">\(F(\vec x)_2=\max\big((1-\lambda)+\lambda x_2, 4(1-\lambda)+\lambda
x_3\big) = \max(1,25/12)=25/12\neq 1\)</span>. This suggests modifying
strategy <span class="math notranslate nohighlight">\(\sigma\)</span> to a new strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> with <span class="math notranslate nohighlight">\(\sigma'(0)=4\)</span> and
<span class="math notranslate nohighlight">\(\sigma'(2)=3\)</span>. The new vector of values found by solving the new
linear program is <span class="math notranslate nohighlight">\(\vec{x'}=(8/3,4/3,25/12,1/6,1/3)\)</span>, that is the
(unique) fixed point of <span class="math notranslate nohighlight">\(F\)</span>. Notice in particular that
<span class="math notranslate nohighlight">\(\vec{x}\leq \vec{x'}\)</span> with a strict inequality on the component of
vertex <span class="math notranslate nohighlight">\(2\)</span>.</p>
<p>\medskip</p>
<p>We now come back to the general case by describing more precisely the
algorithm in <a class="reference internal" href="#algo-dp-strategy-improvement"><span class="std std-numref">Fig. 38</span></a>, and prove its
correctness.  For a particular strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve, once
<span class="math notranslate nohighlight">\(\textrm{val}^\sigma\)</span> computed, we can check whether
<span class="math notranslate nohighlight">\(F( \textrm{val}^\sigma)= \textrm{val}^\sigma\)</span> (with <span class="math notranslate nohighlight">\(F\)</span> the more general operator
defined in <a class="reference internal" href="#equation-4-eq-f-contraction">(3)</a>). If it is the case, then we
know that the optimal value vector of the game is indeed
<span class="math notranslate nohighlight">\(\textrm{val}^\sigma\)</span>: thus, <span class="math notranslate nohighlight">\(\sigma\)</span> is a positional optimal strategy for
Eve, and the best response of Adam is a positional optimal strategy
for him. In case <span class="math notranslate nohighlight">\(F( \textrm{val}^\sigma)\neq \textrm{val}^\sigma\)</span>, we consider for
every vertex <span class="math notranslate nohighlight">\(v\in  V_\mathrm{Eve}\)</span>, the decision <span class="math notranslate nohighlight">\(v'\)</span> such that
<span class="math notranslate nohighlight">\(F( \textrm{val}^\sigma)_v=(1-\lambda)c(v,v')+\lambda  \textrm{val}^\sigma(v')\)</span>. We
gather all these decisions in a new strategy <span class="math notranslate nohighlight">\(\sigma'\)</span> for Eve (only
modifying <span class="math notranslate nohighlight">\(\sigma\)</span> over vertices for which it allows for a strictly
better value, to ensure the termination of the algorithm).</p>
<div class="figure align-center" id="algo-dp-strategy-improvement">
<img alt="../_images/4-algo:DP-strategy-improvement.png" src="../_images/4-algo:DP-strategy-improvement.png" />
<p class="caption"><span class="caption-number">Fig. 38 </span><span class="caption-text">The strategy improvement algorithm for discounted payoff games.</span><a class="headerlink" href="#algo-dp-strategy-improvement" title="Permalink to this image">Â¶</a></p>
</div>
<div class="proof theorem admonition" id="4-thm:DP-strategy-improvement-correctness">
<p class="admonition-title"><span class="caption-number">Theorem 112 </span> (Strategy improvement)</p>
<div class="theorem-content section" id="proof-content">
<p>Strategy improvement algorithm computes the value of the game, as
well as a positional optimal strategy for Eve, in exponential time.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>When the algorithm returns a strategy <span class="math notranslate nohighlight">\(\sigma\)</span>, it fulfils
<span class="math notranslate nohighlight">\(F( \textrm{val}^\sigma)\neq  \textrm{val}^\sigma\)</span>, and thus,
by  <a class="reference internal" href="#4-thm:disc-up">Theorem 110</a>, <span class="math notranslate nohighlight">\(\textrm{val}^\sigma\)</span> is the value of the game,
and <span class="math notranslate nohighlight">\(\sigma\)</span> an optimal strategy of Eve.</p>
<p>We thus only have to prove the termination of the algorithm, as well
as its complexity. Consider the positional strategy <span class="math notranslate nohighlight">\(\sigma\)</span> in the
beginning of an iteration such that
<span class="math notranslate nohighlight">\(F( \textrm{val}^\sigma)\neq  \textrm{val}^\sigma\)</span>, as well as the strategy
<span class="math notranslate nohighlight">\(\sigma'\)</span> updated at the end of the same iteration. We see why
<span class="math notranslate nohighlight">\(\textrm{val}^\sigma\leq  \textrm{val}^{\sigma'}\)</span>, with a strict inequality for
at least one of the coefficients. If it is correct, then it shows
that the <strong>while</strong> loop terminates after a finite number of
iterations, since there are only a finite number of positional
strategies and that we cannot visit twice the same one.  More
precisely, the algorithm has an exponential worst-case complexity,
since it may have to go through all (or at least a large fraction
of) the positional strategies.</p>
<p>We thus prove that <span class="math notranslate nohighlight">\(\textrm{val}^\sigma\leq  \textrm{val}^{\sigma'}\)</span>. Consider
for that the two best responses of Adam, <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\tau'\)</span>
respectively. As in the proof of  <a class="reference internal" href="#4-thm:disc-up">Theorem 110</a>, letting <span class="math notranslate nohighlight">\(Q\)</span>,
<span class="math notranslate nohighlight">\(\vec c\)</span>, <span class="math notranslate nohighlight">\(Q'\)</span>, and <span class="math notranslate nohighlight">\(\vec {c'}\)</span> the respective matrices and cost
vectors described by the profiles of strategies <span class="math notranslate nohighlight">\((\sigma,\tau)\)</span> and
<span class="math notranslate nohighlight">\((\sigma',\tau')\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\textrm{val}^\sigma = (1-\lambda) \vec c + \lambda Q  \textrm{val}^\sigma \qquad
    \text{ and } \qquad  \textrm{val}^{\sigma'} = (1-\lambda) \vec {c'} +
    \lambda Q'  \textrm{val}^{\sigma'}\,.\]</div>
<p>Therefore, by adding and subtracting <span class="math notranslate nohighlight">\(\lambda Q'
   \textrm{val}^\sigma\)</span> we obtain:</p>
<div class="math notranslate nohighlight">
\[\textrm{val}^{\sigma'}- \textrm{val}^\sigma=\lambda Q'
    ( \textrm{val}^{\sigma'}- \textrm{val}^{\sigma}) + \underbrace{\lambda
      (Q'-Q) \textrm{val}^\sigma + (1-\lambda)(\vec{c'}-\vec c)}_{=\vec
      \delta}\,.\]</div>
<p>Since <span class="math notranslate nohighlight">\(Q'\)</span> is a positive matrix with coefficients in
<span class="math notranslate nohighlight">\(\{0,1\}\)</span>, the series <span class="math notranslate nohighlight">\(\sum_i \lambda^iQ'^i\)</span> converges, which shows
that <span class="math notranslate nohighlight">\(I-\lambda Q'\)</span> is invertible of inverse
<span class="math notranslate nohighlight">\(\sum_{i=0}^\infty \lambda^i Q'^i\)</span>. In particular, the inverse
<span class="math notranslate nohighlight">\((I-\lambda Q')^{-1}\)</span> has only non negative coefficients, and its
diagonal coefficients are positive. Therefore, to show that
<span class="math notranslate nohighlight">\(\textrm{val}^{\sigma'}- \textrm{val}^\sigma=(I-\lambda Q')^{-1} \vec\delta\)</span> is
non-negative with at least one positive coefficient, it suffices to
show that <span class="math notranslate nohighlight">\(\vec\delta\)</span> is non-negative with at least one positive
coefficient. Consider thus <span class="math notranslate nohighlight">\(v\in V\)</span>:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(v\in  V_\mathrm{Eve}\)</span>, we have
<span class="math notranslate nohighlight">\(\delta_v=\lambda( \textrm{val}^{\sigma}(v'_1)- \textrm{val}^\sigma(v_1)) +
(1-\lambda)(c(v,v'_1)-c(v,v_1))\)</span>, with
<span class="math notranslate nohighlight">\(\sigma(v)=(v,v_1)\)</span> and <span class="math notranslate nohighlight">\(\sigma'(v)=(v,v'_1)\)</span>. If <span class="math notranslate nohighlight">\(v_1=v'_1\)</span>, then
<span class="math notranslate nohighlight">\(\delta_v=0\)</span>. Otherwise, since <span class="math notranslate nohighlight">\(\sigma'\)</span> is obtained by switching
the decisions according to <span class="math notranslate nohighlight">\(F\)</span>, we have <span class="math notranslate nohighlight">\(\delta_v&gt;0\)</span>: notice that
there exists at least one such vertex <span class="math notranslate nohighlight">\(v\)</span>, since otherwise,
<span class="math notranslate nohighlight">\(\sigma'=\sigma\)</span> and the algorithm has already terminated.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(v\in  V_\mathrm{Adam}\)</span>, we have the same formula for <span class="math notranslate nohighlight">\(\delta_v\)</span> with
<span class="math notranslate nohighlight">\(\tau(v)=(v,v_1)\)</span> and <span class="math notranslate nohighlight">\(\tau'(v)=(v,v'_1)\)</span>. Once again, <span class="math notranslate nohighlight">\(\delta_v=0\)</span>
if <span class="math notranslate nohighlight">\(v_1=v'_1\)</span>. Otherwise, since <span class="math notranslate nohighlight">\(\tau\)</span> is the best response of Adam
to the strategy <span class="math notranslate nohighlight">\(\sigma\)</span> of Eve, <span class="math notranslate nohighlight">\(\tau\)</span> is at least as good as
<span class="math notranslate nohighlight">\(\tau'\)</span>, which means that <span class="math notranslate nohighlight">\(\delta_v\geq 0\)</span> too.</p></li>
</ul>
</div>
<p>We now study another algorithm to compute the values with a possibly
better worst-case complexity, trading an exponential (with respect to
the number of vertices) complexity (but polynomial with respect to the
binary encoding of <span class="math notranslate nohighlight">\(\lambda\)</span> and the weights of the arena), for a
pseudopolynomial time complexity (polynomial with respect to the
number of vertices and the binary encoding of the weights of the
arena, but exponential with respect to the binary encoding of
<span class="math notranslate nohighlight">\(\lambda\)</span>).</p>
</div>
<div class="section" id="value-iteration-algorithm">
<h2>Value iteration algorithm<a class="headerlink" href="#value-iteration-algorithm" title="Permalink to this headline">Â¶</a></h2>
<p>Another way to make use of the contraction mapping <span class="math notranslate nohighlight">\(F\)</span>
of <a class="reference internal" href="#equation-4-eq-f-contraction">(3)</a> is to compute the sequence
<span class="math notranslate nohighlight">\(\big(F^n(\vec 0)\big)_{n\in  \mathbb{N}}\)</span> that converges towards the value
vector. However, the sequence is not stationary in general, and thus,
to obtain an exact value we find a index <span class="math notranslate nohighlight">\(K\)</span> for which <span class="math notranslate nohighlight">\(F^K(\vec 0)\)</span>
is close to <span class="math notranslate nohighlight">\(\textrm{val}\)</span>, as well as a rounding procedure to get the exact
value <span class="math notranslate nohighlight">\(\textrm{val}\)</span> from its approximation <span class="math notranslate nohighlight">\(F^K(\vec 0)\)</span>. It is mainly
based on the following technical lemma stating that <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> is a
rational number with a denominator that we can bound, in a similar
manner as for \cref{4-cor:rational-MP} in the mean payoff setting:</p>
<div class="proof lemma admonition" id="4-lem:rational-discounted">
<p class="admonition-title"><span class="caption-number">Lemma 113 </span> (Upper bound on rational values in mean payoff games)</p>
<div class="lemma-content section" id="proof-content">
<p>If the arena has integer costs and <span class="math notranslate nohighlight">\(\lambda=\frac a b\in (0,1)\)</span>,
then for all vertices <span class="math notranslate nohighlight">\(v\in V\)</span>, <span class="math notranslate nohighlight">\(D\times  \textrm{val}(v)\in  \mathbb{Z}\)</span>, with
<span class="math notranslate nohighlight">\(D= b^{n-1}\prod_{j=1}^{n}(b^j-a^j)\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>By picking any two optimal positional strategies for Eve and Adam
(by  <a class="reference internal" href="#4-thm:discounted">Theorem 109</a>), we obtain a play <span class="math notranslate nohighlight">\(\pi\)</span> starting in
vertex <span class="math notranslate nohighlight">\(v\in V\)</span> that has a discounted payoff
<span class="math notranslate nohighlight">\(\mathtt{DiscountedPayoff}(\pi) =  \textrm{val}(v)\)</span>. Since both strategies are
positional, the play <span class="math notranslate nohighlight">\(\pi\)</span> is a lasso: thus, the sequence of costs
encountered through the play is of the form
<span class="math notranslate nohighlight">\(w_0,w_1,\ldots,w_{k-1},(w_{k},\ldots,w_\ell)^\omega\)</span>, with
<span class="math notranslate nohighlight">\(0\leq k\leq\ell&lt; n\)</span> and <span class="math notranslate nohighlight">\(w_i\in  \mathbb{Z}\)</span>. We can thus compute the
optimal value exactly:\todo{Ãa ne passe pas dans la version
htmlâ¦ pourquoi ?}</p>
<div class="math notranslate nohighlight">
\[\begin{split}   \textrm{val}(v) &amp;= (1-\lambda) \left[\sum_{i=0}^{k-1} \lambda^i w_i +
             \lambda^{k}\sum_{m=0}^\infty
             \lambda^{(\ell-k+1)m}\sum_{i=0}^{\ell-k}
             \lambda^iw_{k+i}\right]\\
           &amp;= \frac{b-a}b \left[\sum_{i=0}^{k-1} \frac{b^{k-1-i}a^i w_i}{b^{k-1}} +
             \frac{\lambda^{k}}{1-\lambda^{\ell-k+1}}\sum_{i=0}^{\ell-k}
             \frac{b^{\ell-k-i}a^iw_{k+i}}{b^{\ell-k}}\right]\\
           &amp;= \frac {N_1}{b^{k}} + 
             \frac{a^{k}b^{\ell-k+1}}{b^{k+1}(b^{\ell-k+1}-a^{\ell-k+1})}
             \frac{N_2}{b^{\ell-k}} \qquad \text{(with $N_1,N_2\in  \mathbb{Z}$)}\\
           &amp;= \frac{N_3}{b^{k}(b^{\ell-k+1}-a^{\ell-k+1})} \qquad \text{(with
             $N_3\in  \mathbb{Z}$)}\\
           &amp;= \frac{N}{b^{n-1}\prod_{j=1}^{n}(b^j-a^j)} \qquad \text{(with
             $N\in  \mathbb{Z}$)} 
\end{split}\]</div>
<p>which proves that <span class="math notranslate nohighlight">\(\textrm{val}(v)\times D = N\in  \mathbb{Z}\)</span>.</p>
</div>
<p>Therefore, <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> is a rational number with a denominator bounded
by <span class="math notranslate nohighlight">\(D\)</span>. In particular, if we have an approximation <span class="math notranslate nohighlight">\(\eta\)</span> of
<span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> such that <span class="math notranslate nohighlight">\(| \textrm{val}(v)-\eta|&lt;\frac 1 {2D}\)</span>, we get that
<span class="math notranslate nohighlight">\(\textrm{val}(v) = \frac{\lfloor D\eta+1/2\rfloor}D\)</span>. Using the fact that
operator <span class="math notranslate nohighlight">\(F\)</span> is contracting, we can find an index <span class="math notranslate nohighlight">\(K\)</span> after which this
rounding leads to the correct optimal value vector. In the following,
we let again <span class="math notranslate nohighlight">\(W = \max_{(v,c,v')\in E} |c|\)</span> the maximal weight on edges of the arena, in
absolute values.</p>
<div class="proof lemma admonition" id="4-lem:number-steps-VI-discounted">
<p class="admonition-title"><span class="caption-number">Lemma 114 </span> (Number of steps of value iteration)</p>
<div class="lemma-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(K\in  \mathbb{N}\)</span> at most
<span class="math notranslate nohighlight">\(\frac{1}{-\log_2\lambda} \left(\frac{n(n+3)}{2}\log_2b +
    \log_2 W+2\right)\)</span>. Then,
<span class="math notranslate nohighlight">\(\|F^K(\vec 0)- \textrm{val}\|_\infty &lt; \frac 1 {2D}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>First, we bound <span class="math notranslate nohighlight">\(D\)</span> by <span class="math notranslate nohighlight">\(b^{n+\frac{n(n+1)}2}\)</span>, so that
<span class="math notranslate nohighlight">\(\frac{n(n+3)}{2}\log_2b\geq \log_2D\)</span>. Therefore
<span class="math notranslate nohighlight">\(K\geq \frac{1}{-\log_2\lambda} (\log_2D + \log_2 W+\log_24) =
  \log_{1/\lambda}(4DW)\)</span>. This implies that
<span class="math notranslate nohighlight">\(\lambda^KW\leq \frac{1}{4D}&lt; \frac 1 {2D}\)</span>. But <span class="math notranslate nohighlight">\(F\)</span> is
<span class="math notranslate nohighlight">\(\lambda\)</span>-contracting, so that
<span class="math notranslate nohighlight">\(\|F^K(\vec 0)- \textrm{val}\|_\infty\leq
  \lambda^K\| \textrm{val}\|_\infty\)</span>. Since <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> is the discounted sum
of weights all bounded in absolute value by <span class="math notranslate nohighlight">\(W\)</span>, we also know that
<span class="math notranslate nohighlight">\(\| \textrm{val}\|_\infty\leq W\)</span> which allows us to conclude.</p>
</div>
<p>Therefore, the value iteration algoritm consists at iterating the
contracting mapping <span class="math notranslate nohighlight">\(F\)</span> for a certain number <span class="math notranslate nohighlight">\(K\)</span> of steps which is
polynomial with respect to the arena, each of the steps being
performed in time <span class="math notranslate nohighlight">\(O(m)\)</span>, and then finish the computation by a
rounding procedure (see <a class="reference internal" href="#algo-dp-value-iteration"><span class="std std-numref">Fig. 39</span></a>). In the
overall, it thus has complexity <span class="math notranslate nohighlight">\(O(K m)\)</span>.</p>
<div class="figure align-center" id="algo-dp-value-iteration">
<img alt="../_images/4-algo:DP-value-iteration.png" src="../_images/4-algo:DP-value-iteration.png" />
<p class="caption"><span class="caption-number">Fig. 39 </span><span class="caption-text">The value iteration algorithm for discounted payoff games.</span><a class="headerlink" href="#algo-dp-value-iteration" title="Permalink to this image">Â¶</a></p>
</div>
<div class="proof theorem admonition" id="4-thm:DP-value-iteration">
<p class="admonition-title"><span class="caption-number">Theorem 115 </span> (Correctness and complexity of value iteration)</p>
<div class="theorem-content section" id="proof-content">
<p>Value iteration algorithm computes in pseudopolynomial time the
value vector of a given discounted payoff game with only rational
weights and a rational discount factor <span class="math notranslate nohighlight">\(\lambda\in (0,1)\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The correctness of the algorithm follows
from  <a class="reference internal" href="#4-lem:number-steps-VI-discounted">Lemma 114</a>.  This algorithm runs
in pseudopolynomial time (and not polynomial-time) because of the
dependence in the discount factor <span class="math notranslate nohighlight">\(\lambda\)</span>. Indeed, consider that
<span class="math notranslate nohighlight">\(\lambda = 1-\frac 1 b\)</span>, with <span class="math notranslate nohighlight">\(b\in  \mathbb{N}\setminus \{0\}\)</span>. Then, we may
store <span class="math notranslate nohighlight">\(\lambda\)</span> with <span class="math notranslate nohighlight">\(\log_2 b\)</span> bits, yet
<span class="math notranslate nohighlight">\(\frac 1{-\log_2\lambda} \sim_{b\to \infty} b\ln 2\)</span> is exponential
in <span class="math notranslate nohighlight">\(\log_2b\)</span>.</p>
</div>
<p>Once the optimal values are known, finding some positional optimal
strategies for both players still requires to work, as we have already
seen in Section <a class="reference internal" href="../1_Introduction/memory.html#sec-memory"><span class="std std-ref">Memory</span></a>:</p>
<div class="proof theorem admonition" id="4-thm:DP-strategies">
<p class="admonition-title"><span class="caption-number">Theorem 116 </span> (Optimal strategies)</p>
<div class="theorem-content section" id="proof-content">
<p>In a discounted payoff game with integer costs and rational discount
factor <span class="math notranslate nohighlight">\(\lambda = a/b\)</span>, optimal strategies for both players can be
found in
<span class="math notranslate nohighlight">\(O\big((n^3b\log_2b + \log_2W)\allowbreak
  \log(m/n) m\big)\)</span> time.</p>
</div>
</div></div>
<div class="section" id="polynomial-reduction-from-mean-payoff-games-to-discounted-payoff-games">
<span id="sec-mean-payoff-values"></span><h2>Polynomial reduction from mean payoff games to discounted payoff games<a class="headerlink" href="#polynomial-reduction-from-mean-payoff-games-to-discounted-payoff-games" title="Permalink to this headline">Â¶</a></h2>
<p>Building upon the pseudopolynomial time algorithm for
discounted payoff, we now describe a classical encoding of mean payoff
games into discounted payoff games to obtain another algorithm with
pseudopolynomial time complexity for mean payoff games. Compared to
the algorithms studied before that were computing the values of a
mean payoff game by a binary search, this other algorithm (indeed the
oldest one) is more direct even if it does not obtain a better
complexity.</p>
<p>Recall that \cref{4-cor:rational-MP} states that, in an arena where
costs are integers, the mean payoff value <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> is a rational
number with denominator in <span class="math notranslate nohighlight">\(\{1,\ldots,n\}\)</span>. The minimal distance
between two rational numbers <span class="math notranslate nohighlight">\(\frac \alpha k\)</span> and <span class="math notranslate nohighlight">\(\frac{\alpha'}{k'}\)</span>
with <span class="math notranslate nohighlight">\(k,k'\in \{1,\ldots,n\}\)</span> is
<span class="math notranslate nohighlight">\(\frac 1{n-1}-\frac 1{n}=\frac{1}{n(n-1)}\)</span>. Thus, a
<span class="math notranslate nohighlight">\(\frac{1}{2n(n-1)}\)</span> approximation <span class="math notranslate nohighlight">\(\beta\)</span> of <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> is enough
to apply a rounding procedure finding the only rational
<span class="math notranslate nohighlight">\(\frac \alpha k\)</span> with <span class="math notranslate nohighlight">\(k\in \{1,\ldots,n\}\)</span> in interval
<span class="math notranslate nohighlight">\([\beta-\frac{1}{2n(n-1)}, \beta+\frac{1}{2n(n-1)}]\)</span>. By
interpreting the mean payoff game as a discounted payoff game with a
nicely chosen <span class="math notranslate nohighlight">\(\lambda\)</span>, we are able to find such a good
approximation:</p>
<div class="proof theorem admonition" id="4-thm:MP-Zwick-Paterson">
<p class="admonition-title"><span class="caption-number">Theorem 117 </span> (Discounted payoff approximation)</p>
<div class="theorem-content section" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> be an arena with integer costs. Let
<span class="math notranslate nohighlight">\(\lambda\in(0,1)\)</span>. We let <span class="math notranslate nohighlight">\(\textrm{val}(v)\)</span> be the value of vertex <span class="math notranslate nohighlight">\(v\)</span> in
the mean payoff game on <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, and <span class="math notranslate nohighlight">\(\textrm{val}_\lambda(v)\)</span> be the
value of vertex <span class="math notranslate nohighlight">\(v\)</span> in the discounted payoff game on <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, with
<span class="math notranslate nohighlight">\(\lambda\)</span> as discount factor. Then
<span class="math notranslate nohighlight">\(\| \textrm{val}- \textrm{val}_\lambda\|_\infty\leq 2n(1-\lambda)W\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>Let <span class="math notranslate nohighlight">\(v\in V\)</span>. We prove the inequality
<span class="math notranslate nohighlight">\(\textrm{val}_\lambda(v)- \textrm{val}(v)\geq -2n(1-\lambda)W\)</span> by reasoning on
Eveâs strategies: a similar reasoning on Adamâs strategies allows
one to obtain the other inequality
<span class="math notranslate nohighlight">\(\textrm{val}_\lambda(v)- \textrm{val}(v)\leq 2n(1-\lambda)W\)</span>.</p>
<p>By  <a class="reference internal" href="mean_payoff.html#4-thm:mean_payoff_positional">Theorem 92</a>, we may select positional optimal
strategies for Eve and Adam in the mean payoff game, denoted by
<span class="math notranslate nohighlight">\(\sigma^*\)</span> and <span class="math notranslate nohighlight">\(\tau^*\)</span> respectively. As we have already seen, the play
<span class="math notranslate nohighlight">\(\pi\)</span> starting in <span class="math notranslate nohighlight">\(v\)</span> following <span class="math notranslate nohighlight">\(\sigma^*\)</span> and <span class="math notranslate nohighlight">\(\tau^*\)</span> is then a
lasso, with a sequence of costs encountered of the form
<span class="math notranslate nohighlight">\(w_0,w_1,\ldots,w_{k-1},(w_k,\ldots,w_\ell)^\omega\)</span> with
<span class="math notranslate nohighlight">\(0\leq k\leq \ell&lt;n\)</span>. Then,
<span class="math notranslate nohighlight">\(\textrm{val}(v)=\frac 1 {\ell-k+1}\sum_{i=k}^\ell w_i\)</span>. By choosing the
same strategy <span class="math notranslate nohighlight">\(\sigma\)</span> for Eve in the discounted payoff game, we
know that Eveâs value is at least
<span class="math notranslate nohighlight">\(\mathtt{DiscountedPayoff}_\lambda( \pi)\)</span>: therefore, by the determinacy
result of  <a class="reference internal" href="#4-thm:discounted">Theorem 109</a>,
<span class="math notranslate nohighlight">\(\textrm{val}_\lambda(v)\geq  \mathtt{DiscountedPayoff}_\lambda( \pi)\)</span>. We now
compute precisely <span class="math notranslate nohighlight">\(\mathtt{DiscountedPayoff}_\lambda( \pi)\)</span>:\todo{Ne
fonctionne pas en HTML}</p>
<div class="math notranslate nohighlight" id="equation-4-eq-1">
<span class="eqno">(4)<a class="headerlink" href="#equation-4-eq-1" title="Permalink to this equation">Â¶</a></span>\[\begin{split}   \mathtt{DiscountedPayoff}_\lambda( \pi)
  &amp;=
    (1-\lambda)\sum_{i=0}^{k-1}\lambda^i
    \underbrace{w_i}_{\makebox[0pt][c]{\scriptsize$\geq -W$}}
    +
    (1-\lambda)\lambda^k\sum_{m=0}^\infty
    \lambda^{(\ell-k+1)m} \sum_{i=0}^{\ell-k}\lambda^iw_{k+i}\\
  &amp; \geq -(1-\lambda^k)W +
    \frac{(1-\lambda) \lambda^k}{1-\lambda^{\ell-k+1}}
    \sum_{i=0}^{\ell-k}\lambda^iw_{k+i} \tag*{
}\end{split}\]</div>
<p>By shifting all weights by <span class="math notranslate nohighlight">\(W\)</span>, we can rewrite the remaining
sum as:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=0}^{\ell-k}\lambda^iw_{k+i} =
    \sum_{i=0}^{\ell-k}\lambda^i(w_{k+i}+W) -
    W\sum_{i=0}^{\ell-k}\lambda^i\]</div>
<p>By using the fact that <span class="math notranslate nohighlight">\(w_{k+i}+W\)</span> is non-negative and
<span class="math notranslate nohighlight">\(\lambda^i\geq \lambda^{\ell-k}\)</span>, we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}  \sum_{i=0}^{\ell-k}\lambda^iw_{k+i}
  &amp;\geq \lambda^{\ell-k}
    \sum_{i=0}^{\ell-k}(w_{k+i}+W) -W
    \frac{1-\lambda^{\ell-k+1}}{1-\lambda} \\
  &amp;= \lambda^{\ell-k}
    \sum_{i=0}^{\ell-k}w_{k+i} + (\ell-k+1)\lambda^{\ell-k}W
    -W \frac{1-\lambda^{\ell-k+1}}{1-\lambda}
\end{split}\]</div>
<p>Therefore, since <span class="math notranslate nohighlight">\(\textrm{val}(v)=\frac 1 {\ell-k+1}\sum_{i=k}^\ell w_i\)</span>,
we obtain</p>
<div class="math notranslate nohighlight">
\[\sum_{i=0}^{\ell-k}\lambda^iw_{k+i}\geq
    \lambda^{\ell-k}(\ell-k+1)( \textrm{val}(v)+W)-
    W\frac{1-\lambda^{\ell-k+1}}{1-\lambda} \,.\]</div>
<p>Simplifying <a class="reference internal" href="#equation-4-eq-1">(4)</a> gives:</p>
<div class="math notranslate nohighlight">
\[\mathtt{DiscountedPayoff}_\lambda( \pi)
    \geq -W+ \frac{(1-\lambda)(\ell-k+1)}{1-\lambda^{\ell-k+1}}
    \lambda^\ell ( \textrm{val}(v) + W)\]</div>
<p>Since
<span class="math notranslate nohighlight">\(\frac {1-\lambda^{\ell-k+1}}{1-\lambda} =
  \sum_{i=0}^{\ell-k}\lambda^i &lt; \ell-k+1\)</span>, and <span class="math notranslate nohighlight">\(\textrm{val}(v) + W\geq 0\)</span>
(the mean payoff is an average of costs of the arena, so it is in
the interval <span class="math notranslate nohighlight">\([-W,W]\)</span>), we have</p>
<div class="math notranslate nohighlight">
\[\mathtt{DiscountedPayoff}_\lambda( \pi)
    \geq -W + \lambda^\ell ( \textrm{val}(v) + W)\]</div>
<p>Finally, notice that
<span class="math notranslate nohighlight">\(\ell\leq n\)</span>, so that
<span class="math notranslate nohighlight">\(\lambda^\ell\geq \lambda^{n}&gt;(1-n(1-\lambda))\)</span>, using the fact
that
<span class="math notranslate nohighlight">\(\frac{1-\lambda^{n}}{1-\lambda} = \sum_{i=0}^{n-1}\lambda^i &lt;
  n\)</span>. Therefore,</p>
<div class="math notranslate nohighlight">
\[\begin{split}   \mathtt{DiscountedPayoff}_\lambda( \pi)
  &amp;\geq -W + (1-n(1-\lambda)) ( \textrm{val}(v) + W)\\
  &amp;= -n(1-\lambda)(W+ \textrm{val}(v)) +  \textrm{val}(v)\\
  &amp;\geq -2n(1-\lambda)W +  \textrm{val}(v)
\end{split}\]</div>
<p>by using again <span class="math notranslate nohighlight">\(\textrm{val}(v)\leq W\)</span>. We obtain</p>
<div class="math notranslate nohighlight">
\[\textrm{val}_\lambda(v)- \textrm{val}(v)\geq -2n(1-\lambda)W\]</div>
<p>as wanted, which allows us to conclude.</p>
</div>
<p>Therefore, by picking <span class="math notranslate nohighlight">\(\lambda = 1-\frac 1{4n^2(n-1)W}\)</span>, we may
obtain a good enough approximation of the mean payoff optimal value,
by solving the associated discounted payoff game. From a complexity
point of view, this value iteration algorithm runs in polynomial time
with respect to the arena, but exponential with respect to the
representation of <span class="math notranslate nohighlight">\(\lambda\)</span>: here, it is therefore polynomial in
<span class="math notranslate nohighlight">\(4n^2(n-1)W\)</span> which leads to a pseudopolynomial complexity to solve
mean payoff games. More precisely,</p>
<div class="proof theorem admonition" id="4-thm:MP-direct-value-iteration">
<p class="admonition-title"><span class="caption-number">Theorem 118 </span> (Direct value iteration)</p>
<div class="theorem-content section" id="proof-content">
<p>The direct value iteration algorithm computes the values of a
mean payoff game in complexity <span class="math notranslate nohighlight">\(O(mn^3W)\)</span>.</p>
</div>
</div><p>As for discounted payoff game, a binary search also
permits to obtain optimal positional strategies for both players in
<span class="math notranslate nohighlight">\(O\big(n^4m\log(m/n)W\big)\)</span> time.</p>
<p>Notice that the previous encoding implies a better theoretical
complexity for mean payoff and parity games, that what we obtained
before:</p>
<div class="proof corollary admonition" id="4-col:UP">
<p class="admonition-title"><span class="caption-number">Corollary 119 </span> (Complexity)</p>
<div class="corollary-content section" id="proof-content">
<p>Deciding the winner (with respect to a threshold) for mean payoff
games, and deciding the winner for parity games, can be done in
<span class="math notranslate nohighlight">\(\textrm{UP}\cap \textrm{coUP}\)</span>.</p>
</div>
</div><div class="dropdown tip admonition">
<p class="admonition-title">Proof</p>
<p>The previous polynomial-time reduction from mean payoff to
discounted payoff games allows to lift the <span class="math notranslate nohighlight">\(\textrm{UP}\cap \textrm{coUP}\)</span> complexity
of  <a class="reference internal" href="#4-thm:disc-up">Theorem 110</a>. Moreover, the polynomial-time reduction
of  <a class="reference internal" href="mean_payoff.html#4-thm:parity2MP">Theorem 96</a> allows one to obtain the same complexity for
parity games.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./4_Payoffs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="mean_payoff.html" title="previous page">Mean payoff games</a>
    <a class='right-next' id="next-link" href="shortest_path.html" title="next page">Shortest path games</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By a set of authors coordinated by Nathana&euml;l Fijalkow<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>